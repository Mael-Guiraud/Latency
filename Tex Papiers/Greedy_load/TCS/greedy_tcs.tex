\documentclass[a4paper,UKenglish,cleveref, autoref, thm-restate]{lipics-v2019}


\usepackage[utf8]{inputenc}
\usepackage{xspace}
\usepackage{url}
\usepackage{graphicx,graphics} 
\usepackage{color}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{longtable}
\usepackage{complexity}
\usepackage{tkz-graph}
\usepackage{float}
\usepackage{tabularx} 
\usepackage{tkz-graph}
\usepackage{complexity}
 
%\renewcommand{\algorithmicrequire}{\textbf{Input:}}
%\renewcommand{\algorithmicensure}{\textbf{Output:}}

 
%\newtheorem{fact}{Fact}
\DeclareMathOperator{\Fo}{FO} 
\DeclareMathOperator{\Fmo}{FMO} 
\newcommand\pma{\textsc{pma}\xspace}
\newcommand\firstfit{\texttt{First Fit}\xspace}
\newcommand\compactpair{\texttt{Compact Pairs}\xspace}
\newcommand\metaoffset{\texttt{Meta Offset}\xspace}
\newcommand\greedyuniform{\texttt{Greedy Uniform}\xspace}
\newcommand\swapandmove{\texttt{Swap and Move}\xspace}
\newcommand\compactfit{\texttt{Compact Fit}\xspace}
\newcommand\greedypotential{\texttt{Greedy Potential}\xspace}
\newcommand{\todo}[1]{{\color{red} TODO: {#1}}}

\bibliographystyle{plainurl}% the mandatory bibstyle

\title{Scheduling Periodic Messages on a Shared Link without Buffering} %TODO Please add
%\titlerunning{Dummy short title} %TODO optional, please use if title is longer than one line

\author{Ma\"el Guiraud}{CESI, France \and Nokia Bell Labs, France}{mael.guiraud@uvsq.fr}{}{}
\author{Yann Strozecki}{David Laboratory, UVSQ, France }{yann.strozecki@uvsq.fr}{}{}%TODO mandatory, please use full name; only 1 author per \author macro; first two parameters are mandatory, other parameters can be empty. Please provide at least the name of the affiliation and the country. The full address is optional



\authorrunning{M. Guiraud and Y. Strozecki} %TODO mandatory. First: Use abbreviated first/middle names. Second (only in severe cases): Use first author plus 'et al.'

\Copyright{Ma\"el Guiraud and Yann Strozecki} %TODO mandatory, please use full first names. LIPIcs license is "CC-BY";  http://creativecommons.org/licenses/by/3.0/

\ccsdesc[500]{Theory of computation~Design and analysis of algorithms}


%\ccsdesc[100]{\textcolor{red}{Replace ccsdesc macro with valid one}} %TODO mandatory: Please choose ACM 2012 classifications from https://dl.acm.org/ccs/ccs_flat.cfm 

\keywords{Periodic Scheduling, Greedy Algorithm, Randomized Algorithm, Experimental Algorithms, C-RAN} %TODO mandatory; please add comma-separated list of keywords

%\relatedversion{} %optional, e.g. full version hosted on arXiv, HAL, or other respository/website
%\relatedversion{A full version of the paper is available at \url{https://arxiv.org/abs/2002.07606}.}

%\acknowledgements{I want to thank \dots}%optional




\begin{document}

\maketitle


\begin{abstract}
Cloud-RAN is a recent architecture for mobile networks where the processing units are located in distant data-centers while, until now, they were attached to antennas. The main challenge, to fulfill protocol constraints, is to guarantee a low latency for the periodic messages sent from each antenna to its processing unit and back. The problem we address is to find a periodic sending scheme of these messages \emph{without contention nor buffering}, when all messages are of the same size and the period is fixed.

We study the problem \pma modeling this situation on a common topology, where contention arises from a single link shared by all antennas. The problem is reminiscent of classical scheduling and packing problems, but the periodicity introduces a new twist. We study how the problem behaves with regard to the \emph{load} of the shared link. 
The main contributions are polynomial time algorithms which \emph{always} find a solution for arbitrary size of messages and load less than $4/10$ or for messages of size one and load less than $\phi - 1$, the golden ratio conjugate. We also prove that, a randomized greedy algorithm finds a solution on almost all instances with high probability, explaining why most greedy algorithms work so well in our experiments.
\end{abstract}


\section{Introduction}

Centralized radio network architecture, called C-RAN for Cloud Radio Access Network, has been proposed as a next generation architecture to reduce energy consumption costs~\cite{mobile2011c} and more generally the total cost of ownership. The main challenge for C-RAN is to reach a latency compatible with transport protocols~\cite{ieeep802}. The latency is measured between the sending of a message by a Remote Radio Head (RRH) and the reception of the answer, computed by a BaseBand Unit (BBU) in the cloud. For example, LTE standards require processing functions like HARQ (Hybrid Automatic Repeat reQuest) in $3$ms~\cite{bouguen2012lte}. In 5G, some services need end-to-end latency as low as $1$ms~\cite{3gpp5g,boccardi2014five}. The specificity of the C-RAN context is not only the latency constraint, but also the periodicity of the data transfer in the frontaul network between RRHs and BBUs: messages need to be emitted and received each millisecond~\cite{bouguen2012lte}. 

Our aim is to operate a C-RAN on a low-cost shared switched network: several (tens of) antennas share an high-speed link to send their periodic messages to one (or several) data-center. This shared link is the only contention point for a message going to the data-center and it is also the contention point for the answer sent back by the data-center to the antenna.
This model with two contention points (one for the message and one for the answer) also capture other periodic systems such as processors communicating over a bus or sensors doing periodic radio transmissions on the same frequency.

We address the following question: \emph{is it possible to schedule periodic messages on a shared link without using buffers}? Eliminating this source of latency leaves us with more time budget for latency due to the physical length of the routes in the network, and thus allows for wider deployment areas. Our proposed solution is to compute beforehand a \emph{periodic and deterministic} sending scheme, which completely avoids contention.  

The algorithmic problem studied, called \emph{Periodic Message Assignment} or \pma, is as follows:
Given a period, a message size and a delay between the two contention points for each message, set a departure time in the period for each message, so that they go through both contention points without collision. It is similar to the two flow shop scheduling problem~\cite{yu2004minimizing} with periodicity. The periodicity adds more constraints, since the sending pattern for a single period must be repeated without creating collision at contention points. In flow shop problems, the aim is usually to minimize the makespan, or schedule length, but in our periodic variant this quantity is infinite. Hence, we choose to look for any periodic schedule without buffering between the two contention points, to minimize the trip time of each message. 


\paragraph*{Related Works}


The model we study was recently introduced in~\cite{dominique2018deterministic} to find sending schedules for C-RAN messages, with \emph{buffering allowed}. This problem has also been studied for a cycle topology instead of a shared link~\cite{Guir1905:Deterministic}. In these articles, the main results are heuristics, using classical scheduling algorithms as subroutines, and FPT algorithms which find a sending scheme with \emph{minimal latency}. The problem of finding sending schemes with \emph{no additional latency}, which is the subject of this article under the name \pma, is also briefly introduced and studied in~\cite{dominique2018deterministic}.
In this article, we propose several new polynomial time algorithms which dramatically improve on the greedy algorithm used to solve \pma in~\cite{dominique2018deterministic}, in the worst case or in average and for large and small messages. 
While a sending scheme without buffering is simpler and less expensive to implement in C-RAN networks than one with buffering, it may not exist. However, we prove in this article that \emph{when the load is not too high,
there is always a solution without buffering}. Moreover, we explain in Sec.~\ref{sec:reduction} how solving \pma can be used to produce heuristic to solve the problem of finding sending schedules with small latency.

 Variations on the problem of minimizing latency of periodic messages in networks have been considered and practically solved, using mixed integer programming~\cite{nayak2017incremental,steiner2018traffic} or an SMT solver~\cite{dos2019tsnsched}, but without theoretical guarantees on the quality of the produced solutions nor on the computation time. Typical applications cited in these works (out of C-RAN) are sensor networks communicating periodically inside cars or planes, or logistic problems in production lines, which could also be captured in our model.

 To our knowledge, most periodic scheduling problems studied in the literature are quite different from the one we study in this article. In some works~\cite{korst1991periodic,hanen1993cyclic}, the aim is to minimize the number of processors on which the periodic tasks are scheduled, while our problem corresponds to two processors and a constraint similar to makespan minimization. In cyclic scheduling~\cite{levner2010complexity}, the aim is to minimize the period of a scheduling to maximize the throughput, while our period is fixed. The train timetabling problem~\cite{lusby2011railway} and in particular the periodic event scheduling problem~\cite{serafini1989mathematical} are generalizations of our problem, since they take the period as input and can express the fact that two trains (like two messages) should not cross. However, they are much more general: the trains can vary in size, speed, the network can be more complex than consecutive single tracks and there are precedence constraints. Hence, the numerous variants of train scheduling problems are very hard to solve. Therefore, some delay is allowed in different parts of the network to make these problems solvable and most of the research done~\cite{lusby2011railway} is devising practical algorithms using branch and bound, mixed integer programming, genetic algorithms etc. 
 

\paragraph*{Organization of the Paper}

In Sec.~\ref{sec:model}, we present the model and the problem \pma. In Sec.~\ref{sec:large},
we present several greedy algorithms and prove they always find a solution to \pma for moderate loads. 
These algorithms rely on schemes to build compact enough solutions, to bound measures of the size wasted when scheduling messages. Then, in Sec.~\ref{sec:small} we present deterministic and probabilistic algorithms for the case $\tau = 1$, which work for much higher loads than the algorithms for large messages. The deterministic algorithm is not greedy, contrarily to algorithms of Sec.~\ref{sec:large}, since it uses a swap mechanism which can move already scheduled messages. 
 In Appendix~\ref{sec:reduction}, we justify how we can restrict the problem to messages of size one for the price of doubling the load or adding some latency. 
 In Appendix~\ref{sec:coherent}, we show how the presented algorithms also work in complex networks with many contention points, as long as the routing is coherent. Finally, we present the performance of all algorithms on random inputs, both on large messages in Sec.~\ref{sec:perf_large} and small messages in Sec.~\ref{sec:perf_small}.
 % It turns out that our algorithms work even better on random instances than what we have established for their worst case.


\section{Modeling a C-RAN Network}\label{sec:model}
\begin{center}
\begin{figure}
\begin{minipage}[c]{.45\linewidth}
\centering
\includegraphics[scale=0.3]{network2.pdf} 
\end{minipage}
\hfill
\begin{minipage}[c]{.45\linewidth}
\centering
\scalebox{0.45}{
\begin{tikzpicture}
    \SetGraphUnit{5}
      \node[black] at (8,5.9) {$d_0$};
       \node[black] at (4,4.6) {$C_1$};
        \node[black] at (12,4.6) {$C_2$};
         \node[black] at (8,5.3) {$d_1$};
            \node[black] at (8,2.9) {$d_{n-1}$};
            \node[black] at (8,4.15) {.};
            \node[black] at (8,4.0) {.};
            \node[black] at (8,3.85) {.};
  \tikzstyle{VertexStyle}=[shape = circle, draw, minimum size = 10pt]
  \SetUpVertex[FillColor=black]  
  \Vertex[x=4,y=4]{1}
  \Vertex[x=12,y=4]{2}  
 \draw[->,line width=2pt,black] (4,4) parabola bend (8,5.6) (12,4);
  \draw[->,line width=2pt,black] (4,4) parabola bend (8,5) (12,4);
      \draw[->,line width=2pt,black] (4,4) parabola bend (8,2.6) (12,4);
\end{tikzpicture}
}
\end{minipage}
\caption{C-RAN network with a single shared link modeled by two contention points and delays}
\label{fig:model}
\end{figure}
\end{center}

In this article, we model a simple network in which periodic messages flow through a single bidirectional link. Each RRH sends messages through the link to its
BBU and two messages cannot go at once in the link: this is the first contention point, represented in Fig.~\ref{fig:model}. Upon receiving a message, a BBU sends an answer back to its RRH, which goes through the link in the other direction: this is the second contention point represented in Fig.~\ref{fig:model}. Since the answer must be sent back as soon as a message arrives, we see this process as a single message going from an RRH to its BBU and back to the RRH, while traversing two contention points. 

Messages using the link in two different directions do not interact, since the link we model is full-duplex. In the C-RAN context we consider, \emph{all messages are of the same kind}, hence they are all of the same size denoted by $\tau$. This \textbf{size} represents the time needed to send a message through a contention point of the network, here the beginning of the link shared by all antennas. Allowing messages of different sizes would help model applications where several type of periodic messages use the same network, further work to adapt the algorithms presented in this paper is required to handle this potential generalization.


 We denote by $n$ the number of messages, which are numbered from $0$ to $n-1$. A message $i$ is characterized by its \textbf{delay} $d_i$: when message number $i$ arrives at the beginning of the shared link (first contention point) at time $t$, it returns to the other end of the link on its way back (second contention point) at time $t + d_i$. The model and problem can easily be generalized to any topology, that is any directed acyclic multigraph with any number of contention points, see~\cite{dominique2018deterministic}. We choose here to focus on a realistic network with a single shared link, which is simple enough to obtain theoretical results. It turns out that algorithms solving the problem for a single shared link can be used on networks with many contention points, as long as the routing is coherent, see Appendix~\ref{sec:coherent}. 

The time is discretized and \emph{the process we consider is periodic} of fixed integer \textbf{period $P$}. We use the notation $[P]$ for the set $\{0,\dots,P-1\}$. A message is emmited an infinite number of times periodically, hence it is enough to consider any interval of $P$ units of time to completely represent the state of our system by giving the times, in this interval, at which each message goes through the two contention points. We call the representation of an interval of $P$ units of time in the first contention point the \textbf{first period} and the \textbf{second period} for the second contention point. 

An \textbf{offset} of a message is a choice of time at which it arrives
at the first contention point (i.e. in the first period). Let us consider a message $i$
of offset $o_i$, it uses the interval of time $[i]_1 = \{ (o_i + t) \mod P \mid 0 \leq t < \tau \}$ in the first period and $[i]_2 = \{ (d_i + o_i + t) \mod P \mid 0 \leq t < \tau \}$ in the second period. Two messages $i$ and $j$ \textbf{collide} if either $[i]_1 \cap [j]_1 \neq \emptyset $ or $[i]_2 \cap [j]_2 \neq \emptyset $. If $t \in [i]_1$ (resp. $t \in [i]_2$), we say that message $i$ uses time $t$ in the first period (resp. in the second period).

We want to send all messages, so that there is no collision in the shared link.
In other words, we look for a way to send the messages without using buffering,
hence limiting the latency of messages to the physical length of the links. An \textbf{assignment} is a choice of an offset for each message such that \emph{no pair of messages collide}, as shown in Fig.~\ref{fig:assignment}.
Formally, an assignment is a function from the messages in $[n]$ to their offsets in $[P]$.  
Let \textbf{Periodic Message Assignment} or \pma be the following problem: given an instance of $n$ messages of delays $d_0,\dots,d_{n-1}$, a period $P$ and a size $\tau$, find an assignment or decide there is none. When an assignment is found, we say the problem is solved \textbf{positively}.

\begin{figure}
\begin{center}
\includegraphics[scale=0.7]{instance}
\end{center}
\caption{An instance of \pma with $3$ messages, $P= 10$, $\tau = 2$, and one assignment}
\label{fig:assignment}
\end{figure}

The complexity of \pma is not yet known. However, it has been proven that, when parameterized by
$n$ the number of messages, the problem is \FPT~\cite{barth2018deterministic}. A slight generalization of \pma presented in Appendix~\ref{sec:coherent}, with more contention points, but each message only going through two of them as in \pma, is \NP-hard~\cite{barth2018deterministic}. If the shared link is not full-duplex, that is, there is a single contention point and each message goes through it twice, it is also \NP-hard, since we can encode a similar non periodic problem~\cite{orman1997complexity}. However, we did not achieve to prove that \pma is \NP-hard, but we conjecture it is.
	
Because we are interested in \pma when it can be solved positively, we study it when the load of the system is small enough. The \textbf{load} is defined as the number of units of time used in a period by all messages divided by the period that is $n\tau /P$. There cannot be an assignment when the load is larger than one; we prove in this article that, for moderate loads, there is \emph{always} an assignment and that it can be found by a polynomial time algorithm. This result is also helpful when solving the following optimization version of \pma: given a set of messages, find the largest subset 
which admits an assignment. A weigthed version, where the messages have different values can also be considered. An optimal solution to the optimization problem is a set of messages corresponding to a load of at most $1$. Assume we have an algorithm that always finds an assignment for an instance of load $\lambda$. Then, such an algorithm finds an assignment for any subset of load $\lambda$
and is an approximation algorithm for the optimization problem with approximation ratio $\lambda$.


\section{Greedy Algorithms for Large Messages} \label{sec:large}

In this section, we study the case of arbitrary values for $\tau$. When modeling a C-RAN network,
we choose the time granularity, and we could set it so $\tau = 1$ for simplicity. However, the size of a link and thus the delay of a message
is typically of the same magnitude as $\tau$, therefore setting $\tau = 1$ is a too coarse granularity to faithfully model the network.

A \textbf{partial assignment} $A$ is a function defined from a subset $S$ of $[n]$ to $[P]$.
The cardinal of $S$ is the \textbf{size} of partial assignment $A$. A message in $S$ is \textbf{scheduled} (by $A$), and a message not in $S$ is \textbf{unscheduled}. We only build partial assignments such that no pair of messages of $S$ collide. If $A$ has domain $S$, and $i \notin S$, we define the extension of $A$ to the message $i$ by the offset $o$, denoted by $A[i \rightarrow o]$, as $A$ on $S$ and $A[i \rightarrow o](i) = o$.

All presented algorithms build an assignment incrementally, by growing the size of a partial assignment. Moreover, algorithms in this section are \emph{greedy}: Once an offset is chosen for a message, it is never changed. In the rest of the paper, we sometimes compare the relative position of messages to detect collisions, but one should remember that the time is periodic and these are relative positions on a circle. 
In some remarks and computations, we may omit to write \emph{mod P}, when it is unimportant and weigh down the presentation.


\subsection{First Fit}


Consider some partial assignment $A$, in the first period, the message $i$ uses the times in $[A(i), A(i) + \tau -1]$. If a message $j$ is scheduled by $A$, with $A(j) < A(i)$, then the last time it uses in the first period is $A(j)+\tau-1$ and it should be less than $A(i)$, which implies that $A(j) \leq A(i) - \tau$. Symmetrically, if $A(j) > A(i)$, to avoid collision between messages $j$ and $i$, we have $A(j) \geq A(i) + \tau$. Hence, message $i$ forbids the interval $[A(i) - \tau +1, A(i) + \tau -1]$ as offsets for messages still not scheduled, because of its use of time in the first period. The same reasoning shows that $2\tau -1$ offsets are also forbidden because of the times used in the second period. Hence, if $|S|$ messages are already scheduled, then at most $|S|(4\tau -2)$ offsets are forbidden for an unscheduled message. The real number of forbidden offsets may be smaller, since the same offset can be forbidden both because of a message on the first and on the second period.

Let $A$ be a partial assignment defined over $S$ and $i\notin S$, we let $\Fo(A)$ be the maximum over $i \in [n]$ of $|\left\{ o \in [P] \mid A[i \rightarrow o] \text{ has a collision}\right\}|$. 
The notation $\Fo(A)$ stands for \emph{forbidden offset by $A$}. We have computed in the previous paragraph that $\Fo(A)$ is less than $(4 \tau -2)|S|$. 

Let \firstfit be the following algorithm:  for each unscheduled message (in the order they are given), test all offsets from $0$ to $P-1$ until one does not create a collision with the current assignment, and use it to extend the assignment. If $\Fo(A) < P$, then whatever the delay of the message we want to extend $A$ with, there is an offset to do so. Since $\Fo(A) \leq (4 \tau -2)|S|$ and $|S| < n$, \firstfit (or any greedy algorithm) always succeeds when $(4 \tau -2)n \leq P$, that is when the load $ n\tau /P$ is less than $1/4$.
It turns out that \firstfit always creates compact assignments (as defined in~\cite{dominique2018deterministic}), that is a message is always next to another one in one of the two periods. Hence, we can prove a better bound on $\Fo(A)$, when $A$ is built by \firstfit, as stated in the following theorem.

\begin{theorem}
\firstfit solves \pma positively on instances of load less than $1/3$. 
\end{theorem}
\begin{proof}
We show by induction on the size of $S$, that $\Fo(A) \leq |S|(3\tau -1) + \tau - 1$. For $S = 1$, it is clear since a single message forbid at most $(3\tau -1) + \tau -1 = 4\tau-2$ offsets, as explained before. Now, assume $\Fo(A) \leq |S|(3\tau -1) + \tau -1$ and consider a message $i \notin S$ such that \firstfit builds $A[i \rightarrow o]$ from $A$. By definition of \firstfit, choosing $o-1$ as offset creates a collision. W.l.o.g. say it is a collision in the first period. It means that there is a scheduled message between $o - \tau $ and $o-1$, hence all these offsets are forbidden by $A$. The same offsets are also forbidden by the choice of $o$ as offset for $i$, hence only $3\tau -1$ new offsets are forbidden, that is $\Fo(A[i \rightarrow o]) \leq \Fo(A) + (3\tau -1)$, which proves the induction.  
 During \firstfit, $\Fo(A)$ is maximal when the last element is scheduled, that is when $A$ is of size $n-1$, hence $\Fo(A) \leq (n-1)(3\tau -1) + \tau - 1 < 3n\tau$, which proves the theorem.
\end{proof}

\subsection{Meta-Offset}

The method of this section is described in~\cite{dominique2018deterministic} and it achieves the same bound on the load using a different method. It is recalled here to introduce algorithms of the next section.
The idea is to restrict the possible offsets at which messages can be scheduled. It seems counter-intuitive, since it decreases artificially the number of available offsets to schedule new messages. However, it allows to reduce the number of forbidden offsets for unscheduled messages. A \textbf{meta-offset} is an offset of value $i\tau$,
with $i$ an integer from $0$ to $\lceil P / \tau \rceil - 1$. We call \metaoffset the greedy algorithm which works as \firstfit, but consider only meta-offsets when scheduling messages. 

To study \metaoffset, we introduce a variant of $\Fo(A)$ restricted to meta-offsets.
 Let $A$ be a partial assignment defined over $S$ and $i\notin S$, we let $\Fmo(A)$ be the maximum over $i \in [n]$ of $|\left\{ j \in [\lceil P / \tau \rceil] \mid A[i \rightarrow j\tau] \text{ has a collision}\right\}|$.
 By definition, two messages with a different meta-offset cannot collide in the first period. Hence, $\Fmo(A)$ can be bounded by $3|S|$ and we obtain the following theorem.


\begin{theorem}[Proposition 3 of~\cite{dominique2018deterministic}]\label{th:metaoffset}
\metaoffset solves \pma positively on instances of load less than $1/3$.
\end{theorem}

The complexity of a naive implementation of \metaoffset is in $O(n P/\tau)$, while \firstfit is in $O(nP)$. However, it is not useful to consider every possible (meta-)offset at each step. By maintaining a list of increasing position of scheduled messages in first and second period, both algorithms can be implemented in time $O(n^2)$, which is better than $O(n P/\tau)$ since $n < P/\tau$.

\subsection{Compact Tuples}

We present in this section a family of greedy algorithms which solve \pma positively for larger loads. We try to combine the good properties of the two previous algorithms: the compactness of the assignments produced by \firstfit and the absence of collision in the first period of \metaoffset. The idea is to schedule several messages at once, using meta-offsets, to maximize the compactness of the obtained solution. We describe an algorithm which schedules pairs of messages, which is then extended to any tuples of messages.


In Lemma~\ref{lemma:multiple}, we show that we can assume $P = m\tau$ in the rest of the section. This hypothesis makes the analysis of algorithms based on meta-offsets simpler and tighter. The load increases from $\lambda = n \tau / P$ to at most $\lambda (1 + 1/m)$: the difference is less than $1/m < 1/n$, thus very small for most instances. If we drop this hypothesis, the theorems of this section
can be restated as proving the existence of an assignment for a load $\lambda - o(1)$, where $o(1)$ goes to $0$ when $n$ grows. 

\begin{lemma}\label{lemma:multiple}
Let $I$ be an instance of \pma with $n$ messages of size $\tau$, period $P$ and $m = \lfloor P / \tau \rfloor$. There is an integer $\tau'$ and an instance $J$ with $n$ messages of size $\tau'$ and period $P'= m\tau'$ such that any assignment of $J$ can be transformed into an assignment of $I$ in polynomial time.
\end{lemma}
\begin{proof}
%Fig.~\ref{fig:multipleperiod} illustrates the reductions we define in this proof on a small instance.
Let $P = m \tau + r$ with $r \leq \tau$. We define the instance $I'$ as follows: $P' = mP$, $d_{i}' = m d_i$ and $\tau' = m \tau + r$. With this choice, we have $P' = m(m \tau + r) = m \tau'$.
Consider an assignment $A'$ of the instance $I'$. We let $\tau'' = m\tau$, then $A'$ is also an assignment for $I'' = (P',\tau'',(d_{0}',\dots,d_{n-1}'))$. Indeed, the size of each message, thus the intervals of time used in the first and second period begin at the same position but are shorter, which cannot create collisions. We then use a compactification procedure on $A'$ seen as an assignment of $I''$, with size of messages multiple of $m$ (see Th.4 of~\cite{dominique2018deterministic} for a similar compactification). W.l.o.g., message $0$ is positioned at offset zero. The first time message $0$ uses in the second period is a multiple of $m$ since its delay is by construction a multiple of $m$. Consider the following translation of $A'$: $A'(0) = 0$ and for $i>0, A'(i) = A'(i) -s$. We choose $s$ to be a non negative integer such that
$A'$ translated by $s$ is an assignment without collision, while $A'$ translated by $s+1$ has a collision with message $0$. We let $A'$ be $A'$ translated by $s$, then by construction,
 there is a message $j$ which is next to message $0$ in the first or second period. It implies that either $A'(j)$ or $A'(j)+d_j \mod P'$ is a multiple of $m$ and since $d_j$ is a multiple of $m$, then both $A'(j)$ and $A'(j)+d_j \mod P'$ are multiples of $m$. The procedure can be repeated, by fixing messages $O$ and $j$ and translating the other messages, and so on until we get an assignment $A''$ to $I''$, such that all positions of messages in the first and second period are multiples of $m$. Finally, we define $A$ assignment of $I$ as $A(i) = A''(i)/m$. 
\end{proof}

Notice that, transformation of Lemma~\ref{lemma:multiple} does not give a bijection between assignments of both instances but only an injection, which is enough for our purpose. 

%\begin{figure}
% \begin{center}
%\includegraphics[scale=0.75]{multipleperiod}
%\end{center}
%\caption{Transformation from $A''$ to $A$}
%\label{fig:multipleperiod}
%\end{figure}


%We are interested in the remainder modulo $\tau$ of the delays. 
Let $d_i = d_{i}'\tau + r_i$ be the Euclidean division of $d_i$ by $\tau$. We assume that \emph{messages are sorted by increasing $r_i$}.
A \textbf{Compact pair}, as shown in Fig.~\ref{fig:compactpair} is a pair of messages $(i,j)$ with $i < j$ that can be scheduled using meta-offsets such that $A(i) + (d'_i+1)\tau = A(j) + d'_j\tau$, i.e. the beginning of $j$ is less than $\tau$ unit of times after the end of $i$ in the second period.
The \textbf{gap} between $i$ and $j$ is defined as  $g = d'_{i} + 1 - d'_{j} \mod m$, it is the distance in meta offsets between $i$ and $j$ in the first period. By definition, we can make a compact pair out of $i$ and $j$, if and only if their gap is not zero.

\begin{figure}[h]
\begin{center}

\includegraphics[scale=0.7]{compact_pair}
\end{center}
\caption{The compact pair $(0,1)$ with $d'_0 = 2$ and $d'_1 = 0$}
\label{fig:compactpair}
\end{figure}

\begin{lemma}\label{lemma:pair_find}
Given three messages $(1,2,3)$ in order of increasing delay modulo $\tau$, then either $(1,2)$, $(1,3)$ or $(2,3)$ form a compact pair. 
\end{lemma}
\begin{proof}
If the first two messages or the first and the third message form a compact pair, we are done. If not, then by definition $d_{1}' = 1 + d_{2}' = 1 + d_{3}'$. Hence, messages $2$ and $3$ have the same delay and form a compact pair of gap $1$.
\end{proof}

Let \compactpair be the following greedy algorithm:  A sequence of at least $n/3$ compact pairs is built by forming triples of messages in order of increasing $r_i$, and applying Lemma~\ref{lemma:pair_find} to each triple. Pairs are scheduled in the order they have been built using meta-offsets. If at some point all compact pairs are scheduled or the current one cannot be scheduled, the remaining messages are scheduled as in \metaoffset. The analysis of \compactpair relies on the evaluation of the number of forbidden meta-offsets. In the first phase of \compactpair, we evaluate the number of forbidden offsets when scheduling any compact pair, that we denote by $\Fmo_2(A)$. In the second phase, we need to evaluate $\Fmo(A)$. When scheduling a message in the second phase, a scheduled compact pair only forbids \emph{three} meta-offsets in the second period, while two messages scheduled independently forbid \emph{four} meta-offsets, which explains the improvement from \compactpair. We state the previous remarks as Lemma~\ref{lemma:pair_forbid}, see an illustration in Fig.~\ref{fig:forbidenmeta}. 

\begin{lemma}\label{lemma:pair_forbid}
Let $C_1$ be compact pair scheduled by \compactpair, $C_2$ a compact pair and $i$ a single message both later scheduled by \compactpair.
Then $C_1$ forbids at most four meta-offsets to $C_2$ and three meta-offsets to $i$ because of collisions in the second period. 
\end{lemma}

\begin{figure}
\begin{center}
\includegraphics[scale=0.7]{pairforbiden}
\end{center}

\caption{Positions forbidden by a scheduled compact pair (in blue) when scheduling another compact pair (in red) with larger $r_i$'s} 
\label{fig:forbidenmeta}
\end{figure}
\begin{theorem}
\compactpair solves \pma positively on instances of load less than $3/8$.
\end{theorem}
\begin{proof}
Let $n_2$ be the number of compact pairs scheduled in the first phase. When scheduling a new pair, the position of the $2n_2$ messages on the first period forbid $4n_2$ offsets for a compact pair. Indeed, each scheduled message can collide with each of the two messages which form a compact pair. In the second period, we use Lemma~\ref{lemma:pair_forbid} to bound the number of forbidden offsets by $4n_2$. 
Hence, we have established that during the first phase, the partial solution $A$ satisfies $\Fmo_2(A) \leq 8n_2$. This first phase continues while there are available offsets for compact pairs, which is guaranteed when $\Fmo_2(A) \leq m$, that is while $n_2 \leq m/8$. Hence, we may assume that $n_2 = m/8$.

In the second phase, by Lemma~\ref{lemma:pair_forbid}, a compact pair forbids $3$ meta-offsets in the 
second period and $2$ in the first. Hence, if we let $n_1$ be the number of messages scheduled in the second phase to build partial assignment $A$, we have $\Fmo(A) \leq n_2*5 + n_1*3$. 
\compactpair can always schedule messages when $\Fmo(A)$ is less than $m$, which is implied by $n_2*5 + n_1*3 \leq m$.
Solving this equation, we obtain that $n_1 \geq \frac{m}{8}$ thus the number of messages scheduled is at least $2n_2 + n_1 \geq \frac{3}{8}m$. Assuming there are exactly $\frac{3}{8}m$ messages to schedule, then $\frac{2m}{8}$ messages are scheduled as compact pairs. It is two third of the $\frac{3}{8}m$ messages, hence Lemma~\ref{lemma:pair_find} guarantees the existence of enough compact pairs. Therefore, an assignment is always produced when the load is less or equal to $\frac{3}{8}$.
\end{proof}

\compactpair can be improved by forming compact tuples instead of compact pairs, see Appendix~\ref{sec:compact} for the description 
 and the analysis of algorithm \texttt{Compact k-tuples}.


\begin{theorem}\label{th:k-tuples}
\texttt{Compact 8-tuples} always solves \pma positively on instances of load less than $4/10$, on instances with $n \geq 205$.
\end{theorem}


\section{Messages of Size One} \label{sec:small}

For $\tau = 1$ and a load less than $1/2$, \emph{any greedy algorithm} solves \pma positively since $\Fo(A) \leq (4\tau -2)|S| = 2|S|$ where $S$ is the number of scheduled messages. In this section, we give an algorithm which always finds an assignment when the load is larger than $1/2$. In Appendix~\ref{sec:reduction} we show how and at what cost $\tau$ can be assumed to be one.

\subsection{Deterministic Algorithm}

To go above $1/2$ of load, we optimize a potential measuring how many offsets are available for the messages of the instance, scheduled or not. 
%Messages are scheduled while possible using any greedy algorithm. Then, when all unscheduled messages have no available offset, we use a Swap operation defined later, which improves the potential. 
%When the potential is high enough, it ensures that there are two messages whose offset can be changed so that a new message can be scheduled. 

\begin{definition}
The potential of a message of delay $d$, for a partial assignment $A$
is the number of integers $p \in [P]$ such that $p$ is used in the first period and $p+d \mod P$ is used in the second period.
\end{definition}

%The computation of the potential of a message of delay $3$, is illustrated in Fig.~\ref{fig:messagepotential}.
The potential of a message counts how many forbidden offsets are avoided by the message given a partial assignment $A$.
Indeed, when $p$ is used in the first period and $p+d \mod P$ is used in the second period,
then the same offset is forbidden \emph{twice} for a message of delay $d$. Hence, the potential of a message is related to the number of possible offsets as stated in the following lemma. 
%\begin{figure}
% \begin{center}
%\includegraphics[scale=1]{messagepotential}
%\end{center}
%\caption{A message with a potential $2$}
%\label{fig:messagepotential}
%\end{figure}

\begin{lemma}
Given a partial assignment $A$ of size $s$, and $i$ an unscheduled message of potential 
$v$, then the set $\{o \mid A[i \rightarrow o] \text{ has no collision}\}$ is of size $P - 2s + v$.
\end{lemma}

We define a global measure of quality of a partial assignment, 
that we later optimize by local modification when it is not possible to schedule a new message. 
We call our measure \textbf{the potential of an assignment} and we denote it by $Pot(A)$, it is the sum of potentials of all messages in the instance.


\begin{definition}
The potential of a position $p \in [P]$, for a partial assignment $A$, is the number of messages $i \in [n]$, such that 
$A[i \rightarrow p]$ has a collision. 
\end{definition}

%\begin{figure}
% \begin{center}
%\includegraphics[scale=1]{positionspotential}
%\end{center}
%\caption{A position of potential $3$}
%\label{fig:positionpotential}
%\end{figure}

%The potential of a position is illustrated in Fig.~\ref{fig:positionpotential}.
Instead of decomposing the global potential as a sum over messages, it can be interpreted
as a sum over positions, as stated in the next lemma.

\begin{lemma}\label{lemma:pot_pos}
The sum of potentials of all positions used in the first period by messages scheduled by $A$ is equal to $Pot(A)$.  
\end{lemma}

By definition of the potential of a position, we obtain the following simple invariant.

\begin{lemma}\label{lemma:inv}
The sum of potentials of all positions of a partial assignment of size $k$ is $nk$.  
\end{lemma}

 As a consequence of this lemma, $Pot(A) \leq nk$. Let us define a \textbf{Swap operation},
 which guarantees to obtain at least half the maximal value of the potential.
Let $A$ be some partial assignment of size $s$ and let $i$ be an unscheduled message. 
Assume that $i$ cannot be used to extend $A$. The Swap operation is the following: 
select a free position $p$ in the first period, remove the message which uses the position $p+d_i$ in the second period from $A$ and extend $A$ by $i$ with offset $p$. We denote by $Swap(i,p,A)$ the partial assignment obtained by this operation.

\begin{lemma}\label{lemma:swap}
Let $A$ be some partial assignment of size $k$ and let $i$ be an unscheduled message. If $i$ cannot be used to extend $A$, then either $Pot(A) \geq kn/2$ or there is $p \in [P]$ such that $Pot(Swap(i,p,A)) > Pot(A)$.
\end{lemma}

\begin{proof}
The positions in the first period can be partitioned into $P_{u}$ the positions used by some scheduled message and $P_{f}$ the unused positions.
Let $V_f$ be the sum of the potentials of the positions in $P_f$ and let $V_u$ be the sum of the potentials of the positions in $P_u$. By Lemma~\ref{lemma:inv}, since $P_f$ and $P_u$ partition the positions, we have $V_f + V_u = kn$. Moreover, by Lemma~\ref{lemma:pot_pos}, $Pot(A) = V_u$, then $V_f + Pot(A) = kn$.

By hypothesis, $i$ cannot be scheduled, then, for all $p \in P_{f}$, $p+d_i$ is used in the second period. Let $F$ be the function which associates to $p \in P_{f}$ the position $A(j)$ such that there is $j$ a scheduled message which uses $p+d_i$ in the second period, that is $A(j) + d_j = p + d_i \mod P$. The function $F$ is an injection from $P_{f}$ to $P_u$. Remark that, in both $Swap(i,p,A)$ and $A$, the same positions are used in the second period. Hence, the potential of each position stay the same after the swap. As a consequence, doing the operation $Swap(i,p,A)$ adds to $Pot(A)$ the potential of the position $p$ and removes the potential of the position $F(p)$. 

Assume now, to prove our lemma, that for all $p$, $Pot(Swap(i,p,A)) \leq Pot(A)$. It implies that for all $p$, the potential of $p$ is smaller than the potential of $F(p)$. Since $F$ is an injection from $P_f$ to $P_u$, we have that $V_f \leq V_u = Pot(A)$. Since $V_f + Pot(A) = kn$, we have that $Pot(A) \geq kn/2$.
\end{proof}


Let us now describe the algorithm \swapandmove:  messages are scheduled while possible by \firstfit and then the Swap operation is applied while it increases the potential. When the potential is maximal, \swapandmove schedules a new message by moving at most two scheduled messages to other available offsets. If it fails to do so, \swapandmove stops, otherwise the whole procedure is repeated. 
\swapandmove  is not greedy, since we allow to change the offsets of two scheduled message to make room for an unscheduled one. It cannot work online, since it requires to know all delays of the messages in advance. 
%We analyze \swapandmove in the following theorem.

\begin{theorem}
\swapandmove solves positively \pma, in time $O(n^3)$, for instances with $\tau =1$ and load less than $1/2 + (\sqrt{5}/2 -1) \approx 0,618$.
\end{theorem}

\begin{proof}
We determine for which value of the load \swapandmove always finds an assignment. We let $n = (1/2 + \epsilon)P$ be the number of messages, the load is $1/2 + \epsilon$. We only study the situation when $n-1$ messages are scheduled by $A$ and \swapandmove tries to schedule the last one, since previous steps are similar but easier. 

Let $d$ be the delay of the unscheduled message. We consider the pairs 
of times $(p,p+d)$ for $p \in [P]$. Since the message
cannot be scheduled, there are three cases. First, $p$ is unused in the first period but $p+d$ is used in the second period. Since there are $n-1$ scheduled messages, there are $P-n+1$ such value of $p$. If a message using the time $p+d$ in the second period can be scheduled elsewhere, so that the unscheduled message can use offset $p$, then \swapandmove succeeds.
Otherwise, the message has no possible offset, which means its potential is equal to $2(\epsilon P -1)$.
The second case is symmetric: $p$ is used in the first period but $p+d$ is unused in the second period. 
Finally, we have the case $p$ is used in the first period and $p+d$ is used in the second period.  There are $2(\epsilon P -1)$ such values of $p$. If the two messages using times 
$p$ and $p+d$ can be rescheduled so that offset $p$ can be used for the unscheduled message,
then \swapandmove succeeds. This is always possible when one message is of potential at least $2\epsilon P -1$ and the other of potential at least $2\epsilon P + 1$. Since the messages must be of potential more than $2(\epsilon P -1)$ and at most $n-1$, it is satisfied when the sum of the two potentials is at least $2(\epsilon P -1) + n$.

If we assume that \swapandmove is unable to schedule the last message by moving two scheduled messages, the previous analysis gives us a bound on twice $Pot(A)$: 
$$ 2Pot(A) \leq 2(P-n+1) 2(\epsilon P -1) + 2(\epsilon P -1)(2(\epsilon P -1) + n) $$
$$ Pot(A) \leq (\epsilon P -1) (P + n)$$
By Lemma~\ref{lemma:swap}, we know that $Pot(A) \geq n(n-1)/2$, hence 
\swapandmove must succeed when
$$n(n-1)/2 \geq  (\epsilon P -1) (P + n).$$
By expanding and simplifying, we obtain a second degree inequation in $\epsilon$, $1/4 - 2\epsilon - \epsilon ^2 \geq  0$.
Solving this inequation yields $\epsilon \leq \sqrt{5}/2 -1$.


Let us prove that \swapandmove is in polynomial time. All Swap operations 
strictly increase the potential. Moreover, when one or two messages are moved, the potential may decrease but
a message is added to the partial assignment. The potential is bounded by $O(n^2)$ and the move operations all together can only remove $O(n^2)$ to the potential, hence there are at most $O(n^2)$ Swap operations during \swapandmove. A Swap operation can be performed in time $O(n)$, since for a given message, all free offsets must be tested and the potential is evaluated in time $O(1)$ (by maintaining the potential of each position). This proves that Swap and Move is in $O(n^3)$.  
\end{proof}

Consider a partial assignment of size $n' = (1/2 + \epsilon)P$, and a message of delay $d$.
If we consider all $n'$ used positions $p$ and all times time $p+d$ in the second period, 
then $p$ and $p+d$ are both used for at least $n' - (P -n') = 2\epsilon P$ values of $p$.
The potential of any message is thus larger or equal to $2\epsilon P$. When a message cannot be scheduled, its potential is less or equal to $2\epsilon P$, hence it is equal to $2\epsilon P$.

Hence, the potential of any assignment of size $n'$ is at least $2\epsilon P n $. The method of Lemma~\ref{lemma:swap} guarantes a non-trivial potential for $2\epsilon P n <  nn'/2$, that is $\epsilon < 1/6$. As a consequence, an algorithm relying on the potential and the Swap operation cannot be guaranteed to work for load larger than $2/3 = 1/2 + 1/6$. Hence, we conjecture that \swapandmove solves \pma positively for load up to $2/3$. To go further, the analysis in Lemma~\ref{lemma:swap} may be improved: $2\epsilon P$ positions in $P_{u}$ are not taken into account in the proof. However, there is an instance (found by a bruteforce search) with $8$ messages and $P=10$ for which there is no assignment, hence the largest $\lambda$ for which $\pma$ has always a solution is strictly less than $8/10$. 

%On random instances, we expect the potential to be higher than the guarantee of Lemma~\ref{lemma:swap} and to be better spread on the messages, which would make \swapandmove works for even larger loads, as it is indeed observed in experiments (see Appendix~\ref{sec:perf_small}).

\subsection{Randomized Algorithm for Random Instances}

We would like to better understand the behavior of greedy algorithms on instances drawn uniformly at random. To this aim, we analyze the algorithm \greedyuniform, defined as follows: for each message in the order of the input, choose one of the offsets, which does not create a collision with the current partial assignment, uniformly at random. 

We analyze \greedyuniform over random instances:  all messages have 
their delays drawn independently and uniformly in $[P]$. We compute the probability of success of \greedyuniform over all random choices by the algorithm \emph{and all possible instances}. 
It turns out that this probability, for a fixed load strictly less than one, goes to one when $P$ grows. 
For a given partial assignment, we are only interested in its trace: the set of times which are used in the first and second period. Hence, if $n$ messages are scheduled in a period of size $P$, the trace of an assignment is a pair of subsets of $[P]$ of size $n$. We now show that these traces are produced uniformly by \greedyuniform.

\begin{theorem}
The distribution of traces of assignments produced by \greedyuniform when it succeeds, from instances drawn uniformly at random, is also uniform.
\end{theorem}
\begin{proof}
The proof is by induction on $n$, the number of messages. It is clear for $n=1$,
since the delay of the first message is uniformly drawn and all offsets can be used.
Assume now the theorem true for some $n>1$. \greedyuniform, by induction hypothesis has produced
uniform traces from the first $n$ messages.  Hence, we should prove that, if we draw the delay
of the $n+1^{th}$ message randomly, extending the trace by a random possible offset produces a random distribution on the traces of size $n+1$. 

 If we draw an offset uniformly at random (among all $P$ offsets) and then extend the trace by scheduling the last message at this offset or fail, the distribution over the traces of size $n+1$ is the same as what produces \greedyuniform. Indeed, all offsets which can be used to extend the trace have the same probability to be drawn. Since all delays are drawn independently, we can assume that, given a trace, we first draw an offset uniformly, then draw uniformly the delay of the added message and add it to the trace if it is possible. This proves that all extensions of a given trace are equiprobable. Thus, all traces of size $n+1$ are equiprobable, since they each can be formed from $(n+1)^2$ traces of size $n$ by removing one used time from the first and second period. This proves the induction and the theorem.
\end{proof}

Since \greedyuniform can be seen as a simple random process on traces by Th.~\ref{theorem:uniform}, it is easy to analyze its probability of success.

\begin{theorem}\label{theorem:uniform}
The probability over all instances with $n$ messages and period $P$ that \greedyuniform solves $\pma$ positively is $\displaystyle{\prod_{i=P/2}^{n-1}1 - \frac{\binom{n}{2i-P}}{\binom{P}{i}}}$.
\end{theorem}
\begin{proof}
We evaluate $\Pr(P,n)$ the probability that \greedyuniform fails at the $n^{th}$ step assuming it has not failed before. It is independent of the delay of the $n^{th}$ message. Indeed, the operation which adds one to all times used in the second period is a bijection on the set of traces of size $n-1$. It is equivalent to remove one to the delay of the $n^{th}$ message. We can thus assume that the delay is zero.

Let $S_1$ be the set of times used in the first period by the $n-1$ first messages
and $S_2$ the set of times used in the second period. We can assume that $S_1$ is fixed, since all subsets of the first period are equiprobable and because $S_2$ is independent of $S_1$ (Th.~\ref{theorem:uniform}). There is no possible offset for the $n^{th}$ message, if and only if $S_1 \cup S_2 = [P]$. It means that $S_2$ has been drawn such that it contains $[P] \setminus S_1$. By Th.\ref{theorem:uniform}, $S_2$ is uniformly distributed over all sets of size $n-1$. Hence, the probability that  $[P]  \setminus S_1 \subseteq S_2$  is the probability to draw a set of size $n-1$ which contains $P-n + 1$ fixed elements. This proves $\Pr(P,n) = \frac{\binom{n}{2(n-1)-P}}{\binom{P}{n-1}}$.

From the previous expression, we can derive the probability of success of \greedyuniform by a simple product of 
the probabilities of success $(1 - \Pr(P,i))$ at step $i$, for all $i \leq n$, which proves the theorem. 
\end{proof}


If we fix the load $\lambda = n/P$, we can bound $\Pr(P,n)$ using Stirling formula. The computation yields a constant $C_{\lambda}$
such that $\Pr(P,n) \leq C_{\lambda} \left(\frac{\lambda^{2\lambda}}{(2\lambda -1)^{2\lambda -1}}\right)^P$.
For instance, with $\lambda = 2/3$, $\Pr(P,n) < 1,16 \times (0,84)^P$.

We let $f(\lambda) = \frac{\lambda^{2\lambda}}{(2\lambda -1)^{2\lambda -1}}$.
The derivative of $f$ is strictly positive for $1/2 < \lambda < 1$ and $f(1) = 1$, hence 
$f(\lambda) < 1$ when $\lambda < 1$. By a union bound, the probability that \greedyuniform fails is bounded by $C_{\lambda} \lambda P f(\lambda)^P$. For any fixed $\lambda$, the previous expression goes to zero, exponentially quickly, when $P$ goes to infinity. It explains why \greedyuniform is good in practice for large $P$, even when the load is large. 


 \bibliography{Sources}
%\section{Conclusion}

%In this article, we have proved that there is always a solution to \pma and that it can be found in polynomial time 
%for large $\tau$ and load  $0.4$ or for $\tau = 1$ and load $0.61$. Moreover, the performance of the presented algorithms over average instances are shown to be excellent empirically but also theoretically for \compactpair.
%Hence, we can use the simple algorithms presented here to schedule C-RAN messages \emph{without buffer nor additional latency}, if we are willing to use only half the bandwidth of the shared link. 

%Many questions on \pma are still unresolved, the first one being its complexity.
%Moreover, we plan to adapt the Swap algorithm to the case $\tau > 1$. While the potential
%can be defined in the same way, it is not yet clear that it would help as much in this setting.
%We could also analyze the behavior of the presented algorithms over random instances in the case $\tau > 1$.
%For instance, it is possible to form very long compact tuples over random instances and we could
%use that to obtain an algorithm which works with high probability for load less than $0.5$. 
%First Fit or Meta Offset can easily be adapted to network topologies with more than a single link, but we could also try to adapt Compact Tuples and Swap. Finally, to capture networks carrying several types of messages, it would be interesting to allow for different message sizes, which makes methods using meta-offsets seemingly useless.
%Mélanger les tau: que se passe t-il ?


%\section{Lower bounds} 

%Pour m=6, on peut toujours placer 5 éléments, que dire pour plus grand ?
%Remarque si tous les delais sont différents, on peut les placer, expliquer ça. 
%Example/family of examples for which some greedy alg fail -> facile pour le first fit
%Example/family of examples with a given load such that there are no feasible solution.

\newpage
\appendix

\label{sec:appendix}


In this appendix, we justify the interest of studying $\tau = 1$ and a network with a single shared link.
We also present the results of all algorithms of the paper run over synthetic data and we describe the algorithm \texttt{Compact k-tuples}.


\section{Compact k-tuples}\label{sec:compact}


Recall that a delay $d_i$ is equal to  $d'_i*\tau + r_i$, we call $d'_i$ the \textbf{meta-delay}. The algorithm we describe relies only
on meta-delays and the fact that the $r_i$ are increasing.
A compact $k$-tuple is a sequence of messages $i_1 < \dots < i_k$ with $i_1,\dots,i_k$ increasing, for which meta-offsets can be chosen so that, there is no collision, the messages in the second period are in order $i_1,\dots,i_k$ and for all $l$, $A(i_l) + (d'_{i_l} + 1)\tau = A(i_{l+1}) + d'_{i_{l+1}}\tau$. Scheduling a compact $k$-tuple is choosing a meta-offset for the first message of the tuple, the offsets of the 
other messages are also fixed by this choice.  
The algorithm \texttt{Compact k-tuples} works by scheduling compact $k$-tuples
using meta offsets while possible, then scheduling compact $(k-1)$-tuples and so on until $k=1$.


\begin{lemma}\label{lemma:uple_find}
Given $k + k(k-1)(2k-1)/6$ messages, $k$ of them always form a compact $k$-tuple and we can find them in polynomial time. 
\end{lemma}
\begin{proof}
We assume the messages are sorted according to $r_i$. We prove the lemma by induction on $k$. Lemma~\ref{lemma:pair_find} already proves the lemma for $k=2$.
Now assume that we have found $C$ a compact $(k-1)$-tuple in the first $k-1 + (k-1)(k-2)(2k-3)/6$
messages. Consider the next $(k-1)^2 + 1$ messages: if $k$ of them have the same meta-delay,
then they form a compact $k$-tuple and we are done. Otherwise, there are at least $k$ different meta-delays in those $(k-1)^2 + 1$ messages. Each of the $k-1$ elements of $C$ forbids one possible meta-delay for an additional $k$-th message in $C$. By pigeonhole principle, one of the $k$ messages with distinct meta-delays can be used to extend $C$. We can thus build a compact $k$-tuple from at most $(k-1) + (k-1)(k-2)(2k-3)/6 + (k-1)^2 + 1$ messages, that is $k + k(k-1)(2k-1)/6$ messages which proves the induction.
\end{proof}


\begin{theorem}\label{th:k-tuples}
\texttt{Compact 8-tuples} always solves \pma positively on instances of load less than $4/10$, for instances with $n \geq 205$.
\end{theorem}
\begin{proof}
We use the following fact, which generalizes Lemma~\ref{lemma:pair_forbid}: A $k$-tuples forbids $k+j+1$ offsets in the second period when scheduling a $j$-tuple. 
It enables us to compute a lower bound on the number of scheduled $i$-tuples for $i$ equal $k$ down to $1$ by bounding $\Fmo_i(A)$, the number of forbidden meta-offsets when scheduling compact $i$-tuples in the algorithm.
If we denote by $n_i$ the number of compact $i$-tuples scheduled by the algorithm,
we have the following equation:  $$ \Fmo_i(A) \leq \displaystyle{\sum_{j=i}^k n_j(j*i + j + i+ 1)}.$$
The equation for $n_1$ is slightly better: 
$$ \Fmo(A) \leq \displaystyle{\sum_{j=1}^k n_j(2j + 1)}.$$
A bound on $n_i$ can be computed, using the fact that $A$ can be extended while $\Fmo_i(A) < m$. 
Lemma~\ref{lemma:uple_find} ensures that enough compact $i$-tuples can be built, when $n + n_i - \sum_{i \leq j \leq 8} j*n_j$ is larger than $i + i(i-1)(2i-1)/6$. 
A numerical computation of the $n_i$'s shows that \texttt{Compact 8-tuples} always finds an assignment when the load is less than $4/10$ and for $n \geq 205$.
\end{proof}

The code computing $n_i$ can be found on one author's website\footnote{\url{https://yann-strozecki.github.io/textesmaths.html}}. Th.~\ref{th:k-tuples} is obtained for $k=8$. Taking arbitrary large $k$ and using refined bounds on $\Fmo_i(A)$ is not enough to get an algorithm working for a load of $41/100$ (and it only works from larger $n$). To produce a compact $8$-tuples by Lemma~\ref{lemma:uple_find}, there must be $148$ messages, hence the restriction of $n \geq 205$ to be able to produce enough compact $8$-tuples.
The bound of Lemma~\ref{lemma:uple_find} can be refined, by using better algorithms to construct $k$-tuples, e.g. a simple case analysis shows that, in the worst case, $7$ messages are necessary to construct a compact $3$-tuple and not $8$. However, the restriction on $n$ is not relevant in practice, since on random instances, the probability that $k$ messages do not form a compact $k$-tuples is low, and thus we can build the tuples greedily. For instance, with $P=50\tau$ and thus $n \leq 50$, there is a probability larger than $55\%$ that $8$ random messages form a compact $8$-tuples, $86\%$ for $9$ messages and $96\%$ for $10$ messages.



\section{From Large to Small Messages}\label{sec:reduction}


In this section, we explain how we can trade load or buffering in the network to reduce the size of messages up to $\tau = 1$. This further justifies the interest of Sec.~\ref{sec:small}, where specific algorithms for $\tau = 1$ are given.

\subsection{Message of Size One by Increasing the Load}

We describe here a reduction from an instance of \pma to another one with the same period and number of messages but 
the size of the messages is doubled. This instance is equivalent to an instance with $\tau = 1$, by dividing everything by the message size. Thus we can always assume that $\tau = 1$, if we are willing to double the load.


\begin{theorem}\label{th:double_load}
Let $I$ be an instance of \pma with $n$ messages and load $\lambda$. There is an instance $J$ with $n$ messages of size $1$
and load $2\lambda$ such that an assignment of $J$ can be transformed into an assignment of $I$ in polynomial time.
\end{theorem}
\begin{proof}
From $I = (P,\tau,(d_{0},\dots,d_{n-1}))$, we build $I' = (P, 2\tau, (d_{0}',\dots,d_{n-1}'))$, where $d_i' = d_{i} - (d_{i} \mod 2\tau)$. The instance $I'$ has a load twice as large as $I$.
On the other hand, all its delays are multiples of $2\tau$ hence solving \pma on $I'$ is equivalent to solving it on $I'' = (P/2\tau, 1,(d_{0}/ 2\tau,\dots,d_{n-1} /2\tau))$, as already explained in the proof of Lemma~\ref{lemma:multiple}. 

Let us prove that an assignment $A'$ of $I'$ can be transformed into an assignment $A$ of $I$. 
Consider the message $i$ with offset $A'(i)$, it uses all times between $A'(i)$ and $A'(i) + 2\tau -1$ in the first period and all times between $A'(i) + d_{i} - (d_{i} \mod 2\tau)$ to $A'(i) + 2\tau -1+ d_{i} - (d_{i} \mod 2\tau)$ in the second period. 
If $d_{i} \mod 2\tau < \tau $, we set $A(i) = A'(i)$, and the message $i$ of $I$ is scheduled ``inside'' the 
message $i$ of $I'$, see Fig.~\ref{fig:transf_2tau}. If $\tau \leq d_{i} \mod 2\tau < 2\tau$, then we set 
$A(i) = A'(i) - \tau$. There is no collision in the assignment $A$, since all messages in the second period use
times which are used by the same message in $A'$. In the first period, the messages scheduled by $A$ use either the first
half of the same message in $A'$ or the position $\tau$ before, which is either free in $A'$ or the second half of the times used by another message in $A'$ and thus not used in $A$. 
\end{proof}
\begin{figure}[h]
\begin{center}

\includegraphics[scale=0.7]{transfo2tau}
\end{center}
\caption{Building $I$ from $I'$}
\label{fig:transf_2tau}
\end{figure}

Remark that combining \greedyuniform and Th.~\ref{th:double_load} allows to solve $\pma$ on random instances, with probability one when the number of messages goes to infinity and the load is strictly less than $1/2$. 
This is why we have not presented nor analyzed an algorithm designed for arbitrary $\tau$ on random instances, since any greedy algorithm, relying on minimizing $\Fo(A)$, cannot guarantee anything for load larger than $1/2$. However, in Sec.~\ref{sec:perf_large}, we present \compactfit, a simple greedy algorithm which exhibits good performance on random instances.

\subsection{Trade-off between Latency and Message Size}

The problem \pma is a simplified version of the practical problem we adress, allowing a single degree of freedom for each message: its offset. We may relax it slightly to be more similar to what is studied in~\cite{barth2018deterministic}: we allow buffering a message $i$ during a time $b$ between the two contention points, which corresponds here to changing $d_i$ into $d_i + b$. The quality of the solutions obtained for such a modified instance of \pma are worst since the buffering adds latency to the messages. We now describe how we can make a trade-off between the added latency and the size of the messages, knowing that having smaller messages helps to schedule instances with higher load.

The idea is to buffer all messages so that their $d_i$ have the same
remainder modulo $\tau$. It costs at most $\tau - 1$ of buffering, which is not
so good, since algorithms optimizing the latency do better on random instances, see~\cite{barth2018deterministic}. However, it is much better than buffering for a time $P$, the only value for which we are guaranteed to find an assignment, whatever the instance. When all delays are changed so that $d_i$ is a multiple of $\tau$, we have an easy reduction to the case of $\tau = 1$, by dividing all values by $\tau$, as explained in the proof of Lemma.~\ref{lemma:multiple}.


We can do the same kind of transformation by buffering all messages, so that $d_i$ is a multiple of $\tau / k$. The cost in terms of latency is then at most $\tau / k - 1$ but the reduction yields messages of size $k$.
For small size of messages, it is easy to get better algorithm for \pma, in particular for $\tau = 1$ as we have shown in Sec.~\ref{sec:small}. Here, we show how to adapt \compactpair to the case of $\tau = 2$, to get an algorithm working with higher load.


\begin{theorem}
\compactpair on instances with $\tau =2$ always solves \pma positively on instances of load less than $4/9$.
\end{theorem}
\begin{proof}
We assume w.l.o.g that there are less message with even $d_i$ than odd $d_i$.
We schedule compact pairs of messages with even $d_i$, then we schedule single message with odd $d_i$. The worst case is when there is the same number of the two types of messages. In the first phase, if we schedule
 $n/2$ messages, the number of forbidden offsets is $(2 + 3/2)n/2 = 7n/4$. In the second phase,
 if we schedule $n/2$ additional messages, the number of forbidden offsets is bounded by 
$ (1 + 3/2) n/2  + (1 + 1)n/2 = 9n/4$. Hence, both conditions are satisfied and we can always schedule messages when $n \leq (4/9)m$.
\end{proof}


We may want to add less latency to the message using the longest route. A simple solution is the following: choose the message with the longest route as the reference remainder by subtracting its remainder to every delay. As a consequence, this message needs zero buffering. However, the message with the second longest route may have a remainder of $\tau -1$, thus the worst case increase of total latency is $\tau -1$. 

Another aim would be to minimize the average latency rather than the worst latency.
We prove that we can do the transformation yielding $\tau=1$ while optimizing the average latency. 
 The only degree of freedom in the presented reduction is the choice of the reference remainder since all other delays are then modified to have the same remainder. Let us define the total latency for a choice $t$ of reference time, denoted by $L(t)$, as the sum of buffering times used for the messages, when $t$ has been removed from their delay.
If we sum $L(t)$, from $t=0$ to $\tau-1$, the contribution of each message is $\sum_{i=0}^{\tau-1} i$. Since there are $n$ messages, the sum of $L(t)$ for all $t$ is $n \tau (\tau-1)/2$. There is at least one term of the sum less than its average, hence there is a $t_0$ such that $L(t_0) \leq n (\tau-1)/2$. Hence, the average delay for a message, with $t_0$ as reference is less than $(\tau -1)/2$.

\section{Coherent Routing}\label{sec:coherent}

In this section, we explain how algorithms solving \pma may be used on more complex networks with many contention points.
We consider networks with \textbf{coherent routing}, a common property of telecommunication network (see e.g.~\cite{Schwiebert1996ANA}).
Each message follow a fixed route from an antenna to the data-center, and the coherent routing property implies that two routes
share either nothing or a single path (i.e. a sequence of contiguous links) in the network. See Fig.~\ref{fig:coherent} for a network with and without coherent routing.

In other word, for each pair of message, there is either no common contention point or a single contention point
which is the beginning of their common path, and if there is no collision at this contention point, there is no collision between these two messages further in the network.
The routing is coherent from the antennas to the data-centers, and it is also coherent from the data-centers to the antenna. 
Hence, each pair of messages can be characterized by their two contentions points (on the way forward and on the way back) and the delay between these two points. 


\begin{figure}
\begin{center}
\begin{minipage}[c]{.45\linewidth}
\scalebox{0.5}{

\begin{tikzpicture}
  \SetGraphUnit{5}
    \tikzset{
  EdgeStyle/.append style = {->} }
   \tikzstyle{VertexStyle}=[shape = circle, draw, minimum size = 30pt]
 

  \node (s2) at (0,1.5) {\includegraphics[width = 1cm]{rrh.png}};
  \node (s1) at (0,0) {\includegraphics[width = 1cm]{rrh.png}};
  

   \node (b1) at (10,0.75) {\includegraphics[width = 1cm]{bbu.png}};

 
  
   \node (t1) at (4,0.75) {\includegraphics[width = 1cm]{switch.png}};
    \node (t2) at (6,0.75) {\includegraphics[width = 1cm]{switch.png}};
  \node (t3) at (8,0.75) {\includegraphics[width = 1cm]{switch.png}};
 \node (t4) at (7,2.25) {\includegraphics[width = 1cm]{switch.png}};

 \path (s1) [->,blue,thick] edge (t1);
 \path (s2) [->,green,thick] edge (t1);


 \path ([yshift=-0.5mm]t1.east) [->,blue,thick] edge ([yshift=-0.5mm]t2.west);
 \path (t1.east)  [->,green,thick] edge  (t2.west);
 \path (t2) [->,blue,thick] edge (t3);
 \path (t2) [->,green,thick] edge (t4);
 \path (t4) [->,green,thick] edge (t3);
 \path ([yshift=-0.5mm]t3.east) [->,blue,thick] edge ([yshift=-0.5mm]b1.west);
 \path (t3.east)  [->,green,thick] edge  (b1.west);



\end{tikzpicture}
}



\end{minipage}
\begin{minipage}[c]{.45\linewidth}
\scalebox{0.5}{

\begin{tikzpicture}
  \SetGraphUnit{5}
    \tikzset{
  EdgeStyle/.append style = {->} }
   \tikzstyle{VertexStyle}=[shape = circle, draw, minimum size = 30pt]
 

  \node (s2) at (0,1.5) {\includegraphics[width = 1cm]{rrh.png}};
  \node (s3) at (3,2.25) {\includegraphics[width = 1cm]{rrh.png}};
  \node (s1) at (0,0) {\includegraphics[width = 1cm]{rrh.png}};
  

   \node (b1) at (10,0.75) {\includegraphics[width = 1cm]{bbu.png}};
   \node (b2) at (10,2.25) {\includegraphics[width = 1cm]{bbu.png}};

 
  
   \node (t1) at (4,0.75) {\includegraphics[width = 1cm]{switch.png}};
    \node (t2) at (6,0.75) {\includegraphics[width = 1cm]{switch.png}};
  \node (t3) at (8,0.75) {\includegraphics[width = 1cm]{switch.png}};

 \path (s1) [->,blue,thick] edge (t1);
 \path (s2) [->,green,thick] edge (t1);
 \path (s3) [->,orange,thick] edge (t2);


 \path ([yshift=-0.5mm]t1.east) [->,blue,thick] edge ([yshift=-0.5mm]t2.west);
 \path (t1.east)  [->,green,thick] edge  (t2.west);

 \path ([yshift=0.5mm]t2.east) [->,orange,thick] edge ([yshift=0.5mm]t3.west);
 \path ([yshift=-0.5mm]t2.east) [->,blue,thick] edge ([yshift=-0.5mm]t3.west);
 \path (t2.east)  [->,green,thick] edge  (t3.west);


 \path ([yshift=-0.5mm]t3.east) [->,blue,thick] edge ([yshift=-0.5mm]b1.west);
 \path (t3.east)  [->,orange,thick] edge  (b1.west);
 \path (t3) [->,green,thick] edge (b2);



\end{tikzpicture}
}



\end{minipage}

 \caption{Left, a C-RAN network with a routing not coherent, and right a C-RAN network with coherent routing. The edges with multiple colors represent a single physical link used by several messages.}

\label{fig:coherent}
\end{center}
\end{figure}


The problem $\pma$ can be defined over any networks: the problem is to find an assignment (an offset for each message) such that there is no collision in the network.
The problem $\pma$ (under the name \textsc{PAZL}) is proven to be $\NP$-hard in~\cite{dominique2018deterministic} and the instances used for the reduction
have a coherent routing. However, the algorithms proposed in this article for the single shared link case, can be easily transfered to the
coherent routing case. We prove that we can transform a network with coherent routing into a network with a single shared link such that 
one assignment of the latter is also an assignment of the former.

The transformation is the following: let us consider two contention points $c_1$ and $c_2$ in the network, such that
there is no contention point before $c_1$ nor between $c_1$ and $c_2$. Then, all messages going through $c_2$ but not $c_1$ are 
routed through $c_1$ and $c_2$ is not a contention point anymore, see Fig~\ref{fig:transformation}. Let $l$ be the length of the link
between $c_1$ and $c_2$. Assume that we have rerouted messages in $S$ from $c_2$ to $c_1$, an let $A$ be an assignment for the transformed network,
then the assignment $A'$ defined as for $i\notin S, A'(i) = A(i)$ and for $i \in S, A'(i) = A(i) + l \mod P$ is an assignment for the original network.

\begin{figure}
\begin{center}

\begin{minipage}[c]{.45\linewidth}
\scalebox{0.6}{

\begin{tikzpicture}
  \SetGraphUnit{5}
    \tikzset{
  EdgeStyle/.append style = {->} }
   \tikzstyle{VertexStyle}=[shape = circle, draw, minimum size = 30pt]
 

  \node (s2) at (0,1.5) {\includegraphics[width = 1cm]{rrh.png}};
  \node (s3) at (3,2.25) {\includegraphics[width = 1cm]{rrh.png}};
  \node (s1) at (0,0) {\includegraphics[width = 1cm]{rrh.png}};
  

   \node (b1) at (8,0.75) {\includegraphics[width = 1cm]{bbu.png}};

 
  
   \node (t1) at (4,0.75) {\includegraphics[width = 1cm]{switch.png}};
    \node (t2) at (6,0.75) {\includegraphics[width = 1cm]{switch.png}};


 \path (s1) [->,blue,thick] edge (t1);
 \path (s2) [->,green,thick] edge (t1);
 \path (s3) [->,orange,thick] edge (t2);


 \path ([yshift=-0.5mm]t1.east) [->,blue,thick] edge ([yshift=-0.5mm]t2.west);
 \path (t1.east)  [->,green,thick] edge  (t2.west);

 \path ([yshift=0.5mm]t2.east) [->,orange,thick] edge ([yshift=0.5mm]b1.west);
 \path ([yshift=-0.5mm]t2.east) [->,blue,thick] edge ([yshift=-0.5mm]b1.west);
 \path (t2.east)  [->,green,thick] edge  (b1.west);



\node at (10, 0.75) {\huge $\rightarrow$};
\node at (4,0.3) {$c_1$};
\node at (6, 0.3) {$c_2$};

\end{tikzpicture}
}



\end{minipage}
\begin{minipage}[c]{.45\linewidth}
\scalebox{0.6}{
\hspace{2cm}
\begin{tikzpicture}
  \SetGraphUnit{5}
    \tikzset{
  EdgeStyle/.append style = {->} }
   \tikzstyle{VertexStyle}=[shape = circle, draw, minimum size = 30pt]
 

  \node (s2) at (0,1.5) {\includegraphics[width = 1cm]{rrh.png}};
  \node (s3) at (3,2.25) {\includegraphics[width = 1cm]{rrh.png}};
  \node (s1) at (0,0) {\includegraphics[width = 1cm]{rrh.png}};
  

   \node (b1) at (6,0.75) {\includegraphics[width = 1cm]{bbu.png}};

 
  
   \node (t1) at (4,0.75) {\includegraphics[width = 1cm]{switch.png}};


 \path (s1) [->,blue,thick] edge (t1);
 \path (s2) [->,green,thick] edge (t1);
 \path (s3) [->,orange,thick] edge (t1);



 \path ([yshift=0.5mm]t1.east) [->,orange,thick] edge ([yshift=0.5mm]b1.west);
 \path ([yshift=-0.5mm]t1.east) [->,blue,thick] edge ([yshift=-0.5mm]b1.west);
 \path (t1.east)  [->,green,thick] edge  (b1.west);




\node at (4,0.3) {$c_1$};


\end{tikzpicture}
}



\end{minipage}
 \caption{Transformation of a network $N$ with coherent routing into $N'$ with one less contention point.}

\label{fig:transformation}
\end{center}
\end{figure}


The coherent routing property ensures that applying the transformation to some network $N$ while possible, yields a network $N'$ with a single shared link. Hence, we can apply the algorithms presented in this article to find an assignment for $N'$, which can be transformed into an assignment for $N$. Let us define the load of a general network as $n\tau /P$, then the load of $N'$ is the same as the load of $N$. It proves that there is always an assignment when the load of a network with coherent routing is less than $4/10$ or less than $1/2 + (\sqrt{5}/2 -1)$ and $\tau = 1$. 

Remark that there is a more precise way to define the load for general networks, since the load is not a global notion. 
Let $n_c$ be the number of messages going through the contention point $c$, then the load at $c$ is $n_c\tau/P$. The \textbf{local load} of the network is then defined as the maximum
of the load of the contention points. It is always less than the load defined as $n\tau /P$ and it can be significantly so.
It is easy to see that in a network with coherent routing, any greedy algorithm finds a solution when the local load is less than $1/4$ since we can associate 
exactly two contention points to each message. However, the algorithms of this article do not seem to work for a local load larger than $1/4$, since the bounds on $\Fo$ or $\Fmo$ do not hold anymore. 




\section{Experimental Results}


\subsection{Experimental Results for Large Messages} \label{sec:perf_large}


In this section, the performance on random instances of the algorithms presented in Sec.~\ref{sec:large} is experimentally characterized. The implementation in C of these algorithms can be found on one author's website\footnote{\url{https://yann-strozecki.github.io/textesmaths.html}}. We experiment with several periods and message sizes. For each set of parameters, we try every possible load by changing the number of messages and give the success rate of each algorithm. The success rate is measured on $10000$ instances of \pma generated by drawing uniformly and independently the delays of each message in $[P]$. 

We consider the following algorithms:
\begin{itemize}
  \item \firstfit
  \item \metaoffset
  \item \compactpair
  \item \compactfit
  \item \greedyuniform, the algorithm introduced and analyzed in Sec.~\ref{sec:small}, used for arbitrary $\tau$
  \item \texttt{Exact Resolution} using an algorithm from~\cite{dominique2018deterministic}  
\end{itemize}

\begin{figure}[h]
 \begin{center}
\includegraphics[scale=1]{compactfit}
\end{center}
\caption{An run of \compactfit with $\tau = 2$ and $P=10$, which creates two compact pairs}
\label{fig:compactfit}
\end{figure}

The only algorithm we have yet to describe is \compactfit. The idea is, as for \compactpair, to combine the absence of collision on the first period of \metaoffset and the compactness of assignments given by \firstfit.
The messages are ordered by increasing remainder of delay modulo $\tau$, and each message is scheduled so that it extends an already scheduled compact tuples. 
In other words, it is scheduled using meta offsets, so that using one less for meta offset creates a collision on \emph{the second period}. If it is not possible to schedule the message in that way, the first possible meta-offset is chosen. See Fig.~\ref{fig:compactfit} for an example run of \compactfit. This algorithm is designed to work well on random instances. Indeed, it 
is not hard to evaluate the average size of the created compact tuples, and from that, to prove that \compactfit works with high probability when the load is strictly less than $1/2$.


On a regular laptop, all algorithms terminates in less than a second when solving $10000$ instances with $100$ messages except the exact resolution, whose complexity is exponential in the number of messages (but polynomial in the other parameters). Hence, the exact value of the success rate given by the exact resolution is only available in the experiment with at most $10$ messages (the algorithm cannot compute a solution in less than an hour for twenty messages and high load). 



\begin{minipage}[c]{.49\linewidth}

\begin{center}
\includegraphics[scale=0.275]{100messBig}

\captionof{figure}{Success rates of all algorithms for increasing loads, $\tau = 1000$, $P=100,000$}
\label{fig:100messBig}
\end{center} 
\end{minipage}
\begin{minipage}[c]{.45\linewidth}
\begin{center}  
\includegraphics[scale=0.275]{100messSmall}
\captionof{figure}{Success rates of all algorithms for increasing loads, $\tau = 10$, $P=1,000$}
\label{fig:100messSmall}
\end{center}
\end{minipage}



\begin{minipage}[c]{.49\linewidth}

\begin{center}
\includegraphics[scale=0.275]{10mess}
\end{center}
\captionof{figure}{Success rates of all algorithms for increasing loads, $\tau = 1000$, $P=10,000$}
\label{fig:10mess}
\end{minipage}
\begin{minipage}[c]{.45\linewidth}
\begin{center}
\includegraphics[scale=0.275]{routestau}
\end{center}
\captionof{figure}{Same parameters as in Fig.~\ref{fig:100messBig}, delays uniformly drawn in $[\tau]$}
\label{fig:shortroutes}
\end{minipage}

\medskip

For all sets of parameters, the algorithms have the same relative performances. \metaoffset and \greedyuniform
perform the worst and have almost equal success rate. Remark that they have a $100\%$ success rate for load
less than $1/2$, while it is easy to build an instance of \pma of load $1/3 +\epsilon$ which makes them fail. 
The difference between the worst case analysis and the average case analysis is explained for \greedyuniform, when $\tau = 1$ in Sec.~\ref{sec:small}.

\firstfit performs better than \metaoffset while they have the same worst case. \compactpair, which is the best theoretically also performs well in the experiments, always finding assignments for load of 
$0.6$.  \compactfit, which is similar in spirit to \compactpair but is designed to have a good success rate on random instances is indeed better than \compactpair, when there are enough messages.

As demonstrated by Fig.~\ref{fig:100messBig} and Fig.~\ref{fig:100messSmall}, the size of the messages has little impact on the success rate of the algorithms, when the number of messages and the load are kept the same. Comparing Fig.~\ref{fig:10mess} and Fig.~\ref{fig:100messBig} shows that for more messages, the transition between $100\%$ success rate to $0\%$ success rate happens faster.
Finally, the results of Exact Resolution in Fig.~\ref{fig:10mess} show that the greedy algorithms are far from always finding a solution when it exists. Moreover, we have found an instance with load $0.8$ with no assignment, which gives an upper bound on the highest load for which \pma can always be solved positively.

We also investigate the behavior of the algorithms when the delay of the messages are drawn in $[\tau]$ in Fig.~\ref{fig:shortroutes}. The difference from the case of large delay is that \compactpair and \compactfit are extremely efficient: they always find a solution for $99$ messages. It is expected, since all $d'_i$ are equal in these settings and 
they will both build a $99$-compact tuple and thus can only fail for load $1$.

\subsection{Experimental Results for Small Messages} \label{sec:perf_small}


In this section, the performance on random instances of the algorithms presented in Sec.~\ref{sec:small} is experimentally characterized. The settings are as in Sec.~\ref{sec:perf_large}, with $\tau = 1$. The evaluated algorithms are:

\begin{itemize}
  \item \firstfit
  \item \greedyuniform 
  \item \greedypotential, a greedy algorithm which leverages the notion of potential introduced for Swap. 
  It schedules messages in arbitrary order, choosing the available offset which maximizes the potential of the unscheduled messages
  \item \swapandmove 
  \item \texttt{Exact Resolution}
\end{itemize}

As in Sec.~\ref{sec:perf_large}, the success rate on random instances is much better than the bound given by worst case analysis. In the experiment presented in Fig.~\ref{fig:tau1}, all algorithms succeed on all instances when the load is less than $0.64$. \greedyuniform behaves exactly as proved in Th.~\ref{theorem:uniform}, with a very small variance. The performance of \swapandmove and of its simpler variant \greedypotential, which optimizes the potential in a greedy way, are much better than \firstfit or \greedyuniform. Amazingly, \swapandmove always finds an assignment when the load is less than $0.95$. \swapandmove is extremely close to Exact Resolution, but for $P=10$ and load $0.9$ or $1$, it fails to find some assignments, as shown in Fig.~\ref{fig:tau1-10mess}.

\begin{minipage}[c]{.49\linewidth} 
\begin{center} 
\includegraphics[scale=0.275]{success_tau1} 
\end{center}
\captionof{figure}{Success rates of all algorithms for increasing loads, $\tau = 1$ and $P=100$}
\label{fig:tau1}
\end{minipage}
\begin{minipage}[c]{.45\linewidth} 

\begin{center}
\includegraphics[scale=0.275]{tau110}
\end{center}
\captionof{figure}{Success rates of all algorithms for increasing loads, $\tau = 1$ and $P=10$}
\label{fig:tau1-10mess}
\end{minipage}
 
 \medskip
 Finally, we evaluate the computation times of the algorithms to understand whether they scale to large instances. We present the computation times in Fig.~\ref{fig:timelog} and we choose to consider instances of load $1$, since they require the most computation time for a given size. The empirical complexity of an algorithm is evaluated by a
 linear regression on the function which associates to $\log(n)$, the log of the computation time of the algorithm on $n$ messages.  \firstfit, \greedyuniform and \swapandmove scale almost in the same way, with an empirical complexity slightly below $O(n^2)$, while \greedypotential has an empirical complexity of $O(n^3)$. The empirical complexity corresponds to the worst case complexity we have proved, except for \swapandmove which is in $O(n^3)$ worst case. There are two explanations: most of the messages are scheduled by the fast \firstfit subroutine and most Swap operations improve the potential by more than $1$, contrarily to what is assumed in the worst case analysis.

\begin{figure}
 \begin{center}
\includegraphics[scale=0.275]{log}
\end{center}
\caption{Computation time (logarithmic scale) function of the number of messages of all algorithms on $10000$ instances of load $1$}
\label{fig:timelog}
\end{figure}


\end{document}
