\documentclass[a4paper,10pt]{article}
%\documentclass[10pt, conference, letterpaper]{IEEEtran}
\usepackage[utf8]{inputenc}
\usepackage{xspace}
\usepackage{url}
\usepackage{graphicx,graphics} 
\usepackage{color}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{caption}
\usepackage{longtable}
\usepackage{complexity}
\usepackage{tkz-graph}
\usepackage{float}
\usepackage{tabularx}
\usepackage{setspace}
\usepackage{icomma}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\usepackage{authblk}
\usepackage[colorlinks=true,breaklinks=true,linkcolor=blue]{hyperref}

\newcommand\shortestlongest{\texttt{ShortestLongest}\xspace}
\newcommand\metaoffset{\texttt{MetaOffset}\xspace}
\newcommand\ESCA{\texttt{ESCA}\xspace}
\newcommand\greedydeadline{\texttt{GreedyDeadline}\xspace}
\newcommand\MLS{\texttt{MLS}\xspace}
\newcommand\PMLS{\texttt{PMLS}\xspace}
\newcommand\ASPMLS{\texttt{ASPMLS}\xspace}

\newtheorem{proposition}{Proposition}
\newtheorem{theorem}{Theorem}

\newtheorem{fact}{Fact}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{corollary}{Corollary}

% \renewcommand{\thefootnote}{\*}

\newcommand{\todo}[1]{{\color{red} TODO: {#1}}}
\newcommand\pazl{\textsc{pazl}\xspace}
\newcommand\pall{\textsc{pall}\xspace}
\newcommand\wta{\textsc{wta}\xspace}
\newcommand\pra{\textsc{pra}\xspace}
\newcommand\minpazl{\textsc{minpazl}\xspace}
\newcommand\mintra{\textsc{mintra}\xspace}
%opening
\title{Deterministic Scheduling of Periodic Messages for Low Latency in Cloud RAN}
 

\author[1]{Dominique Barth}
\author[1,2]{Ma\"el Guiraud}
\author[1]{Yann Strozecki}
\affil[1]{David Laboratory, UVSQ}
\affil[2]{Nokia Bell Labs France}

\begin{document}

\maketitle

\begin{abstract}
Cloud-RAN (C-RAN) is an architecture for cellular networks, where processing units, previously attached to antennas, are centralized in data-centers. The main challenge, to fulfill protocol time constraints, is to minimize the latency of the periodic messages sent from the antennas to their processing units and back. We show that statistical multiplexing suffers from high logical latency, due to buffering at nodes to avoid to collisions. Hence, we propose to use a \emph{deterministic} scheme for sending periodic messages \emph{without collision} in the network thus saving the latency incurred by buffering.

We give several algorithms to compute such schemes for star routed networks, a common topology where one link is shared by all antennas. First, we show there is a solution without any buffering when the routes are short or the load is small. When the parameters are unconstrained, and buffering is allowed in processing units, we propose the PMLS algorithm adapted from a classical scheduling method. Experimental results show that even under full load,  PMLS finds a deterministic sending scheme with no logical latency most of the time. Using this algorithm on an artificially loaded network, we design low latency periodic sending schemes which do not disrupt random best effort traffic on the network. This article is an extended version of a previous work presented at ICT~\cite{Guir1806:Deterministic}.
\end{abstract}


\section{Introduction}

Cloud Radio Access Network or C-RAN, have been proposed as a next generation mobile network architecture to reduce energy consumption~\cite{mobile2011c} and more generally the total cost of ownership.
C-RAN is a centralized architecture: each antenna has a Remote Radio Head (RRH) which sends the signal to
a BaseBand Unit (BBU) in a data-center\footnote{Others terminologies exist in the literature. The results of this work are fully compatible with any variation of the C-RAN architecture.}.
The main challenge for this type of architecture is to reach a latency compatible with transport protocols~\cite{ieeep802}. The latency is measured between the sending of a message by an RRH and the reception of the answer, computed by real-time virtualized network functions of a BBU. For example, LTE standards require to process functions like HARQ (Hybrid Automatic Repeat reQuest) in $3$ms~\cite{bouguen2012lte}. In 5G, some services need end-to-end latency as low as $1$ms~\cite{3gpp5g,boccardi2014five}. The specificity of the C-RAN context is not only the latency constraint, but also the periodicity of the data transfer in the \emph{frontaul network} between RRHs and BBUs: frames need to be emitted and received each millisecond~\cite{bouguen2012lte}.
Our aim is to operate a C-RAN on a low-cost shared switched network.
The question we address is the following: is it possible to schedule messages such that they do not collide in the network to avoid latency caused by queuing delays? Eliminating this source of latency leaves us with more time budget for latency due to the physical length of the routes in the network, and thus allows for wider deployment areas.

Let us expose briefly our model: the network topology is modeled by a directed weighted multigraph given by a set of directed paths (routes). A path goes from a node representing the sending of a message by an RRH, to a node representing a BBU and finally to a node representing the reception of the answer by the RRH. Time is discretized and a unit of time or \emph{tic} corresponds to the time needed to transmit a minimal unit of data over the network. To obtain the best possible latency, we want to avoid any buffering in internal nodes of the graph, corresponding to switches of the network. We take advantage of the deterministic nature of the C-RAN messages, called datagrams, i.e. the dates of arrival of the datagrams in the RRHs are known beforehand. In fact, following LTE standard~\cite{bouguen2012lte}, we assume that arrivals of all datagrams are periodic with the same period. We propose to design a \emph{periodic} process to send the messages through the network without collision. By periodic process of period $P$, we mean that the network at times $t$ and $t+P$ is in the exact same state. 

We assume that the route taken by each datagram emmited by some RRH is fixed, and there are no buffering allowed inside the network. Hence, we only have two sets of values that we can choose when building a periodic sending process, called a \emph{periodic assignment}: the time at which each datagram is sent by an RRH in the period, called an \emph{offset}, and the \emph{waiting time} in the BBU before the answer is sent back to the RRH. 


When building a periodic assignment, we must take into account the periodicity which makes many scheduling methods unusable. Not only a datagram must not collide with the datagrams sent by the others BBU/RRH in the same period, but also in the other periods. The latency, that is the time between the emission of a datagram and the complete return of its answer, must be minimized. This means that the only buffering we are allowed -- the waiting time before sending back the answer-- must be small, in particular when the route is long.
% Note that the model is technology agnostic, i.e. it is compatible with an optical network with a fixed packet size. 

 In this article, we assume that all RRHs send datagrams with the same periodicity, but are not synchronized. It means that the datagram of each RRH is available at a different time in the period, given by its offset.
 In current cellular network, the RRHs are synchronized, and simulating our settings would cost a large additional latency, since datagrams should be buffered in their RRHs to honor their offsets. 
Hence, the model we propose should be seen as a suggestion to design future cellular networks, where emissions of the RRHs are not synchronized. It can already model sensor networks in cars, logistic problems in production lines or multiprocessor systems, where periodic messages (or goods) must be scheduled over a bus (or an assembly line), since we have a better handle on when these messages are generated.
 
In this article, we focus on \emph{star routed networks}, which represent a simple but common topology,
where all RRHs share a single link. We give efficient algorithms for two versions of the problems, called 
\pall and \pazl, the second one requiring zero waiting time in the BBU. The algorithms are either polynomial or mildly exponential in $n$, the number of RRHs, and are able to compute periodic sending schemes
for star shaped networks with tens of RRHs. The solutions we obtain are extremely good, with no 
additional latency most of the time, eventhough buffering can only be done in the BBU. For more complex networks and synchronized RRHs, studied in a follow-up work~\cite{guiraud2020synchronized}, we need to allow buffering at each node to obtain good sending schemes.


 \subsection*{Related works}

  We show in this article that statistical multiplexing, even in a fronthaul network with a small load, does not comply with the latency requirements of C-RAN. Therefore, current solutions~\cite{pizzinat2015things,tayq2017real}  use dedicated circuits for the fronthaul. Each end-point (RRH on one side, BBU on the other side) is connected through direct fiber or full optical switches. This architecture is very expensive and hardly scales in the case of a mobile network composed of about $10,000$ base stations. The deterministic approach we propose has gained some traction recently: Deterministic Networking is under standardization in IEEE 802.1 TSN group~\cite{finn-detnet-architecture-08}, as well at IETF DetNet working group~\cite{ieee802}. Several patents on concepts and mechanisms for DetNet have been already published, see for example~\cite{howe2005time,leclerc2016transmission}. 
     
The algorithmic problem we focus on may look like wormhole problems~\cite{cole1996benefit}, but we want to minimize the time lost in buffers and not just to avoid deadlocks. Several graph colorings have been introduced to model similar problems such as the allocation of frequencies~\cite{borndorfer1998frequency}, bandwidths~\cite{erlebach2001complexity} or routes~\cite{cole1996benefit} in a network. Unfortunately, they do not take into account the periodicity of the scheduling and the associated problems are already $\NP$-complete. The only coloring with periodicity is the circular coloring~\cite{zhou2013multiple} but it is not expressive enough to capture our problem. 
The problem \pall on a star routed network is very close to a two flow-shop scheduling problem~\cite{yu2004minimizing} with the additional constraint of periodicity. To our knowledge, all studied periodic scheduling problems are different from \pall that we consider in this article. 
Either the aim is to minimize the number of processors on which the periodic tasks are scheduled~\cite{korst1991periodic,hanen1993cyclic} while our problem correspond to a single processor and a constraint similar to makespan minimization. Or, in cyclic scheduling~\cite{levner2010complexity}, the aim is to minimize the period of a scheduling to maximize the throughput, while our period is fixed. 

The train timetabling problem~\cite{lusby2011railway} and its restriction, the periodic event scheduling problem~\cite{serafini1989mathematical} are generalizations of our problem. Indeed, they take the period as input and can express the fact that two trains (like two messages) should not cross. However, they are much more general: the trains can vary in size, speed, the network can be more complex than a single track and there are precedence constraints. Hence, the numerous variants of train scheduling problems are very hard to solve (and always $\NP$-hard). Thus, some delay is allowed to make the problems solvable and most of the research done~\cite{lusby2011railway} is devising practical algorithms using branch and bound, mixed integer programming, genetic algorithms\dots  In the same spirit, complex scheduling problems for time sensitive networks have also been practically solved, using mixed integer programming~\cite{nayak2017incremental,steiner2018traffic} or an SMT solver~\cite{dos2019tsnsched}.


\subsection*{Outline}

 In Sec.~\ref{sec:def}, we propose a model of the fronthaul network and the periodic sending of datagrams along its routes. Then, \pall is introduced to formalize the problem of sending periodic messages in a network without collision and its variant \pazl, with zero waiting time in the BBU. We present a simple but very common topology, the star routed network, with a single shared duplex link, that is studied in the rest of the article.  In Sec.~\ref{sec:complexity}, we prove that both \pazl and \pall are $\NP$-hard for very restricted classes of graphs, and that their optimization counterparts are hard to approximate. 
 In Sec.~\ref{sec:PAZL}, we study the problem \pazl and several algorithms are proposed: Polynomial time for small load or small routes, or exponential time in the number of routes, based on a compact representation of optimal solutions. We use these algorithms to provide experimental evidences that \pazl can be solved positively when the network is mildly loaded. In Sec.~\ref{sec:PALL}, we propose polynomial time heuristics and an exact FPT algorithm for the general \pall problem and experimentally show that they work well, even in extremely loaded networks. 
Finally, in Sec.~\ref{sec:comparison}, we show that our solution largely outperforms stochastic multiplexing, even using a buffering policy taking into account the latency, or in the presence of additionnal random traffic in the network.



\section{Modeling of the Problem}\label{sec:def}

Let $[n]$ denote the interval of $n$ integers $\{0,\dots,n-1\}$.


	\subsection{Routes and Contention Points}

  	We study a communication network with pairs of source-destination nodes between which messages are sent periodically. The routing between each pair of such nodes is given: a \textbf{route} is a sequence of vertices $(u_0, \ldots , u_{l})$. A vertex appears only once in a route. Each vertex corresponds to a contention point, that is the beginning of a link of the communication network shared by several routes. Hence, a vertex appears in several routes, except the first and last vertex of a route, which are exclusive to the route and represent the source and the destination of the message. When modeling a C-RAN network, the first vertex represents the sending of the message by the RRH and the last vertex represents the reception of the answer in the same RRH. 

  	The set of routes is denoted by ${\cal R}$. A route is interpreted as a directed path in a directed multigraph constituted of all routes, where the sets of arcs of the routes are disjoint. The routes contain no loop nor cycle, since all vertices of a route are different. Thus, the directed multigraph is acyclic. An arc in the multigraph may represent several physical links or nodes of the modeled network, which do not induce contention points. 


  	Each arc $(u,v)$ of a route $r$ is labeled by an integer weight $\omega(r,u)$. It represents the time elapsed between the sending of the message of the route $r$ in $u$ and its reception in $v$.
    The {\bf weight of a vertex} $u_i$ in a route $r=(u_0,\dots,u_l)$ is defined by $\lambda(r,u_i)= \sum\limits_{0 \leq j <i} \omega(r,u_j)$. It is the time needed by a message to go from the first vertex of the route to $u_i$. The \textbf{length} of the route $r$ is defined by $\lambda(r)= \lambda(r,u_l)$. 

  	On each route, we can buffer the message in the BBU. Since the BBU does not correspond to a contention point, we identify the BBU with the next contention point in the route. The set of these contention points with possible buffering is denoted by ${\cal B}$. In our context, with buffering in the BBU only, there is exacly one vertex of each route in $\cal{B}$.
  	A \textbf{routed network}, which models the telecommunication network, is a triple $N = (\cal{R},\,\cal{B},\,\omega)$, see Figure~\ref{fig:graphmodel} for an example. 



\begin{figure}
\centering

	
	\includegraphics[scale=0.7]{graphmodel}\\

\caption{A routed network, each route is represented by a colored path}
\label{fig:graphmodel}
\end{figure} 
 

	 
	 
 	\subsection{Dynamic of Datagrams Transmissions}
	    
 		In this article, we consider a discretized time. The unit of time is called a {\bf tic}. This is the time needed to send an atomic data in a link of the network. We assume that the speed of the links is the same over all the network. One of the authors is developing a prototype of this work based on ethernet base-X~\cite{ieee_8023}, using standard values for the parameters of the network: the size of an atomic data is $64$ bits, the speed of the links is $10$Gbps, and the length of a tic is thus about $6.4$ nanoseconds. 

        In the process we study, a message, called a {\bf datagram}, is sent on each route from the source node. The \textbf{size} of a datagram is an integer, denoted by $\tau$, it is the number of tics needed by a node to emit the full datagram through a link.  In this paper, we assume that $\tau$ is the same for all routes. It is justified by our application to C-RAN, where all source nodes are RRHs sending the same type of message. There is no preemption: Once a datagram has been emitted, it cannot be fragmented during its travel in the network. 

        Let $r=(u_0,\dots,u_l)$ be a route. In order to avoid contention, it is possible to buffer datagrams in the contention points in $\cal{B}$. An \textbf{assignment} $A$ of a routed network $N = (\cal{R},\,\cal{B},\,\omega)$ is a function which associates to each route $r \in \cal{R}$, the pair of integers $A(r) = (o_r,w_r)$.
        The value $o_r$ is the \textbf{offset}, the time at which the datagram is available in the first vertex of $r$. The value $w_r$ is the \textbf{waiting time}: the datagram is buffered 
        for $w_r$ tics in $u_j \in \cal{B}$, the vertex representing the BBU.
 		The \textbf{arrival time} of a datagram in the vertex $u_i$ of $r$, is the first time at which the datagram sent on $r$ reaches $u_i$, and is defined by $t(r,u_i) = \lambda(r,u_i) + o_r $ if 
 		$i < j$ and $t(r,u_i) = \lambda(r,u_i) + o_r + w_r$ otherwise.

 		 Let $u_l$ be the last vertex of the route $r$, the \textbf{transmission time} of the datagram on 
  		$r$ is denoted by $TR(r,A)$ and is equal to $\lambda(r) + w_r$ or equivalently $t(r,u_l) - o_r$. This is the total time taken by the process we study: the sending of the datagram from the RRH to the BBU and the return of the answer back to the RRH. We can decompose this time into $\lambda(r)$, the \emph{physical latency} of the process and $w_r$, the \emph{logical latency}. 
  		We define the \textbf{transmission time} of an assignment $A$ as the worst transmission time of a route: $TR(A) = \displaystyle \max\limits_{r \in {\cal R}} TR(r,A)$. 
        Figure~\ref{fig:datagramtimeline} represents the different events happening during the lifetime  of a datagram  sent on a route $r$.
  		\begin{figure}
  		 \begin{center}
      \includegraphics[width=\textwidth]{time.pdf}
      \end{center}
      \caption{Timeline of a datagram during its travel on a route $r = (s_r,c_1,c_2,t_r)$, with $c_2 \in \cal{B}$}
      \label{fig:datagramtimeline}
  		\end{figure}




 	\subsection{Periodic Emission of Datagrams}

	In the previous section, we have explained how \emph{one} datagram follows its route.
	However, the process we model in this article is \emph{periodic}: for each period of $P$ tics, a datagram is sent, from each source node in the network, at its offset. The process is assumed to be infinite, since it must work for an arbitrary number of periods. For a given route, we use the same offset and waiting time in all periods, for simplicity of implementation in real networks and to make our problem more tractable from a theoretical perspective. Hence, at the same time of two different periods, all messages are at the same position in the network: the assignments built are themselves periodic of period $P$. Thus, we only need to consider the behavior of the datagrams on each node of the network during a single period, and to apply the same pattern to every subsequent period. 
 	Using a different offset for each route corresponds to sending their datagram at a different time in the period. This matches our hypothesis that the emissions of the RRHs need not to be synchronized but they share a common global time, useful for coordination of their emission.

 	Let $A$ be an assignment of a routed network $N = (\cal{R},\,\cal{B},\,\omega)$.
    Let us denote by $[r,u]_{P,\tau}$, the set of tics used by a datagram on the route $r$ at vertex $u$ in a period $P$, that is $[r,u]_{P,\tau} = \{t(r,u) + i \mod P \mid 0 \leq i < \tau \}$. This set of tics depends on $A$,
    but $A$ is omited in the notation, since it is always clear from the context.
    Let us consider two routes $r_1$ and $r_2$, they have a {\bf collision} at the contention point $u$ if and only if $[r_1,u]_{P,\tau} \cap [r_2,u]_{P,\tau} \neq \emptyset$.
    The assignment $A$ is said to be \textbf{valid} if, for all contention points $u$ and routes $r_1$ and $r_2$ containing $u$, \emph{$r_1$ and $r_2$ have no collision} at $u$. 
    The validity of an assignment depends on $P$ the period and $\tau$ the size of the messages,
    thus we say that $A$ is a valid $(P,\tau)$-assignment. When $P$ and $\tau$ clear from the context, 
    we denote $[r,u]_{P,\tau}$ by $[r,u]$ and say that $A$ is a valid assignment. 

     In the example of Figure~\ref{fig:example}, the three routes are given by three different colors. If we let $P = 2$ and $\tau = 1$, then there is a $(2,1)$-periodic valid assignment with waiting times zero by taking $0$ as offset for each route. However, for the same routed network but $P=5$ and $\tau = 2$, there is no solution to the problem with waiting times zero. If we allow $1$ tic of waiting time for one route, we can build the valid assignment $((0,0),(2,1),(0,0))$.


  
\begin{figure}[ht]
    \begin{center}
        \scalebox{0.47}{
		\begin{tikzpicture}
\tikzset{
  LabelStyle/.style = { rectangle, rounded corners, draw,
                       font = \bfseries },
  EdgeStyle/.append style = {->} }
  \SetGraphUnit{5}
  \node[draw,circle] (s3) at (4, 2) {$s_2$}; 
  \node[draw,circle] (s2) at (0, 4) {$s_1$}; 
  \node[draw,circle] (s1) at (0, 6) {$s_0$}; 

  \node[draw,circle] (t3) at (14, 7) {$t_2$}; 
  \node[draw,circle] (t2) at (14, 4) {$t_1$}; 
  \node[draw,circle] (t1) at (14, 2) {$t_0$}; 

   \node[circle] (buf) at (10, 6) {$\cal{B}$};
  \SetVertexNoLabel
  \Vertex[x=2,y=5]{A}
    \Vertex[x=10,y=2]{B}
  \Vertex[x=10,y=5]{C}

  \Vertex[x=6,y=3]{E}
     \draw[dashed] (10,3.5) ellipse  (1cm and 2cm);
  \tikzset{
  EdgeStyle/.append style = {green} }
  \Edge[label = 2](s2)(A)

  \Edge[label = 1](A)(C)
 
  \Edge[label = 2](C)(t2)

  
   \tikzset{
  EdgeStyle/.append style = {red} }
  \Edge[label = 2](s3)(E)
  \Edge[label = 2](E)(C)
  \Edge[label = 3](C)(t3) 

     \tikzset{
  EdgeStyle/.append style = {blue} }
  \Edge[label = 1](s1)(A)
  \Edge[label = 2](A)(E)
  \Edge[label = 2](E)(B)
 \Edge[label = 1](B)(t1)

\end{tikzpicture}

}
  	\end{center}
    \caption{A routed network with $(\textcolor{blue}{(0,0)},\textcolor{green}{(0,0)},\textcolor{red}{(0,0)})$ as a $(2,1)$-periodic assignment and $(\textcolor{blue}{(0,0)},\textcolor{green}{(2,1)},\textcolor{red}{(0,0)})$ as a $(5,2)$-periodic assignment}
    \label{fig:example}
\end{figure}



	\subsection{Periodic Assignment for Low Latency}

      	The period $P$, as well as the size of a message $\tau$ are fixed in our $C-RAN$ settings, but not the buffering policy. Hence, the aim of this article is to find a valid assignment which minimizes the worst latency of the transmissions over the network, that is $TR(A)$. We denote by \mintra the problem of finding the minimal value of $TR(A)$, for a given period, message size and routed network.
      	For simpler hardness proofs and easier reductions, we rather study the decision version of \mintra, that we call \pall for \textbf{P}eriodic \textbf{A}ssignment for \textbf{L}ow \textbf{L}atency. Each route must respect a time limit called a \emph{deadline}. These limits are encoded in a deadline function $d$, which maps to each route $r$ an integer such that $TR(r,A)$ must be less than $d(r)$.
      	We define the \textbf{margin} of a route $r$ of a routed network $N$, for a deadline function $d$ as 
        $\lambda(r) - d(r)$. The margin of a route is the maximum possible waiting time of the route.
       
       % We will prove in Section~\ref{sec:complexity} that the problem \pra is $\NP$-complete, even in restricted settings.
     
      \noindent {\bf Periodic Assignment for Low Latency} 

      \noindent {\bf Input:}  A routed network $N$, the integers $P$, $\tau$ and a deadline function $d$.
      
      \noindent {\bf Question:} does there exist a $(P,\tau)$-periodic assignment of $N$ such that for all $r \in {\cal R}$, $TR(r,A) \leq d(r)$?

	  In the next subsection, this problem is proved to be $\NP$-hard. In Sec.~\ref{sec:PALL}, we propose heuristics solving the search version of \pall (computing a valid assignment), also denoted by \pall for simplicity. In the definition of \pall, we have chosen to bound the transmission time of each route, in particular we can control the worst case latency. It is justified by our C-RAN application with hard constraints on the latency. 

	 We say that an assignment is \textbf{bufferless} when the waiting time of all routes are zero.
	 The assignment can then be seen as a function from the routes to the integers (the waiting time is omited). We consider a restricted version of \pall, requiring to find a bufferless assignment. This is equivalent to using the deadline function $d(r) = \lambda(r)$, that is the 
     transmission time must be equal to the size of the route, which implies $w_r = 0$ for all $r \in \cal{R}$. This problem is called \textbf{P}eriodic \textbf{A}ssignment for \textbf{Z}ero \textbf{L}atency and is denoted by \pazl. Studying \pazl is simpler: in an instance, there is no need to precise $\cal{B}$ in the routed network nor the deadline function and a solution is just an offset for each route.  Moreover, a solution to \pazl is simpler to implement in real telecommunication networks, since we do not need to deal with any buffering at all.

      An unusual property of assignments is that given a routed network and a deadline, we may have a $(P,\tau)$-periodic assignment but no $(P',\tau)$-periodic assignment with $P' > P$: the existence of an assignment is not monotone with regard to $P$.

	\begin{proposition} \label{prop:monotonic}
	 For any odd $P$, there is a routed network with a $(2,1)$-periodic bufferless assignment but no $(P,1)$-periodic bufferless assignment.
	\end{proposition}

	\begin{proof}
      Let us build $N$, a generalization of the routed network given in Fig.~\ref{fig:example}. 
      Let $n$ be an integer, the vertices of the routes are the $v_{i,j}$, $v_i^1$ and $v_i^2$, with $0 \leq i < j <n$. 
      There are $n$ routes denoted by $r_i$, for $i \in [n]$. The route $r_i$ is equal to $(v_i^1,v_{i,1},\dots,v_{i,n-1},v_i^2)$. The weights of the arcs are set so that $\lambda(r_i, v_{i,j}) - \lambda(r_j,v_{i,j})= P$, where $P$ is an odd number smaller than $n$. It is always possible by choosing appropriate values for $\omega(r_i,v_{i,j-1})$ and $\omega(r_j,v_{i-1,j})$. In such a graph, there is no $(P,\tau)$-periodic assignment with zero waiting time, since the problem reduces to finding a $P$-coloring in a complete graph with $n > P$ vertices, the colors being the offsets of the routes.

      If we consider a period of $2$, for all $i \neq j$, $\lambda(r_i, v_{i,j}) - \lambda(r_j, v_{i,j}) \mod 2 = 1$, hence two messages of same offset and size $1$ do not have a collision at $v_{i,j}$. Therefore, the bufferless assignment defined by $A(r_i) = 0$ for all $i \in [n]$ is a valid $(2,1)$-periodic assignment of $N$.      
\end{proof}


      The table of Fig.~\ref{tab:summary} summarizes the main notations used in the paper.
      \begin{figure}
      \begin{center}
   \begin{tabularx}{\textwidth}{|c|X|}
    \hline
     $N = (\cal{R},\,\cal{B},\,\omega)$ & Routed network \\
     \hline
     $n = |\cal{R}|$ & Number of routes\\
     \hline
     $P$ & Period\\
     \hline
     $\tau$ & Size of a message\\
     \hline
     $\omega(r,u)$ & Weight of the arc $(u,v)$ of $r$ \\
     \hline
     $\lambda(r,u_i)$ & Length of the route $r$ up to $u_i$\\
     \hline
     $\lambda(r)$ & Length of the route $r$\\
     \hline
     $ [t(r,u)]$& Times used in the period by the route $r$ at vertex $v$\\
     \hline 
     $A$ & Assignment\\
     \hline 
     $A(r) = (o_r,w_r)$ & Offest and waiting time of the route $r$ given by $A$ \\
     \hline 
     $TR(A,r)$& Transmission time of the route $r$ for the assignment $A$\\
     \hline 
     $TR(A)$& Transmission time of the assignment $A$\\
     \hline
     $d(r)$ & Deadline of the route $r$\\
     \hline

      \end{tabularx}
      \end{center}
      \caption{Summary of the notations of the article.}\label{tab:summary}
      \end{figure}
  	
  	Let us introduce a few parameters quantifying the complexity of a routed network.
	The \textbf{contention depth} of a routed network is the size of the longest route of the network minus one. It is the number of contention points on the route, since the first and the last vertex are private to the route. The \textbf{width} of a vertex is the number of routes which contains it. By definition, 
	the first and last vertex of a route are of width $1$, while all other vertices are of width at least $2$
	(otherwise they can be removed).
	The \textbf{contention width} of a routed network is the maximal width of its vertices. 
	Remark that a $(P,\tau)$-periodic assignment must satisfy that $P/\tau$ is larger or equal to its contention width. Now, let us fix $P$ and $\tau$, for a given vertex of contention width $c$, we define its \textbf{load} as $c\tau/P$. It represents the proportion of the period used by datagrams at this contention point. The load of the routed network is the maximum of the loads of its vertices. A routed network must have a load less or equal to one to admit a valid assignment.



    \subsection{The Star Routed Network} \label{sec:star_routed_network}
  
	In this section, we define a family of simple routed networks modeling a Multipoint-to-Multipoint fronthaul (see figure~\ref{fig:star}), which has been designed for C-RAN \cite{tayq2017real}. Let $N = (\cal{R},\,\cal{B},\,\omega)$ be a routed network, we say it is a \textbf{star routed network} if and only if the routes are $\{r_0,\dots,r_{n-1}\}$, $r_i$ is $(s_i,c_1,c_2,t_i)$ and ${\cal B} = \{ c_2 \}$ (datagrams can wait in $c_2$). Star routed networks have contention depth two but a maximal contention width of $n$. The load on each of the two contention points is thus $n\tau / P$.

	The fronthaul network we model with star routed network has a single shared link, which connects all RRHs at one end and all BBUs at the other end. The links are all \emph{full-duplex}, meaning that the datagrams going from RRHs to BBUs do not interact with those going in the other direction. 
	The two contention points $c_1$ and $c_2$ model the beginning of the shared link (used to go from the RRHs to the BBUs) and the other end of the shared link (used in the other direction). 
	The computation in the BBU of an answer to a datagram on the route $r$ takes some time.
	In the star routed network, this time is encoded in the weight of the arc between $c_1$ and $c_2$ in $r$. The weight $\omega(r,c_1)$ is the time needed to go through the shared link, then to arrive at the BBU, plus the computation time and the time to return to the shared link, see Fig.~\ref{fig:star}.


		Star routed network may seem simplistic, but every network in which all routes share an arc and satisfy a coherent routing condition can be modeled by a star routed network.
		It is common in fronthaul networks, since often all the BBUs are located in the same data-center. In such a situation, we can see the weights of the arcs $(c_1,c_2)$ either as all equals (in that case \pazl is trivial, see Sec.~\ref{sec:PALL}) or different due to the structure of the network inside the data-center and the various hardwares used for the BBUs. 

      
     
  % \begin{minipage}{0.40\linewidth}
    %	\includegraphics[scale=0.5]{starfronthaul}\\
    	


 %  \end{minipage}\hfill
%\begin{minipage}{0.55\linewidth}   

\begin{figure}
\begin{center}
\scalebox{0.4}{

\begin{tikzpicture}
  \SetGraphUnit{5}
    \tikzset{
  EdgeStyle/.append style = {->} }
   \tikzstyle{VertexStyle}=[shape = circle, draw, minimum size = 30pt]
 

  \node (s1) at (0,4) {\includegraphics[width = 1cm]{rrh.png}};
  \node[below right] at (s1.south) {\huge $r_1$};
  \node (s2) at (0,2) {\includegraphics[width = 1cm]{rrh.png}};
  \node[below right] at (s2.south) {\huge $r_2$};
  \node (s3) at (0,0) {\includegraphics[width = 1cm]{rrh.png}};
  \node[below right] at (s3.south) {\huge $r_3$};
  
   \node (t1) at (12,4) {\includegraphics[width = 1cm]{bbu.png}};
  \node[below right] at (t1.south) {\huge $b_1$};
  \node (t2) at (12,2) {\includegraphics[width = 1cm]{bbu.png}};
  \node[below right] at (t2.south) {\huge $b_2$};
  \node (t3) at (12,0) {\includegraphics[width = 1cm]{bbu.png}};
  \node[below right] at (t3.south) {\huge $b_3$};
    \node (c1) at (4,2) {\includegraphics[width = 1cm]{switch.png}};
  \node[below right] at (c1.south) {\huge $c_1$};
    \node (c2) at (8,2) {\includegraphics[width = 1cm]{switch.png}};
  \node[below right] at (c2.south) {\huge $c_2$};
  
 %\SetVertexNoLabel
  %\Vertex[x=4,y=2]{n1}

  %\Edge[label = $5$](s1)(c1)
  %\Edge[label = $7 + 4+4$](c1)(c2)
  %\Edge[label = $3$](s2)(c1)
   %\Edge[label = $7$](s3)(c1)
  %  \Edge[label = $7+3$](c2)(s2p)
 %  \Edge[label = $7+7$](c2)(s3p)
%\Edge[label = $7 + 5$](c2)(s1p)
\path (s1) edge [->] node[anchor=south,inner sep = 0.2cm]{$5$} (c1);

\path (s2) edge [->] node[anchor=south,inner sep = 0.2cm]{$3$} (c1);
\path (s3) edge [->] node[anchor=south,inner sep = 0.2cm]{$7$} (c1);
\path (c2) edge [->] node[anchor=south,inner sep = 0.2cm]{$4$} (t2);
\path (c2) edge [->] node[anchor=south,inner sep = 0.2cm]{$1$} (t3);

\path (c2) edge [->] node[anchor=south,inner sep = 0.2cm]{$2$} (t1);

\path (c1) edge [->] node[anchor=south,inner sep = 0.2cm]{$7$} (c2);


  \Vertex[x=14,y=4, L = {\huge $s_1$}]{s1};
  \Vertex[x=14,y=2, L = {\huge $s_2$}]{s2};
\Vertex[x=14,y=0, L = {\huge $s_3$}]{s3};
\Vertex[x=26,y=4, L = {\huge $t_1$}]{s1p};
\Vertex[x=26,y=2, L = {\huge $t_2$}]{s2p};
\Vertex[x=26,y=0, L = {\huge $t_3$}]{s3p};
\Vertex[x=22,y=2, L = {\huge $c_2$}]{c2};

  \Vertex[x=18,y=2, L = {\huge $c_1$}]{c1}
  
 %\SetVertexNoLabel
  %\Vertex[x=4,y=2]{n1}

  %\Edge[label = $5$](s1)(c1)
  %\Edge[label = $7 + 4+4$](c1)(c2)
  %\Edge[label = $3$](s2)(c1)
   %\Edge[label = $7$](s3)(c1)
  %  \Edge[label = $7+3$](c2)(s2p)
 %  \Edge[label = $7+7$](c2)(s3p)
%\Edge[label = $7 + 5$](c2)(s1p)
\path (s1) edge [->] node[anchor=south,inner sep = 0.2cm]{$5$} (c1);

\path (s2) edge [->] node[anchor=south,inner sep = 0.2cm]{$3$} (c1);
\path (s3) edge [->] node[anchor=south,inner sep = 0.2cm]{$7$} (c1);
\path (c2) edge [->] node[anchor=south,inner sep = 0.2cm]{$7+3$} (s2p);
\path (c2) edge [->] node[anchor=south,inner sep = 0.2cm]{$7+7$} (s3p);

\path (c2) edge [->] node[anchor=south,inner sep = 0.2cm]{$7+5$} (s1p);

\path (c1) edge [->] node[anchor=south,inner sep = 0.2cm]{$7+4+4$} (c2);

\path (c1) edge [->,bend left=30] node[anchor=south,inner sep = 0.2cm]{$7+2+2$} (c2);
\path (c1) edge [->,bend right=30] node[anchor=north,inner sep = 0.2cm]{$7+1+1$} (c2);
   \node[circle] (buf) at (22, 0.5) {$\cal{B}$};
   \draw[dashed] (22,2) ellipse  (0.6cm and 1cm);
  %\draw[->,line width=0.5pt] (5,2.51) parabola bend (7.5,3.5) (10,2.51);
 %\draw[->,line width=0.5pt] (5,1.49) parabola bend (7.5,0.5) (10,1.49);
 

\end{tikzpicture}
}



%\end{minipage}
             \caption{Left, a physical fronthaul network and right, the star routed network modeling a round trip in the fronthaul network}
	         \label{fig:star}
            \end{center}
	         \end{figure}
	         
  When solving \pall or \pazl on a star routed network, a period, a message size and a deadline function are also given. When the period is fixed, if we can modify the deadline function, we can do several assumptions on the parameters of the star routed network without loss of generality. We say that a star routed network is \textbf{canonical}, for a period $P$, if the weights of the arcs between $c_1$ and $c_2$ are in $[P]$ and the others are equal to zero. Hence, $\lambda(r_i)$, the length of a route is equal to the length of its arc $(c_1,c_2)$. Moreover, $\lambda(r_0) = 0$. See Fig.~\ref{fig:canonical} for an example of the canonical star routed network of Fig~\ref{fig:star}.  
  
\begin{figure}
\begin{center}




 \scalebox{0.5}{

\begin{tikzpicture}
  \SetGraphUnit{5}
    \tikzset{
  EdgeStyle/.append style = {->} }
   \tikzstyle{VertexStyle}=[shape = circle, draw, minimum size = 30pt]
   \renewcommand{\VertexLightFillColor}{orange}
  \Vertex[x=0,y=4, L = {\huge $s_1$}]{s1};
  \Vertex[x=0,y=2, L = {\huge $s_2$}]{s2};
\Vertex[x=0,y=0, L = {\huge $s_3$}]{s3};
\Vertex[x=15,y=4, L = {\huge $t_1$}]{s1p};
\Vertex[x=15,y=2, L = {\huge $t_2$}]{s2p};
\Vertex[x=15,y=0, L = {\huge $t_3$}]{s3p};
\Vertex[x=10,y=2, L = {\huge $c_2$}]{c2};

  \Vertex[x=5,y=2, L = {\huge $c_1$}]{c1}
  
 %\SetVertexNoLabel
  %\Vertex[x=4,y=2]{n1}

  %\Edge[label = $5$](s1)(c1)
  %\Edge[label = $7 + 4+4$](c1)(c2)
  %\Edge[label = $3$](s2)(c1)
   %\Edge[label = $7$](s3)(c1)
  %  \Edge[label = $7+3$](c2)(s2p)
 %  \Edge[label = $7+7$](c2)(s3p)
%\Edge[label = $7 + 5$](c2)(s1p)
\path (s1) edge [->] node[anchor=south,inner sep = 0.2cm]{$0$} (c1);

\path (s2) edge [->] node[anchor=south,inner sep = 0.2cm]{$0$} (c1);
\path (s3) edge [->] node[anchor=south,inner sep = 0.2cm]{$0$} (c1);
\path (c2) edge [->] node[anchor=south,inner sep = 0.2cm]{$10$} (s2p);
\path (c2) edge [->] node[anchor=south,inner sep = 0.2cm]{$14$} (s3p);

\path (c2) edge [->] node[anchor=south,inner sep = 0.2cm]{$12$} (s1p);

\path (c1) edge [->] node[anchor=south,inner sep = 0.2cm]{$15$} (c2);

\path (c1) edge [->,bend left=30] node[anchor=south,inner sep = 0.2cm]{$11$} (c2);
\path (c1) edge [->,bend right=30] node[anchor=north,inner sep = 0.2cm]{$9$} (c2);
   \node[circle] (buf) at (10, 0.5) {$\cal{B}$};
   \draw[dashed] (10,2) ellipse  (0.6cm and 1cm);
  %\draw[->,line width=0.5pt] (5,2.51) parabola bend (7.5,3.5) (10,2.51);
 %\draw[->,line width=0.5pt] (5,1.49) parabola bend (7.5,0.5) (10,1.49);
 

\end{tikzpicture}
}

 $d_1 = 25$, $d_2 = 31$, $d_3 = 25$

$\downarrow$


 \scalebox{0.5}{

\begin{tikzpicture}
  \SetGraphUnit{5}
    \tikzset{
  EdgeStyle/.append style = {->} }
   \tikzstyle{VertexStyle}=[shape = circle, draw, minimum size = 30pt]
   \renewcommand{\VertexLightFillColor}{orange}
  \Vertex[x=0,y=4, L = {\huge $s_1$}]{s1};
  \Vertex[x=0,y=2, L = {\huge $s_2$}]{s2};
\Vertex[x=0,y=0, L = {\huge $s_3$}]{s3};
\Vertex[x=15,y=4, L = {\huge $t_1$}]{s1p};
\Vertex[x=15,y=2, L = {\huge $t_2$}]{s2p};
\Vertex[x=15,y=0, L = {\huge $t_3$}]{s3p};
\Vertex[x=10,y=2, L = {\huge $c_2$}]{c2};

  \Vertex[x=5,y=2, L = {\huge $c_1$}]{c1}
  
 %\SetVertexNoLabel
  %\Vertex[x=4,y=2]{n1}

  %\Edge[label = $5$](s1)(c1)
  %\Edge[label = $7 + 4+4$](c1)(c2)
  %\Edge[label = $3$](s2)(c1)
   %\Edge[label = $7$](s3)(c1)
  %  \Edge[label = $7+3$](c2)(s2p)
 %  \Edge[label = $7+7$](c2)(s3p)
%\Edge[label = $7 + 5$](c2)(s1p)
\path (s1) edge [->] node[anchor=south]{$0$} (c1);

\path (s2) edge [->] node[anchor=south,inner sep = 0.2cm]{$0$} (c1);
\path (s3) edge [->] node[anchor=south,inner sep = 0.2cm]{$0$} (c1);
\path (c2) edge [->] node[anchor=south,inner sep = 0.2cm]{$0$} (s2p);
\path (c2) edge [->] node[anchor=south,inner sep = 0.2cm]{$0$} (s3p);

\path (c2) edge [->] node[anchor=south,inner sep = 0.2cm]{$0$} (s1p);

\path (c1) edge [->] node[anchor=south,inner sep = 0.2cm]{$15$} (c2);

\path (c1) edge [->,bend left=30] node[anchor=south,inner sep = 0.2cm]{$11$} (c2);
\path (c1) edge [->,bend right=30] node[anchor=north,inner sep = 0.2cm]{$9$} (c2);
   \node[circle] (buf) at (10, 0.5) {$\cal{B}$};
   \draw[dashed] (10,2) ellipse  (0.6cm and 1cm);
  %\draw[->,line width=0.5pt] (5,2.51) parabola bend (7.5,3.5) (10,2.51);
 %\draw[->,line width=0.5pt] (5,1.49) parabola bend (7.5,0.5) (10,1.49);
 

\end{tikzpicture}
}

 $d_1 = 14$, $d_2 = 21$, $d_3 = 11$

$\downarrow$


 \scalebox{0.5}{

\begin{tikzpicture}
  \SetGraphUnit{5}
    \tikzset{
  EdgeStyle/.append style = {->} }
   \tikzstyle{VertexStyle}=[shape = circle, draw, minimum size = 30pt]
   \renewcommand{\VertexLightFillColor}{orange}
  \Vertex[x=0,y=4, L = {\huge $s_1$}]{s1};
  \Vertex[x=0,y=2, L = {\huge $s_2$}]{s2};
\Vertex[x=0,y=0, L = {\huge $s_3$}]{s3};
\Vertex[x=15,y=4, L = {\huge $t_1$}]{s1p};
\Vertex[x=15,y=2, L = {\huge $t_2$}]{s2p};
\Vertex[x=15,y=0, L = {\huge $t_3$}]{s3p};
\Vertex[x=10,y=2, L = {\huge $c_2$}]{c2};

  \Vertex[x=5,y=2, L = {\huge $c_1$}]{c1}
  
 %\SetVertexNoLabel
  %\Vertex[x=4,y=2]{n1}

  %\Edge[label = $5$](s1)(c1)
  %\Edge[label = $7 + 4+4$](c1)(c2)
  %\Edge[label = $3$](s2)(c1)
   %\Edge[label = $7$](s3)(c1)
  %  \Edge[label = $7+3$](c2)(s2p)
 %  \Edge[label = $7+7$](c2)(s3p)
%\Edge[label = $7 + 5$](c2)(s1p)
\path (s1) edge [->] node[anchor=south]{$0$} (c1);

\path (s2) edge [->] node[anchor=south,inner sep = 0.2cm]{$0$} (c1);
\path (s3) edge [->] node[anchor=south,inner sep = 0.2cm]{$0$} (c1);
\path (c2) edge [->] node[anchor=south,inner sep = 0.2cm]{$0$} (s2p);
\path (c2) edge [->] node[anchor=south,inner sep = 0.2cm]{$0$} (s3p);

\path (c2) edge [->] node[anchor=south,inner sep = 0.2cm]{$0$} (s1p);

\path (c1) edge [->] node[anchor=south,inner sep = 0.2cm]{$0$} (c2);

\path (c1) edge [->,bend left=30] node[anchor=south,inner sep = 0.2cm]{$4$} (c2);
\path (c1) edge [->,bend right=30] node[anchor=north,inner sep = 0.2cm]{$4$} (c2);
   \node[circle] (buf) at (10, 0.5) {$\cal{B}$};
   \draw[dashed] (10,2) ellipse  (0.6cm and 1cm);
  %\draw[->,line width=0.5pt] (5,2.51) parabola bend (7.5,3.5) (10,2.51);
 %\draw[->,line width=0.5pt] (5,1.49) parabola bend (7.5,0.5) (10,1.49);
 

\end{tikzpicture}
}

 $d_1 = 4$, $d_2 = 6$, $d_3 = 6$
 
\end{center}

\caption{Transformation of the star routed network of Figure~\ref{fig:star} to its canonical form, initially with $\tau = 1$, $P=5$, $d_1 = 30$, $d_2 = 34$, $d_3 = 32$.}
\label{fig:canonical}
\end{figure}

  \begin{proposition}\label{prop:canonical}
   Let $I = (N, P, \tau , d)$, with $N = (\cal{R},\,\cal{B},\,\omega)$ a star routed network, then there is 
   $I' = (N', P, \tau , d')$, with  $N' = (\cal{R},\,\cal{B},\,\omega')$ a canonical star routed network, such that:
     $$I \in \pall \Leftrightarrow I' \in \pall \text{ and } I \in \pazl \Leftrightarrow I' \in \pazl$$
  \end{proposition}

  \begin{proof}
  Let us define $\omega'$ and $d'$ from $\omega$ and $d$ in such a way that there is a bijection 
   between valid assignments of $I$ and $I'$, which proves the proposition. In this bijection,
   the offsets $o_i$ for an assignment of $I$ will be mapped to $o'_i$, while the waiting times remain the same.
  
  The routed network $N'$ is equal to $N$ except for the weight function $\omega'$.
  We set the weights of the arcs $(s_i,c_1)$ to zero in $N'$. We obtain the bijection between valid assigments of $I$ and $I'$ by setting $o_i' + \omega(r_i,s_i) = o_i $ and $d'(r_i) = d(i) - \omega(r_i,s_i)$. The weights $\omega'(r_i,c_2)$ are also set to $0$, it does not change the possible collisions
  for an assignment but it changes the transmission time, hence we set $d'(r_i) = d'(r_i) - \omega(r_i,c_2)$
  to preserve the bijection between assignments of $I$ and $I'$. 

  We let $\omega'(r_i,c_1) = \omega(r_i,c_1) \mod P$. Again, it does not change the collisions since computing a possible collision is done modulo $P$. However, we must change $d'$ to be $d'(r_i) = d'(r_i) - \omega(r_i,c_1) + \omega'(r_i,c_1)$.

  Finally, we assume w.l.o.g. that $\omega'(r_0,c_1)$ is the smallest weight among the weights of the arcs
  $(c_1,c_2)$. We let $\omega'(r_i,c_1) = \omega'(r_i,c_1) - \omega'(r_0,c_1)$, which implies that $\omega'(r_0,c_1) = 0$.  All lengths between $c_1$ and $c_2$ change by the same value, hence collisions are not modified. We change $d'(r_i)$ to  $d'(r_i) - \omega'(r_0,c_1)$ for all $i$ so that the constraint on the deadline stay the same.
  \end{proof}

   From now on, we may assume that a star routed network is canonical, using Prop.~\ref{prop:canonical}. To give a instance of \pall where the routed network is a canonical star routed network, it is enough to give the weights of the arcs $(c_1,c_2)$ for all routes, the period, the message size, and $d$ the deadline function. For an instance of \pazl we can also omit $d$.


\section{Hardness of \pall and \pazl}
  \label{sec:complexity}


	We show in this section that \pall is $\NP$-hard by proving $\NP$-hardness for a restricted version: \pazl with $\tau = 1$. We give two proofs that \pazl is $\NP$-complete.
	The first proof works even for contention depth two, but not for star routed networks.
	 For contention depth one, the problem is trivial: either the load is less than one and there is a valid assignment with zero waiting time or there is no valid assignment. 
	 The second proof works for graphs with contention width $2$: the conflicts are locally very simple, but the problem is complex globally nonetheless. Since solving \pall is trivial on trees, it may be interesting to study its complexity on bounded treewidth (or dagwidth) networks, a common property of real networks~\cite{de2011treewidth}.
 

 \begin{theorem}
\pazl is $\NP$-complete on the class of routed networks with contention depth two.
\end{theorem}
 \begin{proof}
 \pazl is in $\NP$ since given an offset for each route in an assignment, it is easy to check whether there are collisions, in linear time in the routed network's size.
 
  Let $H=(V,E)$ be an undirected graph and let $P$ be its maximal degree. We consider the problem to determine whether $H$ is arc-colorable with $P$ or $P+1$ colors. The arc coloring problem is $\NP$-hard~\cite{holyer1981np} and we reduce it to \pazl to prove its $\NP$-hardness. To do that, we define from $H$ a routed network $N = ({\cal R},\, \omega)$ as follows. 

  Let us choose an arbitrary total order $<$ on $V$.
  For each edge $(u,v) \in E$, if $u<v$, there is a route $s_{u,v},u,v,t_{u,v}$ in ${\cal R}$. 
  All these arcs are of weight $0$. Note that, $N$ is of contention depth $2$, as required by the theorem statement. 

  The existence of a $P$-coloring of $H$ is equivalent to the existence of a $(P,1)$-periodic bufferless assignment of $N$. Indeed, a $P$-coloring of $H$ can be seen as a labeling of its edges by the integers in $[P]$. It induces a bijection between $P$-colorings of $H$ and offsets of the routes of ${\cal R}$, which represent the edges of $H$. Having no collision on some vertex $v$ implies that all offsets of routes going through $v$ are different, since all arcs are of weigth $0$. Hence, edges of $H$ incident to $v$, colored by the offsets of a valid assignment are all of distinct colors. Therefore we have reduced arc coloring to \pazl by a polynomial time transformation which concludes the proof. 
 \end{proof}
 
 Remark that we have used weigths of zero for all arcs in the proof. It is a further restriction to the 
 class of graphs for which \pazl is $\NP$-hard. We could ask the weights to be strictly positive, another possible restriction which makes more sense in our model, since weights represent the delay of physical links. Then, we can prove $\NP$-completness using the same proof, by setting all weights to the period $P$.

We now give a hardness proof for routed networks with contention width two but large contention depth. Note that a vertex of contention depth one does not induce a collision and can be removed from the routed network without loss of generality. The presented reduction can be used to prove an inapproximability result. Let \minpazl be the following problem: given a routed network and $\tau$, find the minimal period $P$ such that there is a $(P,\tau)$-periodic bufferless assignment (a positive instance of \pazl). 


\begin{theorem}\label{th:inapprox}
If $\P \neq \NP$, the problem \minpazl on the classe of routed networks of contention width two cannot be approximated in polynomial time within a factor $n^{1-o(1)}$ where $n$ is the number of routes.
\end{theorem}

\begin{proof}
 We reduce the problem of finding the minimal vertex coloring of a graph to \minpazl. Let $H = (U,E)$ be a graph, an instance of the problem of finding a minimal vertex coloring.  We define the routed network $N$ from $H$ as in Prop.\ref{prop:monotonic}.
 
 Let $<$ be an arbitrary total order on $U$. 
 The vertices of $N$ are in the set $\{v_{u,w} \mid (u,w) \in E\} \cup \{u^1, u^2 \mid u \in U\}$. 
 For each vertex $u$ in $H$, there is a route $r_u$ in ${\cal R}$, whose first and last vertices
 are $u^1$ and $u^2$. In between, the route contains all vertices $v_{u,w}$, following the order $<$ on the $w$. The weights of all arcs is zero. By construction, a contention vertex corresponds to an edge and belongs to exactly two routes representing the vertices of the edge, thus $N$ is of contention width $2$.

  The existence of a $P$-coloring of $H$ is equivalent to the existence of a $(P,1)$-periodic assignment of $N$ without waiting time: the offset of a route can be identified with the color of the corresponding vertex. Indeed, since all weigths are zero, the absence of collision at contention point $v_{u,w}$ is equivalent to the fact that the offsets of $r_u$ and $r_w$ are different and reciprocally.

   Therefore, if we can approximate the minimum value of $P$ within some factor such that there is a $(P,1)$-periodic assignment, we could approximate the minimal number of colors needed to color a graph within the same factor. The proof follows from the hardness of approximability of finding a minimal vertex coloring~\cite{zuckerman2006linear}.
\end{proof}

The previous theorem implies that \pazl is $\NP$-complete on the class of routed networks with contention width two. This also underlines the fact that, for general graphs, the best $P$ such that there is a 
$(P,\tau)$-periodic assignment may correspond to a very small load. We can build on the reduction of the previous theorem to prove that \mintra, the problem of minimizing $TR(A)$, is hard to approximate too.

\begin{theorem}
If $\P \neq \NP$, the problem \mintra, on graphs of contention width two, cannot be approximated in polynomial time within a factor $n^{1-o(1)}$ where $n$ is the number of routes.
\end{theorem}

\begin{proof}
We reduce the problem of finding the minimal vertex coloring of a graph to \mintra.
 Let $H = (U,E)$ be a graph, instance of the problem of finding a minimal vertex coloring. 
 We define the routed network $N$ in two steps. 

 Let the elements of $U$ be $u_0,\dots, u_{n-1}$. There are $n$ routes in $N$, denoted by $r_i$ for $i \in [n]$. In their first part, they go from $u_i^0$ to $u_i^1$, through some vertices in $\{v_{i,j,k}\}_{i,j,k \in [n]}$ that we later define. Moreover, $u_i^1 \in \cal{B}$, that is the waiting time is added at $u_i^1$. Assume that $r_i$ has offset $o_i$ and $r_j$ has offset $o_j$ and let us fix the datagram size to $1$ and the period to $n$. If $r_i$ and $r_i$ go through some vertex $v_{i,j,k}$, and  $\lambda(r_i,v_{i,j,k}) = \lambda(r_j,v_{i,j,k}) + k$, then to avoid a collision, the equation $o_i \neq o_j + k \mod n$ must be satisfied. If $r_i$ and $r_j$ go through $v_{i,j,k}$ satisfying the previous constraints for all $k \neq l$, it implies $o_i = o_j + l \mod n$. 
 It is easy to choose the weigths of the two arcs going to $v_{i,j,k}$ to realize the previous condition, whatever the choice of weights of the previous arcs of the routes $r_i$ and $r_j$.

We ensure, using the vertices $v_{i,j,k}$ for $k \neq i-j$,
that $o_{i} = o_{j} + i - j \mod n$. It implies that there is some $o$, such that 
$ o = o_{i} - i \mod n$ for all $i \in [n]$. Now, for each route $r_i$, we set the weight of the
arc going to $v_i^1$, from the last vertex of the form $v_{i,j,k}$ in $r_i$, to be $n-i$.
With this construction, we have ensured, that the datagram of $r_i$ arrives at 
$v_i^1$ at time $o$ modulo $n$, for all $i \in [n]$. 

The second part of the routes, from $v_i^1$ to $v_i^2$ is built exactly as in the proof of Th.~\ref{th:inapprox}. Hence, the waiting time in the vertices $v_i^1$ plays the exact same role as the offset
in the graph of Th.~\ref{th:inapprox}: the valid $(n,1)$-assignments are in bijection with colorings of $H$, the waiting times corresponding to the colors.

Finally, set the weights of the last arc going to $v_i^2$, for all $i \in [n]$, such that, for all $i,j \in [n]^2$, $\lambda(r_i) = \lambda(r_j)$.  Since all routes are of the same size, $TR(A)$ is equal to the maximal waiting time of $A$. Hence, the maximum waiting time is equal to the number of different waiting times required to have a valid assignment. A valid $(n,1)$-assignment which minimizes $TR(A)$ is in bijection with a minimal proper coloring of $H$, which proves the theorem.
\end{proof}
    %\begin{figure}[ht]
   % \centering
   % \scalebox{0.37}{
    %\begin{tikzpicture}
   % \tikzset{
    %  LabelStyle/.style = { rectangle, rounded corners, draw,
	%		  font = \bfseries },
    %  EdgeStyle/.append style = {->} }
    %  \SetGraphUnit{5}
      
      
    %  \node[draw,circle] (s3) at (4, 2) {$s_2$}; 
     % \node[draw,circle] (s2) at (0, 4) {$s_1$}; 
      %\node[draw,circle] (s1) at (0, 6) {$s_0$}; 

      %\node[draw,circle] (t3) at (12, 3) {$t_2$}; 
      %\node[draw,circle] (t2) at (14, 4) {$t_1$}; 
      %\node[draw,circle] (t1) at (10, 2) {$t_0$}; 
      

      %\tikzstyle{VertexStyle}=[shape = circle, draw, minimum size = 20pt]
	%\tikzset{
     % VertexStyle/.append style = {blue} }
	%\Vertex[x=-8,y=3]{1}
	 %     \tikzset{
      %VertexStyle/.append style = {green} }
	  %\Vertex[x=-7,y=5]{2}

	   % \tikzset{
     % VertexStyle/.append style = {red} }
	  %\Vertex[x=-6,y=4]{3}
		%\tikzset{
      %VertexStyle/.append style = {black} }
      
%       
%       \SetVertexNoLabel
%       \Vertex[x=2,y=5]{A}
%       \Vertex[x=4,y=5]{B}
%       \Vertex[x=10,y=5]{C}
%       \Vertex[x=12,y=5]{D}
%       \Vertex[x=6,y=3]{E}
%       \Vertex[x=8,y=3]{F}
%       \tikzset{
%       EdgeStyle/.append style = {green} }
%       \Edge(s2)(A)
%       \Edge ([yshift=-0.5ex]A.east)([yshift=-0.5ex]B.west)
%       \Edge(B)(C)
%       \Edge(C)(D)
%       \Edge(D)(t2)
% 
%       
%       \tikzset{
%       EdgeStyle/.append style = {red} }
%        \Edge ([yshift=-0.5ex]E.east)([yshift=-0.5ex]F.west)
%       \Edge(s3)(E)
%       \Edge(F)(t3) 
% 	\tikzset{
%       EdgeStyle/.append style = {blue} }
%       \Edge(s1)(A)
%      \Edge ([yshift=0.5ex]A.east)([yshift=0.5ex]B.west)
%       \Edge(B)(E)
%              \Edge ([yshift=0.5ex]E.east)([yshift=0.5ex]F.west)
%       \Edge(F)(t1)
%       
% 	\tikzset{
%       EdgeStyle/.append style = {black,-} }
% 
%       \Edge(1)(2)
%       \Edge(1)(3)
%     \node (1) at (-3,4){\Huge $\rightarrow$};
% %     
% %     \node (2) at (-7,0){\Huge H};
% %     \node (3) at (10,0){\Huge G};
%     \end{tikzpicture}
%     }
%     \caption{Reduction from k-coloring to \minpazl}
%     \label{fig:reduction}
%     \end{figure}

	We would like to prove hardness for even more restricted networks, in particular star routed networks.
   The problem \pazl on star routed networks is similar to the minimization of makespan in a two flow-shop with delays (see Sec.~\ref{sec:wtaheuristic}), a problem known to be $\NP$-complete~\cite{yu2004minimizing}. It suggests that \pazl is $\NP$-complete on star routed network, however we have not been able to prove it yet,  because the makespan cannot easily be encoded in \pazl. If we relax the definition of routed network by allowing loops,  we can model a network with a single half-duplex shared link, that is collisions can happen between datagrams going in both directions. This variant can be shown to be $\NP$-complete by a reduction from the subset sum problem, as it is done for a similar problem of scheduling pair of tasks~\cite{orman1997complexity}.
  

\section{Finding Bufferless Assignments} \label{sec:PAZL}
  
  In this subsection, we deal with the problem \pazl on a star routed network: 
  we give several simple heuristics and an exact fixed parameter tractable algorithm, in time exponential in the number of routes only. We show in the experiments of Sec.~\ref{sec:exp_PAZL}, that \pazl can be very often solved positively, in particular for short routes and when the load is moderate. The sensivity to the load has been studied in details in a follow-up work~\cite{guiraud2020scheduling}, in which \pazl is solved for higher load using more involved polynomial time algorithms. 
  
	\subsection{Shortest-longest policy}
    

    We first present a simple policy, which works when the period is large with regard to the lengths of the routes. More generally, it works as soon as the length of the routes modulo the period are close. The algorithm is called \shortestlongest: it sends datagrams on the shared link from the route with the shortest arc $(c_1,c_2)$ to the longest. There is no idle time in the contention point $c_1$, i.e. a datagram goes through $c_1$ right after the previous one has left $c_1$.
      
      \begin{proposition} Let $N$ be a canonical star routed network, with $r$ the longest route. If $n\tau + \lambda(r) \leq P$ then \shortestlongest produces a $(P,\tau)$-periodic bufferless assignment of $N$ in time $O(n\log(n))$.\label{prop:SL}
      \end{proposition}
      \begin{proof}
       By hypothesis, $N$ is in canonical form, hence $\lambda(r,s_i) = 0$ for all $i \in [n]$. Moreover, $\lambda(r_0) = 0$ and we assume the routes are sorted so that, for all $i$, $\lambda(r_i) \leq \lambda(r_{i+1})$ (equivalently $\lambda(r_i,c_1) \leq \lambda(r_{i+1},c_1)$. We fix $P$ and $\tau$. The algorithm \shortestlongest set $o_{r_i} = i\tau$ for all $i \in [n]$. Then, $[t(r_{i}),c_1] = \{i\tau,\dots, (i+1)\tau -1\}$ and since $n\tau < P$, there is no collision on $c_1$. 

       By definition, we have  $[t(r_{i},c_2)] = \{\lambda(r_{i}) + i\tau \mod P, \dots, \lambda(r_{i}) + (i+1)\tau -1 \mod P\}$. By hypothesis, $n\tau + \lambda(r_{n-1}) \leq P$, hence $[t(c_2,r_{i})] = \{\lambda(r_{i}) + i\tau, \dots, \lambda(r_{i}) + (i+1)\tau -1\}$. Since  $\lambda(r_i) \leq \lambda(r_{i-1})$, we have proven that $[t(c_2,r_{i})] \cap [t(c_2,r_{j})]$ for $i \neq j$. Hence, there is no collision on $c_2$ and the $(P,\tau)$-assignment built by \shortestlongest is valid.

 		The complexity of the algorithm is dominated by the sorting of the routes in $O(n\log(n))$. 
      \end{proof}

      If the period is slightly smaller that the bound of Prop.~\ref{prop:SL}, there is a collision with $r_0$ on $c_1$. Hence, this policy is not useful as a heuristic for longer routes, as confirmed by the experimental results of Sec.~\ref{sec:exp_PAZL}. 

   
    \subsection{Greedy Algorithm}
    

     We propose a greedy algorithm to build a periodic assignment, which always finds an assignment when the load is less than $1/3$. Therefore, in the rest of the article we will be only concerned with load larger than $1/3$. In fact, in~\cite{guiraud2020scheduling}, we prove that there is always an assignment for load smaller than $0.4$ and with high probability for load less than $0.5$.

     The idea is to restrict the possible offsets which can be chosen for the routes. It seems counter-intuitive, since it decreases artificially the number of available offsets to schedule new messages. However, it allows reducing the number of forbidden offsets for unscheduled messages. A \textbf{meta-offset} is an offset of value $i\tau$, with $i$ an integer from $0$ to $P / \tau$. We call \metaoffset the greedy algorithm which works as follows: for each message, in the order they are given, it tries all meta-offsets from $0$ to $P/\tau$ as offset for the assignment until one does not create a collision with the current partial assignment. To simplify, we assume that $P$ is a multiple of $\tau$, there is a reduction to this case presented in~\cite{guiraud2020scheduling}.


\begin{theorem}
\metaoffset solves \pazl positively on star routed network and load less than $1/3$. 
The assignment is found in time $O(n^2)$.
\end{theorem}
    \begin{proof}
    Let us prove that \metaoffset always schedules the $n$ routes when the load is less than $1/3$. Let us assume it has built an assignment for the routes $r_0$,$r_1$, $r_{k-1}$, using only meta-offsets. The number of meta-offsets is $P/\tau$ and already $k$ of them are used, hence to avoid collision in $c_1$, we have $P/\tau - k$ choices. We choose an offset among those for the route $r_k$ so that there is no collision in $c_2$. Remark that exactly two consecutive meta-offsets can create a collision between $r_k$ and some route $r_i$ with $i < k$ in $c_2$, since the messages are all of size $\tau$, see Figure~\ref{fig:metaoffset}. Hence, there are at most $2k$ meta-offsets forbidden by collisions in $c_2$. In conclusion, there are at least $P/\tau - k - 2k$ possible meta-offsets so that its choice for $r_k$ does not create a collision in $c_1$ or $c_2$.  \metaoffset terminates and provides a valid bufferless assignment as soon as $P/\tau - 3(n-1) > 0$, which can be rewritten $(n-1)\tau /P > 1/3$: the load is larger than $1/3$.

     This algorithm works in time $O(n^2)$, since for the $k$th route we have to try at most $3k$ meta-offsets before finding a correct one. We can test whether these $3k$ offsets cause a collision in $c_2$ in time $O(k)$ by maintaining an ordered list of the intervals of tics in the period used by already scheduled routes in $c_2$.
     \end{proof}
         
     \begin{figure}
      \begin{center}
      \includegraphics[width=0.7\textwidth]{ex3nt.pdf}
      \end{center}
      \caption{Times used in the period in $c_1$ and $c_2$, when scheduling the $k$th route in \metaoffset}
      \label{fig:metaoffset}
      \end{figure}


% 	\begin{algorithm}[H]
% 	\caption{Greedy assignment}
% 	\begin{algorithmic}
% 	\REQUIRE ${\cal R}_{\cal C}$, period $P$
% 	\ENSURE A P-periodic assignment in p $\leq P$, or FAILURE
% 	\STATE $T$ a table of the macro slots of size $\tau$ in the forward period.
% 	\STATE $L$ a list of free intervals in the backward period%$P2[P]$ slots backward period.
% 	\FORALL{source $s$ in S}
% 
% 	\FORALL{free intervals $[a,b]$ in $L$}
% 	\FORALL{ $a/\tau - \lambda(s) <j< b/\tau - \lambda(s)$ }
% 	\IF{ $T[j] == FREE$}
% 	\STATE $m_{s} \leftarrow j.\tau$
% 	\STATE $T[j] = USED$
% 	\STATE update $[a,b]$ in $L$
% 	\STATE BREAK
% 	\ENDIF
% 	\ENDFOR
% 	\ENDFOR
% % 	
% % 	\IF{No intervals are found for $s_i$}
% % 	\STATE return FAILURE
% % 	\ENDIF
% % 	\ENDFOR
% 
% 	\ENDFOR
% 
% 	\end{algorithmic}
% 	\end{algorithm}
	
This algorithm, contrarily to the previous one, may work well, even for loads higher than $1/3$.
In fact, experimental data in Sec.~\ref{sec:exp_PAZL} suggest that the algorithm finds a solution when the load is less than $1/2$.


\subsection{Compact assignment}

In this section, we show how every bufferless assignment can be put into a canonical form.
We use that form to design an algorithm solving \pazl in fixed parameter tractable time ($\FPT$), with parameter $n$ the number of routes (for more on parametrized complexity see~\cite{downey2012parameterized}). This is justified since $n$ is small in practice, from $10$ to $20$ in our settings, and the other parameters such as $P$, $\tau$ or the weights are large.

Let $({\cal R},\omega)$ be a star routed network and let $A$ be a bufferless $(P,\tau)$-periodic assignment.
We say that that $A$ is \textbf{compact} if there is a route $r_0 \in \cal{R}$ such that the following holds: for all subsets $S\subset \cal{R}$ with $r_0 \notin S$, the bufferless assignment $A'$, defined by $A'(r) = A(r) - 1 \mod P$ if $r \in S$ and $A(r)$ otherwise, is not valid. In other words, an assignment is compact if for all routes $r$ but one, $A(r)$ cannot be reduced by one, that is either in $c_1$ or in $c_2$, there is a route $r'$ using the tics just before $A(r)$. See Fig.~\ref{fig:compact} for an example of a compact assignment, obtained by the procedure of the next proposition. 
  \begin{figure}
      \begin{center} 
      \includegraphics[width=0.7\textwidth]{compacttoassignment.pdf}
      \end{center}
      \caption{Transformation of a bufferless assignment into a compact assignment, following the process of Proposition~\ref{prop:compactification}}
      \label{fig:compact}
      \end{figure}
\begin{proposition}\label{prop:compactification}
Let $N = ({\cal R}, \omega)$ be a star routed network. If there is a $(P,\tau)$-periodic bufferless assignment of $N$, then there is a compact $(P,\tau)$-periodic assignment of $N$.
\end{proposition}
\begin{proof}
Consider $A$ a $(P,\tau)$-periodic bufferless assignment of $N$.
We describe an algorithm which builds a sequence $(r_0,\dots,r_{n-1})$ and a sequence  
$A_i$ of valid bufferless assignments. We denote by $COMP_i = \{ r_j \mid j < i\}$

Let $r_0$ be an arbitrary route of ${\cal R}$ and $A_0 = A$. For $i = 1$ to $n$, we choose $r_i$ as follows.
Let $A_{i} = A_{i-1}$. While there is no collision, for all routes $r \in {\cal R} \setminus COMP_i$, let $A_i(r) = A_i(r) - 1$. Then choose any route $r$ in ${\cal R} \setminus COMP$ such that setting $A_i(r) = A_i(r-1)$ creates a collision and let $r_i = r$. By construction $A_i$ is a valid bufferless assignment, since it is modified only when no collision is created.

We prove by induction on $i$, that $A_i$ is compact when restricted to $COMP_{i+1}$.
For $i = 0$, $|COMP_1| = 1$ and the property is trivially satisfied. Let us consider $A_i$,
by induction hypothesis, since the offsets of routes in $COMP_{i}$ are not modified at step $i$ of the algorithm, $A$ is compact when restricted to $COMP_{i}$. 

 Consider $S \subseteq COMP_i$ which does not contain $r_0$. If $S$ contains
an element of $COMP_{i}$, then $S \setminus {r_i}$ is not empty and by compacity and we cannot decrement all offsets of $S\setminus {r_i}$ without creating a collision. The same property is true for $S$. If $S = \{r_i\}$, then by construction of $r_i$ by the algorithm, removing one from $A_i(r_i)$ creates a collision. Hence,
$A_i$ is compact restricted to $COMP_{i+1}$, which proves the induction and the proposition.
\end{proof}

We now present an algorithm to find a $(P,\tau)$-periodic assignment by trying all compact assignments.

\begin{theorem}\label{th:FPT}
$\pazl \in \FPT$ over star routed networks when parametrized by the number of routes.
\end{theorem}
\begin{proof}
Let $N = ({\cal R},\omega)$ be a canonical star routed network and let $P$ be the period and $\tau$ the size of a datagram. First, remark that for a given assignment and a route $r$ with offset $o_r$, by removing $o_r$ to all offsets, we can always assume that $o_r = 0$. By this remark and Proposition~\ref{prop:compactification}, we need only to consider all \emph{compact assignments} with an \emph{offset $0$} for the route $r_0$. We now evaluate the number of compact assignments and prove that it only depends on $n$ the number of routes to prove the theorem.

 We describe a way to build any compact assignment $A$ by determining its offsets one after the other, which gives a bound on their number and an algorithm to generate them all. We fix an arbitrary total order on ${\cal R}$. Let $r_0$ be the smallest route of $\cal{R}$, its offset is set to $0$ and we let $S = \{r_0\}$,
 $S_1 = \{r_0\}$ and $S_2 = \{r_0\}$. $S$ represent the routes whose offsets are fixed, 
 offsets of unscheduled routes are chosen so that they follow a route of $S_1$ in $c_1$ or a route of $S_2$ in $c_2$.

 At each step, we add an element to $S$: let $r$ be the smallest element of $S_1$, if it is non empty. Then, select any route $r' \in {\cal R} \setminus S$ 
 such that $o_{r'} = o_{r} + \tau$ does not create collision (by construction $o_{r'} = o_{r} + \tau - 1$ does create a collision in $c_1$). Then, we update the sets as follows:
 $S = S \{r'\}$, $S_1 = S_1 \setminus \{r\} \cup \{r'\}$ and $S_2 = S_2 \cup \{r'\}$. If 
 $S_1$ is empty, $r$ is smallest element of $S_2$, and we set $o_{r'} = o_{r} + \tau + \omega(r,c_2) - \omega(r',c_2)$.
 We can also remove $r$ from $S_1$ (or from $S_2$ if $S_1$ is empty) without adding any element to $S$. Remark that the value of the offset of the route added to $S$ is entirely determined by the values of the offsets of the routes in $S$.

 Now, remark that any compact assignment can be built by this procedure, if the proper choice of element to add is made at each step. Hence, this process generates all compact assignments. We now bound the number of compact assignments it can produce. Remark that, when $|S| = i$, we can add any of the $n-i$ routes in ${\cal R} \setminus S$ to $S$. Hence, the number of sequences of choices of routes to add is $n!$ (but some of these sequences can fail to produce a valid assigment). We have not yet taken into account the steps at which an element is removed from either $S_1$ or $S_2$, without adding something to $S$. At each step of the algorithm, we can remove an element or not, there are at most $2n$ steps in the algorithm, hence there are at most $4^n$ sequences of such choices during the algorithm. As a conclusion, there are at most $4^nn!$ compact assignments.

The algorithm to solve \pazl builds every possible compact assignment in the incremental manner described here, and tests at each step whether, in the built partial assginment, there is a collision, which can be done in time linear in the size of $N$. Therefore $\pazl \in \FPT$.
\end{proof}


We call the algorithm described in Theorem~\ref{th:FPT} \textbf{Exhaustive Search of Compact Assignments}
or \ESCA. The complexity of \ESCA is in $O(4^n n!)$. While a better analysis
of the number of compact assignments could improve this bound, the simple star routed networks with all arcs of weights $0$ has $(n-1)!$ compact assignments. Hence, to improve significantly on \ESCA, one should find an even more restricted notion of bufferless assignment than compact assignment.

To make \ESCA more efficient in practice, we make cuts in the search tree used to explore all compact assignments. Consider a set $S$ of $k$ routes whose offsets have been fixed at some point in the search tree. We consider the times used by these routes in $c_1$. It divides the period into $[(a_0,b_0), \dots, (a_{k-1},b_{k-1})]$ where the intervals $(a_i,b_i)$ are the times not used yet in $c_1$. Therefore at most $\displaystyle{ \sum_{i=0}^{k-1} \lfloor(b_{i} -a_i)/\tau\rfloor}$ routes can still send a datagram through $c_1$. If this value is less than $n - k$, it is not possible to create a compact assignment by extending the current one on $S$ and we backtrack in the search tree. The same cut is also used for the contention point $c_2$. These cuts rely on the fact that the partial assignment is wasting bandwith by creating intervals which are not multiples of $\tau$. It helps with instances of large load, which are also the hardest to solve.



   \subsection{Experimental Evaluation}\label{sec:exp_PAZL}
   
   In this section we compare the experimental results of the three presented algorithms.
   Notice that both \metaoffset and Shortest-Longest are polynomial time algorithms but are not always able to find a solution, depending on the load or the size of the routes. On the other hand, \ESCA finds a solution if it exists, but works in exponential time in $n$. We compare the performance of the algorithms in two different regimes: routes are either short with regard to $\tau$, or unrestricted.
   The defaults parameters, derived from the C-RAN context, are the following: the number of routes is $n = 8$, $\tau$ is equal to $2,500$ and $P=19531$ slots. It corresponds to slots of $64$ Bytes, messages of approximately $1$~Mbit and links of bandwidth $10$~Gbit/s when $P$ is one millisecond. 
   The code in C is available on the web page of one author\footnote{\url{https://yann-strozecki.github.io/}} under a copyleft license. The code has been run on a standard $2016$ laptop with a $2.2$~Ghz Intel Core i7 and the sources are compiled with gcc version 7.3.0. All experiments end in at most a few dozen seconds.

       In the following experiments, we illustrate how well the algorithms work with regards to the load. To change the load, we fix the parameters $\tau$ and $n$ and modify the period $P$, which allows for a smooth control of the load and does not impact the execution time of the algorithms.
      

      \paragraph{Short Routes}
      
    


      We consider first routes which are shorter than $\tau$: a message cannot be contained completely in a single arc which is common in our applications. We generate random star routed networks, by drawing uniformly at random the weigths of the arcs between $0$ and $700$, which corresponds to links of less than $5$km between a BBU and an RRH.

      We evaluate the highest load under which a $(P,\tau)$-periodic assignment can be found by each algorithm when we change the number of routes. In our experiment, we generate $1,000$ random instances of \pazl for $1$ to $14$ routes. We represent in Figure~\ref{fig:short} the average of the maximal load for which each algorithm finds a solution. A bound on the maximum load is given by the exhaustive search which always finds a solution if there is one. 
%       The lower and upper bound $n\tau$ and $3n\tau$ are also represented.
      
     
        \todo{je n'ai pas touché le texte, a gauche 8 route a droite 12, ca calcul encore pour 16...}
      \begin{figure}[h]
      \begin{center}
	 \includegraphics[width=0.47\textwidth]{pazlshort8.pdf}
	 \includegraphics[width=0.47\textwidth]{pazlshort12.pdf}
      \end{center}
      \caption{Maximal load averaged over $1,000$ random instances}\label{fig:short}
      \end{figure}
      First, we remark that the exhaustive search finds a solution even when the load is high, especially when there are more routes.
      It justifies the idea to look for an assignment without waiting time, in this short routes regime.
      Second, remark that the Shortest-Longest algorithm is as good as the exhaustive search. While it was expected to be good with short routes, it turns out to be optimal for all the the random star routed networks we have tried. Therefore, we should use it in practical applications with short routes, instead of the exhaustive search which is much more computationally expensive. 
      Finally, note that, on average, the greedy algorithm works when the load is less than $2/3$ which is twice better than the theoretical lower bound. This algorithm seems to depends on the load only and not on the number of routes.
      
        \paragraph{Long routes}
      
      We now want to understand the performance of these algorithms when the size of the routes is unbounded. In this experiment we fix the number of routes to $8$ and the weights of the arcs $(c_1,c_2)$ are drawn following a uniform distribution in $[P]$. We represent in Figure~\ref{fig:long} the percentage of success of each algorithm, for load from $100\%$ down to $40\%$.
      
\begin{figure}[h]

       \begin{center}
      \includegraphics[width=0.47\textwidth]{echec_longues.pdf}
      \end{center}
       
      \caption{Success rate for $8$ routes over $1,000$ random instances}\label{fig:long}
     \end{figure}
      
      In this regime, the performances of Shortest-Longest are abysmal since it depends on the difference between the longest and the smallest route which is large here. On the other hand, the greedy algorithm has a performance not so far from the case of short routes, which is expected since it does not directly depend on the size of the route. In fact, if we do the previous experiment  (for short routes) but with long routes, we find that, on average, the greedy algorithm finds a solution when the load is less than $59\%$.
      
      When the load is larger than $50\%$, the exhaustive search finds more solutions than the greedy algorithms which justifies its use. However, for load larger than $80\%$ there are many instances for which there are no solutions to \pazl.
      It means that with long routes and high load, looking for an assignment without waiting time is far too restrictive. That is why we present algorithms for the general \pall problem in our next section. We will test them on $8$ long routes and a load between $100\%$ and $80\%$, parameters for which, as shown here, there are often no assignment without waiting times.
      
      The computation time of the exhaustive search is bounded by $O(4^nn!)$ as shown in Theorem~\ref{th:FPT}, but it can be much better in practice, either because it finds a solutions quickly or because a large part of the tree of compact assignments is pruned during the algorithm. We study the evolution of the running time  of the algorithm when $n$ grows in the following experiment. The weights of the arcs $(c_1,t_2)$ are drawn following a uniform distribution in $[P]$ and the load is set to $95\%$.  The table of Figure~\ref{fig:table} shows the time before the exhaustive search ends, for $8$ to $16$ routes, averaged on $100$ random star routed networks. This shows that for less than $16$ routes, which corresponds to all current topologies, the algorithm is efficient enough, but we should improve it further to work on more routes.
      
      \begin{figure}[h]
         \begin{center}
         \begin{tabularx}{0.9\textwidth}{|l|X|X|X|X|X|}
    \hline
   $n$ & $8$ & $10$& $12$&$14$& $16$\\
    \hline
   Time (s) & $6.10^{-5}$&$8.10^{-4}$&$2.10^{-2}$& $0.4$& $11$\\
    \hline
      \end{tabularx}
      \end{center}
      \caption{Running time of the exhaustive search.}
      \label{fig:table}
      \end{figure}
      
         \section{Solving \pall on Star Routed Networks}\label{sec:PALL}
    
    In this section, we consider the more general \pall problem on star routed networks. The messages are allowed to wait in the BBUs to yield more possible assignments. Hence, we allow the process time of a route to be greater than the length of the route, but it must be bounded by its deadline.


	\subsection{Simple Star Routed Networks}
		

	Often in real networks, the length of the routes are not arbitrary and we may exploit that to solve \pall easily. For instance all the weights on the arcs $(c_1,c_2)$ are the same if all the BBUs are in the same data-center and all datagrams require the same time to be processed in the BBUs.
	Finding an assignment in that case is trivial: send all messages so that they follow each other without gaps in $c_1$. For instance, one can set $o_i = i\tau$. Since all arcs $(c_1,c_2)$ are of the same weight, the interval of time used in $c_2$ are the same as for $c_1$ up to a translation and there is no collision in $c_2$.

	Another possible assumption would be that all deadlines are larger than the longest route. It may happens when, in the network we modelize, all RRHs are at almost the same distance to the shared link.

	 \begin{proposition}\label{prop:asym}
	 Let $N = ({\cal R}, \omega)$ be a canonical star routed network with $n$ routes, let $P \geq n\tau$ and let $d$ be a deadline function. Let $r_{n-1}$ be the longest route, and assume that for all $r\in {\cal R}$, $\d(r) \ geq \lambda(r_{n-1})$. Then, there is a $(P,\tau)$-periodic assignment for $N$ and $d$ and it can be built in time $O(n)$.
	 \end{proposition}
      \begin{proof}
       The idea is to set the waiting times of all routes so their datagrams behave exactly as the datagram of $r_{n-1}$. The offset of the route $r_i$ is set to $i\tau$, which ensures that there is no collision in $c_1$ as soon as $P \geq n\tau$. The waiting time of the route $r_i$ is $w_i = \lambda(r_{n-1}) - \lambda(r_{i})$.
        
    The time at which the datagrams of $r_i$ arrives in $c_2$ is $t(r_i, c_2) = w_i + i\tau + \lambda(r_{i})$. Substituting $w_i$ by its value, we obtain $t(r_i, c_2) =  i\tau + \lambda(r_{n-1})$.
    Hence, there is no collision in $c_2$. We denote by $A$ the defined assignment. By definition of the transmission time, we have $TR(r_i,A) = w_i + \lambda(r_i) = \lambda(r_{n-1})$. By hypothesis, $d(r_i) \geq \lambda(r_{n-1})$, which proves that the assignment respect the deadlines.

	Finally, the complexity is in $O(n)$ since we have to find the maximum of the length of the $n$ routes and the computation of each $w_i$ is done by a constant number of arithmetic operations.
     \end{proof}
     
    
     \subsection{Two Stages Approach}
     
     We can decompose any algorithm solving \pall on a star routed network in two parts: first set all the offsets of routes so that there is no collision in $c_1$ and then knowing this information find waiting times so that there is no collision in $c_2$ while respecting the deadlines. 

     
     First, we give several heuristics to choose the offsets, which will be experimentally be evaluated in Sec.~\ref{sec:resultsPALL}. We assume that the sar routed network is in canonical form. 
     We send the datagrams through $c_1$ in a compact way (no gap between datagrams). There are $n$ routes, denoted by $r_0, \dots, r_{n-1}$, their offsets are $o_i = \sigma(i) \tau$ for some permutation $\sigma \in \Sigma_n$. We propose to study the following orders $\sigma$: 
	
	\begin{itemize}
	 \item Decreasing Margin (DM): Decreasing order on the margin of the routes.
	 \item Increasing Margin (IM): Increasing order on the margin of the routes. 
	 \item Decreasing Arc (DA): Decreasing order on the length of the arcs $(c_1,c_2)$.
	 \item Increasing Arc (IA): Increasing order on the length of the arcs $(c_1,c_2)$. This sending order yields a $(P,\tau)$ periodic assignment in which the waiting times are zero, if the period is large enough (see proposition \ref{prop:SL}).
	\end{itemize}

    We also propose to fix the offsets of the routes according to some random order.
    If we pack the datagrams as previously, we call the heurisitic of chosing an order
    uniformly at random Random Order (RO). We may also allow some time between two consecutive datagrams in $c_2$. The order of the routes in $c_1$ is still random and we consider two variations. Either the time between two datagrams in $c_1$ is random and we call this heuristic Random Order and Random Spacing (RORS) or the time between two consecutive datagrams is always the same and we call this heuristic Random Order and Balanced Spacing (ROBS).
 	
 	We call \textbf{W}aiting \textbf{T}ime \textbf{A}ssignment or \wta the problem \pall where the offsets of the routes are also given as input. A solution to \wta
 	is a valid assignment such that the offsets coincide with those given in the instance. 

 	In the rest of the section we will study different methods to solve \wta either by polynomial time heuristics or by an FPT algorithm. The methods to solve \wta are then combined with the heuristics proposed to fix the offsets of the routes to solve \pall.  

   
   \subsection{Greedy scheduling of waiting times}

   We now solve the problem \wta, hence we are given a routed network, a deadline function and an offset for each route. The \textbf{release time} of a route 
   is defined as the first time its datagram can go through $c_2$: for a route $r$ with offest $o_r$, it is $\lambda(r,c_2) + o_r$.

    The first algorithm we propose to solve \wta is a greedy algorithm which sets the waiting times in a greedy way, by prioritizing the routes with the earliest deadline to best satisfy the constraints on the process time. We call it \greedydeadline, and it works as follows. Set $t=0$ and $U = \cal{R}$. While there is a route in $U$, find $s \geq t$ the smallest time for which there is $r \in U$ with a release time larger or equal to $s$. If there are several routes in $U$ with a release time larger or equal   \todo{lower or equal non ?}
 to $s$, then $r$ with the smallest deadline is selected and set $w_r = s - \lambda(r,c_2)$, $t = s + \tau$ and $ U = U \setminus \{r\}$.

    This algorithm does not take into account the periodicity, which may create collisions. Let $r_0$ be the first route selected by the algorithm, then $t_0 = t(r_0,c_2)$ is the first time at which a datagram go through $c_2$.
	Then, if all routes $r$ are such that $t(r, c_2) \leq t_0 + P - \tau$, 
	then by construction, there are no collisions on the central arc.
    However, if a route $r$ has a larger $t(r, c_2)$, since we consider everything modulo $P$ to determine collision, it may collide with another route. Therefore we correct \greedydeadline by this simple modification: $s \geq t$ is the smallest time for which there is $r \in U$ with a release time larger or equal to $s$ \emph{such that there is no collision if a datagram goes through $c_2$ at time $s$}. This rule guarantes that if \greedydeadline succeeds to set all waiting times, it finds a solution to \wta, as illustrated in figure~\ref{fig:greedydeadline}. However, it can fails to find the value $s$ at some point because of the constraint on collisions cannot be satisfied. In that case \greedydeadline stops without finding a solution.
    
    \begin{figure}
          \begin{center}
   \begin{tabularx}{0.7\textwidth}{|c|X|X|X|X|X|X|}
    \hline
     Route& $0$ & $1$ & $2$& $3$ & $4$\\
    \hline
    Deadline & $10$ &$15$&$5$&$7$&$30$\\
    \hline
     Release time & $0$ &$2$&$3$&$16$&$17$\\
    \hline
    Waiting time & $0$ &$5$&$1$&$0$&$15$\\
    \hline
      \end{tabularx}
      
      
      \includegraphics[width=0.7\textwidth]{examplegreedy.pdf}
      \caption{A run of \greedydeadline with $P = 20, \tau = 4$.}
           \label{fig:greedydeadline}
      \end{center}
      
    \end{figure}

    %Algorithm~\ref{alg:GD} is the formal description of the previous algorithm. 
    % The function  min\_non\_assigned(eligible\_time) returns the non assigned route with the smallest time eligible time. The function update(t,free\_intervals) removes an interval of size $\tau$ beginning at t, which correspond to the message,  from free\_intervals.
     
    %  \begin{algorithm}\label{alg:GD}
    % \caption{ Greedy deadline ({\bf GD}) }
    % \begin{algorithmic}
    % \REQUIRE A routed network $(G,{\cal R})$, a period $P$, packet size $\tau$, the deadlines $d_i$, the offsets $m_i$
    % \ENSURE $(P,\tau)$-periodic assignment of $(G,{\cal R})$, or failure
    %\STATE  ${\cal H} \leftarrow$ empty set //{\em set of eligible routes with their deadline}
     %   \STATE  free\_ intervals $\leftarrow$ [0,$P$] //{\em list of intervals of free slots}
   
    % \FORALL{route $r_{i}$}
%      \STATE  deadline[$r_i$]  $\leftarrow$  $m_{i} + T_{max} - \Omega(s_i,c_s)$
     %\STATE  eligible\_time[$r_i$] $\leftarrow$ $m_{i} +  \lambda(r_i) + \Omega(c_t,t_i)$
     %  \ENDFOR
       
     %  \WHILE{There is some non-assigned routes}
      % \IF{${\cal H}$ is empty}
     %  \STATE $r_i$ $\leftarrow $ min\_non\_assigned(eligible\_time)
     %  \STATE insert(${\cal H}$,$r_i$,$d_i$).
     %  \ENDIF
      
      % \STATE $r \leftarrow $ extract\_min(${\cal H}$)
      % \STATE t $\leftarrow$ next\_free\_interval(free\_intervals, t) //{\em if there is no more free interval of size $\tau$, the algorithm fails}
      % \STATE $w_i \leftarrow$ t - eligible\_time[$r_i$]
      % \STATE update(t,free\_ intervals)
      % \STATE t $\leftarrow$ t + $\tau$
      % \FORALL{routes $r_i$ with  eligible\_time[$r_i$] $\leq$ t}
 	 %	\STATE insert(${\cal H}$,$r_i$).
      % \ENDFOR
      % \ENDWHILE
     %\end{algorithmic}
     %\end{algorithm}

   


    The complexity of \greedydeadline is in $O(n\log(n))$, using the proper data structures. The set of routes $U$ must be maintained in a binary heap to be able to find the one with smallest deadline in time $O(\log(n))$. To deal with the possible collisions, one maintains a list of the intervals
    of time during which a datagram can go through $c_2$. Each time the waiting time of a route is fixed, an interval is split into at most two intervals in constant time. During the whole algorithm, each element of this list is used at most twice either when doing an insertion or when looking for the next free interval. Hence, the time needed to maintain the list is in $O(n)$. 
  
     \subsection{Earliest Deadline Scheduling}\label{sec:wtaheuristic}
     
     
     The problem \wta is the same as a classical earliest deadline scheduling problem, if we forget the periodicity. Given a set of jobs with \emph{release times} and \emph{deadlines}, schedule all jobs on a single processor, that is choose the time at which they are computed, so that no two jobs are scheduled at the same time. A job is always scheduled after its release time and it must be dealt with before its deadline. Let us call $n$ the number of jobs, the problem can be solved in time $O(n^2\log(n))$~\cite{simons1978fast} when all jobs have the same running time and it gives a solution which minimizes the time at which the last job is scheduled. On the other hand, if the running times are different the problem is $\NP$-complete~\cite{lenstra1977complexity}. 
     The polynomial time algorithm which solves this scheduling problem is similar to \greedydeadline. However, when it fails because a job finishes after its deadline, it changes the schedule of the last messages to find a possible schedule for the problematic job. The change in the scheduling is so that the algorithm cannot fail on the same job a second time except if there is no solution, which proves that the algorithm is in polynomial time.
     
     The problem \wta is the same as this scheduling problem but adding constraints arising from
     the periodicity. The jobs are the routes, the size of a datagram is the running time of a job, 
     and the deadline and the release time are the same in both models.
	 Let us call \textbf{M}inimal \textbf{L}atency \textbf{S}cheduling, denoted by \MLS, the algorithm which transforms an instance of \wta into one of the described scheduling problem to solve it in time $O(n^2\log(n))$ using the algorithm of~\cite{simons1978fast}.
     

     Recall that $t(r,c_2)$ is the time at which the message of $r$ goes through $c_2$. Let us denote by $t_{min}$ and $t_{max}$ the smallest and largest value of $t(r_i,c_2)$ for all $i \in[n]$. When \MLS finds an assignment $A$, it always satisfies $PT(r) < d(r)$ for all $r$. Moreover, by construction \MLS schedules the datagrams without collision if we forget about the periodicity (each route send only one datagram). Let us assume that $t_{max}- t_{min} \leq P -\tau $, then all datagrams go through $c_2$ during a interval of time less than $P$. Hence, when we compute potential collisions modulo $P$, all the relative positions of the datagrams stay the same which implies there is no collision. However, if $t_{max}- t_{min} > P -\tau $, then computing $t(r_i,c_2)$ modulo $P$ for all $i$ could reveal some collisions. Since the scheduling algorithm minimizes $t_{max}$, it tends to find 
     small values for $t_{max} - t_{min}$ and \PMLS may succeed in finding a valid assignment (as shown in Sec.~\ref{sec:resultsPALL}), but not for all instances. 
     
     
     We now present a variant of the previous algorithm, that we call
     \textbf{P} \textbf{M}inimal \textbf{L}atency \textbf{S}cheduling, denoted by \PMLS. The aim is to deal with the periodicity, by modifiying the instance without changing the assignments, so that the chance of finding a solution with $t_{max}- t_{min} \leq P -\tau $ are larger.  Remark that if an instance has a valid assignment, we can guarantee that one route has a waiting time zero in some valid assignment. 
     
     Algorithm \PMLS runs, for each route $r \in \cal{R}$, the algorithm \MLS on an instance defined as follows. Let $RT(r)$ be the release time of $r$, subtract it to all the release times and deadlines of the other routes. Therefore, $RT(r)$ is zero in the instance we build and the waiting time $w_r$ is set to zero. Hence the datagram of $r$ goes through $c_2$ at time $0$ and $t_min = 0$.
     Then, as in Prop.~\ref{prop:canonical}, the instance is modified so that all release times are in $[P-\tau]$. Each release time $RT(r_i)$ is replaced by $RT(r_i) \mod P$ and $d(r_i) = d(r_i) - (RT(r_i) - RT(r_i) \mod P)$. Furthermore, if the release time of a route $r$ is between $P-\tau$ and $P$, we set it to $0$ and $d(r) = d(r) - P$.  The deadline of each route is set to the minimum of its deadline and $P - \tau$. Hence, if \MLS finds a solution for such a modified instance, we have by construction of the instance $t_{max} \leq P -\tau $. Since $t_{min} = 0$, the assignment is valid. Hence, \PMLS
     returns the first assignment it finds when running \MLS for some $r \in \cal{R}$.

     The instance of \wta we have defined in this transformation is equivalent 
     to the original instance, except we have fixed the waiting time of 
     $r$ to be zero. If there is some valid assignment, then at least one route may have waiting time zero, then if \MLS finds an assignment then \PMLS also finds one. Algorithm \MLS is used at most $n$ times, thus the complexity of \PMLS is in $O(n^3\log(n))$. Note that \PMLS is a heuristic and may fail to find a solution even if it exists. It is the case when, for the $n$ modified instances, there is no solution with the $t(r_i,c_2)$ using an interval of time less than $P$ in $c_2$. 



%     \begin{algorithm}[H]
%     \caption{ Minimized Scheduling Periodic (MSP)}
%     \begin{algorithmic}
%     \REQUIRE A routed network $(G,{\cal R})$,a period $P$, packet size $\tau$, $ T_{max}$, the offsets $m_i$
%     \ENSURE $(P-\tau)-$periodic assignment of $(G,{\cal R})$, if it exists
%   
%     \FORALL{route $r_{t_i}$}
%     \STATE  $w_i \leftarrow 0$
%     \STATE period-end $\leftarrow m_{s_i} + \lambda(r_{s_i}) + t(c_t,r_{t_i}) + P$
%     \FORALL{route $r_{t_j}$}
%     \STATE deadline-route$ \leftarrow m_{s_j} + T_{max}-t(c_s,r_{s_j})$
%     \STATE $deadline \leftarrow$ min(deadline-route,period-end)
%     \ENDFOR
%     
%     \STATE Call (MS)
% 
%     
%     \ENDFOR
% 
%     \STATE return the best $(P,\tau)$-periodic assignment, or FAILURE
% 
%     \end{algorithmic}
%     \end{algorithm}

\subsection{FPT algorithms for \wta and \pall}

As a warm-up, we give a simple FPT algorithm for \wta which is practical,
and then we build on it to give a more complicated FPT algorithm for \pall. Unfortunately, the dependency on $n$ the number of routes in the second algorithm is yet too large to be useful in practice. 

\begin{theorem}\label{th:braFPT}
$\wta \in \FPT$ over star routed networks when parametrized by the number of routes.
\end{theorem}
\begin{proof}
 Consider an instance of \wta, which can be characterized by a release time and a deadline for each route.
 We show that we can build a set of instances such that one of these instances has a valid assignment if and only if the original instance has a valid assignment.

  As for \PMLS, for each route $r$, we consider the instance where $r$ has release time and waiting time zero ($RT(r) = w_r = 0$). The release times and deadlines of all routes are modified so that all release times are less than $P$ as in the transformation described for \PMLS. If there is an assignment such that $t_{max} < P-\tau$, then the periodicity does not come into play for this assignment and the algorithm \MLS will find the assignment as explained in Sec.~\ref{sec:wtaheuristic}.

 Now, remark that if there is a valid assignment for an instance with the properties just stated,
 then there is a valid assignment satisfying for all $i$, $t(r_i,c_2) \leq 2P - \tau$.  
 Indeed, if there is a $i$ such that $t(r_i,c_2) \geq 2P$ in a periodic assignment, then we have 
 $w_i = t(r_i,c_2) - \lambda(r_i,c_2) \geq P$. Hence, we can set $w_i = w_i -P \geq 0$ and we still have 
 a valid assignment. Moreover, for all $r_i \neq r$, it is not possible that $2P-\tau < \lambda(r_i,c_2) \leq 2P$, since it would imply a collision between $r$ and $r_i$.
 

From an instance $I$, with the properties of the first paragraph, we define a new instance $I'$ whose valid assignments are a subset of the ones of $I$. Moreover, one of the valid assignments of $I'$ satisfies that for all $i$, $t(r_i,c_2) \leq P - \tau$ and is thus found by \MLS. 
Let us now consider $A$ a valid assignment of $I$, we can assume that $t(r_i,c_2) \leq 2P - \tau$. Let $S$ be the set of routes $r_i$ such that  $P - \tau < t(r_i,c_2) \leq 2P - \tau$. The instance $I'$ is defined by changing, for all route $r \in S$, $RT(r)$ and $d(r)$ to $RT(r) - P$ and $d(r) - P$. Then, by construction $A$ is also a valid assignment of $I'$. Assigment $A$ as a solution of $I'$, satisfies $t(r_i,c_2) \leq P - \tau$ for all $i\in [n]$. 

The FTP algorithm is the following: for each route $r$ build a modified instance as in $\PMLS$.
Then, for each subset $S$ of routes, remove $P$ to the release time and to the deadline of each route in $S$ and run \MLS on the instance so modified. If there is a valid assignment, then we have proved that there is some $S$, such that the instance built from $S$ has a valid assignment with $t(r_i,c_2) \leq P - \tau$ for all $i\in [n]$. Hence, \MLS finds a valid assignment for this instance.
\end{proof}

The algorithm of Theorem~\ref{th:braFPT} has a complexity of $O(2^nn^3\log(n))$. If we consider some valid assignment, the routes $r$ with $t(r,c_2) > P$, must satisfy $t(r,c_2) > P + \tau$ to avoid collision with the first route. Hence, the deadline of these routes must be larger than $P + \tau$. These routes are exactly those that must be put in $S$, hence we can enumerate only the subsets of routes with a deadline larger than $P + \tau$. In practice, only $k$ routes have a deadline larger than $P + \tau$ with $k << n$, and we need only to consider $2^k$ subsets. Let us call this algorithm \textbf{A}ll \textbf{S}ubsets \PMLS, and let us denote it by \ASPMLS.


\begin{theorem}\label{th:pallFPT}
$\pall \in \FPT$ over star routed networks when parameterized by the number of routes.
\end{theorem}
\begin{proof}
 Consider a star routed network, instance of \pall whith a valid assignment. We characterize such a valid assignment by a set of necessary and sufficient linear equations and inequations it must satisfy.  These conditions are expressed on the values $t(r,c_1)$ and $t(r,c_2)$ and setting those value is equivalent to setting the offsets and the waiting times, that is choosing an assignment.

First, we assume the star routed network is canonical. Hence, there is an assignment $A$, such that for all routes $r \in \cal{R}$, $0 \leq t(r,c_1) < P -\tau$ and $0 \leq t(r,c_2) < 2P-\tau$. 
By definition $t(r,c_2) = t(r,c_1) + \omega(r,c_2) + w_r$. Since a waiting time is non-negative, we have $t(r,c_2) \leq t(r,c_1) + \omega(r,c_2)$. 
Now, let $S$ be the set defined as in Theorem~\ref{th:braFPT}, of the routes $r$ such that  $P - \tau < t(r,c_2) \leq 2P - \tau$. We want to guarantee that for $r \in \cal{R}$, $t(r,c_2) \in [P-\tau]$.
To do that, we replace the inequation $t(r,c_2) \leq t(r,c_1) + \omega(r,c_2)$ by $t(r,c_2) \leq t(r,c_1) + \omega(r,c_2) - P$ and $d(r)$ by $d(r) - P$ for all $r \in S$. Remark that the presented linear constraints now depend on $S$, which itself depends on $A$.

 Let $\sigma$ and $\sigma'$ be two permutations of $\Sigma_n$ such that $\sigma$ is the order 
 of the routes $r_0,\dots, r_{n-1}$ according to the value $t(r,c_1)$ and $\sigma'$ according to the value $t(r,c_2)$.  Since all $t(r,c_1)$ and $t(r,c_2)$ are in $[P-\tau]$, we have $t(r,c_1) = t(r,c_1) \ mod P $ and $t(r,c_2) = t(r,c_2) \ mod P $. Hence, we can express the constraints on the absence of collision between routes by adding the following equations to the ones of the previous paragraph:
 
 \begin{itemize}
 	\item for all $i < n-1$, $t(r_{\sigma_{i}},c_1) \leq r_{\sigma_{i+1}},c_1 + \tau)$ (no collision in $c_1$)
 	\item for all $i < n-1$, $t(r_{\sigma'_{i}},c_2) \leq r_{\sigma'_{i+1}},c_2 + \tau)$ (no collision in $c_2$)
 	\item for all $i < n$,  $t(r_{i},c_2) < d(r_i)$ (deadline respected)
 \end{itemize}

Consider now the system of inequations $E_{S,\sigma,\sigma'}$ we have built from $A$.
The values $t(r,c_1)$ and $t(r,c_2)$ given by $A$ satisfy the system by construction. 
Moreover, any solution to these equations yields a valid assignment, because the equation guarantee 
that there is no collision, that the offsets and the waiting times are non-negative and that all routes meet their deadlines. However, a solution of $E_{S,\sigma,\sigma'}$ may be rational, while offsets and waiting times must be integers. We use the following simple fact: $x + e_1 \leq y + e_2$ implies $\lceil x \rceil + e_1 < \lceil y \rceil + e_2$ when $e_1$ and $e_2$ are integers. Since all equations of $E_{S,\sigma,\sigma'}$ have this form, if we take the upper floor of the components of a solution, it is still a solution of $E_{S,\sigma,\sigma'}$ with \emph{integer} values. As a consequence, any solution to $E_{S,\sigma,\sigma'}$ yields a valid assignment of the original instance of \pall.

The algorithm to solve $\pall$ is the following. Build $E_{S,\sigma,\sigma'}$ for all triples $(S,\sigma,\sigma')$. Then, solve each linear system, and if it admits a solution, convert it back into a
valid assignment of the instance of \pall by rounding. There are $2^n$ sets $S$ and $n!$ orders $\sigma$. Thus, $2^n(n!)^2$ systems with $2n$ variables and a bitsize of the same order as the original instance are solved at most. Since solving each system can be done in polynomial time in the size of the instance, it proves that the algorithm is \FPT in $n$. Moreover, it always finds a valid assignment if there is one, since we have shown that from a valid assignment, we can find $(S,\sigma,\sigma')$ for which the values associated to $A$ satisfy$E_{S,\sigma,\sigma'}$.
\end{proof}


    \subsection{Experimental evaluation}
    \label{sec:resultsPALL}
    \subsubsection{Performances on random topologies }
    
    We set the number of routes to $8$ to make comparisons with the results of Sec.~\ref{sec:exp_PAZL} easier. We draw uniformly the weights of the arcs of the star routed network between $0$ and $20,000$. We use \emph{the same deadline} for all routes, which is the most common constraint, when modeling a C-RAN problem: all RRHs have the same latency constraint and all BBUs take the same time to process the answer. 

    We define the {\bf margin} of an instance as the minimum of the margins of the routes. The margin represents the \emph{logical latency} imposed by the communication process without taking into account the physical length of the network, since it cannot be changed. For a given star routed network, choosing the margin or the deadline is the same. However, to compare different star routed networks with different sizes of routes, the margin is more relevant than the deadline. Hence, in our experiments, we vary the margin, from $0$ to $3,000$ tics.
   	We look at two different regimes, a medium load of $80\%$ and a high load of $95\%$.
   	Considering smaller load is not relevant since we can solve the problem using bufferless assignments, as shown in Sec.~\ref{sec:exp_PAZL}. 
   
   	We first try to understand what is the best choice of heuristics for the first stage of the algorithm. The first stage is followed in this experiment by \greedydeadline, the simplest algorithm to solve \wta. In Figure~\ref{fig:success80} and \ref{fig:success95}, the success rate of all possible first stage heuristics to solve \pall is given, function of the margin of the instances. The success rate is an average computed over $10,000$ random star routed networks. For the three heuristics choosing an order at random, we draw $1000$ different random orders and solve each induced \wta instance. The algorithm is considered to succeed as soon as there is a valid assignment for one order. Each random order drawn is used for RO, RORS and ROBS to make the comparison fairer.
   

   TODO: faire un seul tirage, proposer plusieurs tirage après

\begin{figure}[h] 
  \centering
          \includegraphics[width=0.5\textwidth]{1random.pdf}
      \caption{Success rate of different sending orders, $80\%$ load.}
           \label{fig:success80}
     \end{figure}
\begin{figure}[h] 
  \centering
          \includegraphics[width=0.5\textwidth]{departs_gp_25000.pdf}
      \caption{Success rate of different sending orders, $80\%$ load. The random orders are generated $1000$ times.}
           \label{fig:success80}
     \end{figure}
     
\begin{figure}[h] 
  \centering
    \includegraphics[width=0.5\textwidth]{departs_gp_21000.pdf}
      \caption{Success rate of different sending orders, $95\%$ load. The random orders are generated $1000$ times.}
      \label{fig:success95}
          \end{figure}

     First remark that our algorithms often finds assignments with $95\%$ of load and long routes which was not possible when looking for bufferless assignments (see Sec.~\ref{sec:exp_PAZL}). It justifies the interest of studying \pall and not only \pazl.
          
     According to our experiments, sending the messages from the shortest to the longest route or arc does not work well. It corresponds to the policy of Proposition~\ref{prop:SL} which we already know to be bad for \pazl when the routes are long as in this experiment. Sending from the longest to the shortest route or arc works better and it seems that sorting the routes according to the length of the last arc rather than the route is better, at least in a loaded network. 
     
     \todo{ici expérience avec bcp de tirages randoms, pour voir si ça aide}


     Using many random orders is much better than our arbitrary choices of order. 
     With a load of $95\%$, a solution is found with margin $0$ most of the time. The three random order policies have similar performances, but RO gives slightly more solutions than the two others ones, under high load and small margin. Hence, in the following experiments, we will always draw $1,000$ random orders using the policy RO to set the offsets of the assignments.
     
      We now compare the performances of the four different algorithms used in the second stage to set the waiting times. Since \greedydeadline already finds assignments with margin $0$ on mild loads, it is more interesting to focus on the behavior of the algorithms with high load. In Figure~\ref{fig:success21000}, we represent the success rate of the four algorithms with regards to the margin,  computed over $10,000$ random star routed networks generated with the same parameters as previously. 
     
    \begin{figure} [h] 
       \begin{center}
      \includegraphics[width=0.5\textwidth]{retour_21000.pdf}
      \end{center}
      \caption{Success rate of GD, MLS, PMLS and FPT-PMLS, $95\%$ load}
     \label{fig:success21000}
     \end{figure}
     
      The \MLS algorithm performs poorly, worst than \greedydeadline, \PMLS and \ASPMLS, which shows that \emph{taking into account the periodicity} is fundamental.
     Algorithm \greedydeadline is close to $100\%$ success rate for margins larger than $1,500$ while  \PMLS and \ASPMLS algorithms find a solution for more than $99\%$ of the random instances, even \emph{with a margin $0$}. In other words, for very high load and no margin, there are very few instances for which we do not find an assignment. With a margin of $300$, which corresponds to about $15\mu$s of additional delay with the chosen parameters, we always find a solution. 
     
     It turns out that the performances of \PMLS and \ASPMLS are almost identical. Even with a load of $100\%$ and a margin of $0$, we have to draw $100,000$ random instances before finding one which can be solved by \ASPMLS and not by \PMLS. Since \ASPMLS is of exponential complexity in $n$, it may not be relevant to use it within the parameters of this experiment. To verify that, we present the computing time of \PMLS and \ASPMLS for different instance sizes. To stress the algorithms, we set the margin to $0$ and the load to $95\%$. The table of Fig.~\ref{fig:tps_fpt} shows the computation times of \PMLS and \ASPMLS, averaged on $1,000$ instances. 

     
          \begin{figure}[h] 
       \begin{center}
   \begin{tabularx}{0.8\textwidth}{|c|X|X|X|X|X|X|}
    \hline
    \# routes& $8$ & $12$ & $16$& $20$ & $24$\\
    \hline
    \ASPMLS (ms) & $1.88$ &$5.98$&$47.75$&$209.2$&$1815$\\
    \hline
     \PMLS (ms) & $0.07$ &$0.08$&$0.09$&$0.10$&$0.12$\\
    \hline
    Ratio & $27$ &$78$&$523$&$2122$&$14882$\\
    \hline
      \end{tabularx}
      \end{center}
   \caption{Computing time of \PMLS and \ASPMLS with regard to the number of routes}
        \label{fig:tps_fpt}
     \end{figure}
    
  The complexity of both these algorithm depends on the number of routes. As shown in Fig.~\ref{fig:tps_fpt}, the time complexity of \PMLS seems linear on \emph{average}, while its theoretical worst case complexity is cubic. \ASPMLS scales exponentially with the number of routes as expected. Both algorithms are usable for instances of $20$ routes, but for $40$ routes or more \ASPMLS becomes too slow. Since \ASPMLS almost never finds a solution when \PMLS does not and is much slower, one should prefer to use \PMLS. 

    When evaluating the computing time of our method, we should take into account how many random orders are drawn. In our experiment, we draw $1,000$ random orders which may be $1,000$ time slower than using a single fixed order. There is a trade-off between the number of random orders and the success rate. 
    We investigate the success rate of our algorithms with regards to the number of random orders drawn, a load of $95\%$ and a margin $0$. The table of Fig.~\ref{fig:randomdrawing} presents the success rate for different number of sending orders, averaged over $10,000$ instances, for \greedydeadline, \PMLS and \ASPMLS.

         \begin{figure}[h] 
       \begin{center}
   \begin{tabularx}{0.8\textwidth}{|c|X|X|X|X|X|X|}
    \hline
    \# orders& $1$ & $10$ & $100$& $1,000$& $10^{4}$&$10^{5}$\\
    \hline
    \greedydeadline & $0.55$ &$6.05$&$35.44$&$77.43$&$90.1$&$92.4$\\
    \hline
    \PMLS & $82.04$ &$98.84$&$99.71$&$99.80$&$99.83$&$99.83$\\
    \hline
    \ASPMLS & $91.33$&$99.17$&$99.72$&$99.80$ &$99.83$&$99.83$\\
    \hline
      \end{tabularx}
      \end{center}
   \caption{Success rates function of the number of random orders drawn}
        \label{fig:randomdrawing}
     \end{figure}

	First, observe that the better the algorithm to solve $\wta$ is, the less random order it needs in stage one to achieve its best success rate. In particular, \ASPMLS has better results than \PMLS for less than $1,000$ random orders, but not beyond. This further justifies our choice to draw $1,000$ random orders, to obtain the best success rate within the smallest time.

	The number of different orders is $7!= 5,040$ since we have $8$ routes and the solutions are invariant up to a circular permutation of the order. Hence, for $8$ routes it is possible to test every possible order. However the computation time of this exhaustive method scales badly with $n$. The fact that \PMLS and \ASPMLS have already high success rates for $10$ random orders hints that even for a larger number of routes, drawing $1000$ random orders is sufficient to obtain good assignments.


     \subsubsection{Harder Random Topologies}
     
     The previous experiments use instances where the weights of the arcs in the network are uniformly drawn in a large interval. However, it is quite natural to consider that most routes are of roughly the same length or can be arranged in two groups of similar lengths, when the fronthaul network involves two data-centers.
     
     By Prop.~\ref{prop:asym}, there is an assignment with margin equal to the difference
     between the sizes of the routes. Hence, if all routes have almost the same size, the needed margin is small. Moreover, if the routes are drawn in a large interval, then the expected difference between the longest route and the second longest is large. This difference can be seen as a free waiting time for all routes, hence we expect to need little margin in this regime too. As a consequence, the harder instances should be for routes with length drawn in an interval of moderate size compared to the period.
     
     The figures~\ref{fig:1grp} and~\ref{fig:2grp} show the cumulative distribution of the margin needed by PMLS to find an assignment computed on $10,000$ instances.
     Figure~\ref{fig:1grp} represents the success rate of PMLS for instances where length of arcs are drawn in $[P-I,P+I]$, where $I$ goes from $0$ to $3200$. As expected the success rate decreases when the range increases until $I = 800$ and then increases again.  In the the most difficult settings, only $78\%$ of the instances can be solved with margin $0$, and we need a margin of $1,900$ to ensure that PMLS always finds a solution.
    
     In Figure~\ref{fig:2grp}, we do the same experiment, except that the weight of arcs of half of the routes is drawn in $[P-I,P+I]$ and the length of the other half is drawn in $[P/2-I,P/2 + I]$. The situation is the same as for the previous experiment but with better success rates. 

          
              \begin{figure}
       \begin{center}
      \includegraphics[width = 0.5\textwidth]{departs_distrib1Grp.pdf}
      \end{center}
      \caption{Cumulative distribution of the margin needed to find an assignment}
      \label{fig:1grp}   
     \end{figure}    
     
                \begin{figure}
       \begin{center}
      \includegraphics[width = 0.5\textwidth]{departs_distrib2Grp.pdf}
      \end{center}
    \caption{Cumulative distribution of the margin needed to find an assignment with two groups of routes}
      \label{fig:2grp}   
     \end{figure}    
     
     

\section{Periodic Assignments vs Statistical Multiplexing}\label{sec:comparison}

     \subsection{PMLS Compared to Statistical Multiplexing}

     \textbf{TODO:} donner deux politiques de buffering: FIFO, deadline et les comparer à PMLS.


     Now that we have found the best amongst the algorithms solving \pall, we compare its performances against the actual way to manage the messages in a network:  statistical multiplexing, with a FIFO buffer in each node of the network to resolve collisions. For statistical multiplexing, the time at which the messages are sent in the network is not set by the user as in our approach, thus we fix the offsets of each route to some random value.
     Even if this policy seems to work in practice when the network is not too loaded, it does not give any guarantee on the latency. Remark that the process is not periodic, therefore we must measure the process time of each route over several periods if we want to compute its maximum. We choose to simulate it for $1,000$ periods and we have observed that the process time usually stabilizes in less than $10$ periods. The margin is defined as the maximum process time, computed as explained, minus twice the size of the longest route. 
	    
     In Figure~\ref{fig:sto} and Figure~\ref{fig:stobad}, we represent the probability of success of statistical multiplexing and PMLS for different margins. The success rates are computed from $10,000$ star routed networks for each margin. On Figure~\ref{fig:sto}, the arcs of the network are uniformly drawn between $0$ and $20,000$, while on Figure~\ref{fig:stobad}, the arcs of the network are uniformly drawn between $P-800$ and $P+800$. The others parameters of the experiences are the same as previously. We represent the distribution under high and light load for statistical multiplexing and under high load only for PMLS since under light load the margin is always $0$. 
     

    \begin{figure}
       \begin{center}
      \includegraphics[width = 0.45\textwidth]{stochastic.pdf}
       %\input{figures/stochastic}
      \end{center}
      \caption{Probability of success of statistical multiplexing and PMLS for several margins on random topologies}
      \label{fig:sto}   
     \end{figure}    
     
         \begin{figure}
       \begin{center}
      \includegraphics[width = 0.45\textwidth]{stochasticbad.pdf}
       %\input{figures/stochastic}
      \end{center}
      \caption{Probability of success of statistical multiplexing and PMLS for several margins on random topologies where the routes have almost the same size}
      \label{fig:stobad}   
     \end{figure}    
     
    The experiment clearly shows that statistical multiplexing does not ensure a minimal latency. 
    For random topologies, the latency is extremely high when the load is high, with a margin of about $10,000$ for the worst $10\%$ which corresponds to half the period, that is $0.5$ms. Even when the network is lightly loaded, $20\%$ of the instances have a margin of more than $2,000$ while PMLS finds an assignment with margin $0$ in a highly loaded network $99\%$ of the time! 
    
    For hard topologies, statistical multiplexing is slightly worst for small margins and  the same for high margins. The settings are stressful for PMLS, we find an assignment in only $78\%$ of the instances with margin $0$, and it needs a margin of $2,000$ to be sure to find an assignment. However, PMLS still vastly outperforms the statistical multiplexing both for the average margin and for the worst margin. 
    
    For each $1,000$ slots of latency we save from the periodic process, we are able to lengthen the routes of $10$km, which has a huge economical impact. We feel that it strongly justifies the use of a deterministic sending scheme for latency critical applications such as our C-RAN motivating problem.    
     
    \subsection{Periodic Assignment and Random Traffic}
    
    The algorithms proposed in this paper are designed to manage deterministic flows on dedicated networks. In this section, the objective is to understand what happens when the network is not dedicated and the periodic flows are mixed with non-deterministic flows (internet traffic, best effort) managed by statistical multiplexing.

    The algorithms which find an assignment are not designed to take into account best effort traffics. In particular, they often build very compact assignments, with all
    messages following one another in the period, which is very bad from the point of view
    of best efforts packets trying to go through the same contention point.
    Thus, we propose an adaptation of any algorithm solving \pazl, to find assignments where the unused tics are optimally spaced in the period as in Figure~\ref{fig:space}.
   
    
    \subsubsection{Description of statistical multiplexing}
    This section shortly describe how the statistical mulitplexing simulator is implemented.
    The networks are generated in the same way as previously, but since the contention points can receive several messages to send at the same tic, it is possible to buffer somme messages in every contention points of the node. Two policies to manage which message must be sent in first when contention arise.
    
    The first one is the \texttt{FIFO} (First In First Out) policy, the trivial one, which consists in sending the messages in the same order in which they reached the contention point.

    The second proposed policy is called \texttt{LTE} (Longest Time Elapsed) and consists in sending first the message which has almost spent the largest time in the network between all buffered messages
    
    \subsubsection{Adapted \ASPMLS for BE traffic}

    Dire qu'on se place pour des loads pourlesquelles ASPMLS trouve toujours une solution.
    On donne ensuite l'algo, pour une instance donnée () trouver un P,tau' assignment
    pour le plus grand tau' >= tau.

    Puis on retransforme l'assignement en P,tau assignemet ce qui garanti au moins 
    tau'-tau tics entre deux messages dans un point de contention.

    Faire une expérience sur 1000 instances, 60 pour cent de charge, 8 routes
    pour savoir quelle est la taille du + gd tau trouvé en moyenne -> mieux la distribution
    de ce +gd tau. Ça va nous dire que l'algo réussi bien à espacer (avant de voir l'effet sur la latence).


    Since \ASPMLS always finds an optimal solution for deterministic traffic, we focus on the impact it has on statistical traffic. As mentioned previously, \ASPMLS tends to create some long sequences of deterministic messages and then, avoid the best effort traffic to go through the nodes during those intervals.
    To fix this issue, the idea is to compute an optimal solution with PMLS with the largest messages size $\tau$ possible. Once this solution is computed, the times at which the deterministical traffic will reach every contention points of the network without latency are well computed, but since the messages are shorter than in the computed solution, it induce some free tics to avoid best effort traffic flow.
    Such a similar work focusing on decreasing the BE latency while scheduling CRAN messages on an optical ring can be found in~\cite{DBLP:conf/ondm/BarthGS19}.
    
    \subsubsection{Performance evaluation}
    
    Ici, bien définir ce qu'est un BE message
    (par ou il passe ...) et la définition de sa latence.
    Bien dire que FIFO avantage les best effort car il n'avantage pas les CRAN,
    c'est un peu le meilleur des cas pour les BE. 


    Bien dire que prioriser les CRAN fait perdre un peu de bande passante
    car on doit interdire les BE avant qu'ils ne passent.

    Here, the different ways to manage both statistical and deterministic traffic in the same network is evaluated.
    The star networks are generated with $8$ routes in which the length of the arcs are drawn between $0$ and $P$.
    The network is loaded of $60\%$ of C-RAN traffic, and the size of a Cloud Ran message $\tau$ is $2500$ that means the period is set to $33,333$.

    \paragraph{Best effort generation}
    The best effort traffic is generated following an exponential distribution. The size of a BE packet is set to $50$ tics. The generation is split in two different exponential distribution. A first one, which loads the network in average of $15\%$, and generate one BE packets every $333$ tics in average. The second models a burst of BE messages, that is, a generation of $10$ packets every $10,000$ tics, in average.
    
    Figure~\ref{fig:belatency} shows the cumulative distribution of the logical latency of BE packets, that is, the time each BE packets has wait in the buffers of the network. The experiment is made under several ways to schedule the C-RAN traffic. In \texttt{FIFO}, all CRAN and BE traffic are managed following the \texttt{FIFO} policy, regardless of the packet kind.
    In the three other experiment, the BE traffic is managed in \texttt{FIFO}, but the C-RAN is always prioritized following either \texttt{LTE}, \ASPMLS or adapted \ASPMLS.
    The experiment are made over $100$ random instances.
     \begin{figure}
       \begin{center}
      \includegraphics[width = 0.8\textwidth]{res.pdf}
       %\input{figures/stochastic}
      \end{center}
      \caption{Cumulative distribution of the latency of BE packets in different networks management}
      \label{fig:belatency}   
     \end{figure}    
     
     As expected, the latency of BE packets is better when both CRAN and BE packets are managed in \texttt{FIFO} than when the CRAN packets are prioritized without consideration of BE packets(\texttt{LTE} or \ASPMLS). Also, \ASPMLS performs worst than \texttt{LTE} because of the long sequence of BE traffic it creates.
     
     In adapted \ASPMLS, the CRAN traffic is smoothed on the period, in order to leave some free tics for BE traffic. One can remark that this phenomenon improve the BE traffic latency, even more than with a statistical approach. 
   

   Average
   
   
    \begin{tabularx}{0.9\textwidth}{|X|X|X|X|}
    \hline
    \texttt{FIFO} & \texttt{LTE} & \ASPMLS & Adapted \ASPMLS \\
     \hline
     $1977$ & $3256$ & $4909$ & $949$ \\
     \hline
      \end{tabularx}\\
      
      Max
      
    \begin{tabularx}{0.9\textwidth}{|X|X|X|X|}
    \hline
     \texttt{FIFO} & \texttt{LTE} & \ASPMLS & Adapted \ASPMLS \\
     \hline
      $20723$ & $15099$ & $23945$ & $4677$ \\
     \hline
      \end{tabularx}


 \section{Conclusion}
 
	In this paper, we proposed two kinds of deterministic sending schemes to establish low latency periodic communication between BBUs and RRHs in a star routed network. The first method uses no buffering and has no latency overhead. It works when the routes are short (using algorithm \shortestlongest) or when the load is less than $80\%$ (using algorithm \ESCA).  
	When the load is higher, buffering is allowed in the BBUs and we propose the algorithm \PMLS which finds a deterministic communication scheme with almost no additional logical latency.
 	Our deterministic approach is vastly superior to the classical statistical multiplexing for all loads of the network, even when sources of random traffic are present. This emphasizes that \emph{deterministic sources} of traffic are always best \emph{dealt with in a deterministic manner}.  
   
 	Reformuler ça comme des défis plutôt que des points sur une todolist

  	On star routed networks, we should design a better FPT algorithm for \pall, as efficient as the one for \pazl. We also plan to prove that \pazl and \pall are $\NP$-hard on star routed networks.
   	Then, we must generalize our study of the \pall problem to other common fronthaul topologies, such as caterpillars, trees, cycles or bounded treewidth graphs. Some elements on cycle topologies are given in~\cite{DBLP:conf/ondm/BarthGS19} and on routed networks of bounded contention depth, for synchronized RRHs~\cite{guiraud2020synchronized}.

   	Several variations of our model are relevant. Instead of minimizing the worst transmission time, we may want to minimize the average transmission time. This objective is linear, and it makes the size of the route irrelevant to the objective. Hence, it should be \emph{easier} to solve, for intance using linear programming. We could allow preemption, that is the messages may be cut into pieces, which would certainly change the complexity of the problem and help with the latency.  Instead of using periodic sending schemes, we could try to organize communications with pseudo-periodic schemes (periodic over several periods) or even use a temporal law. Finally, the routes may not be fixed but chosen in the graph to minimize $TR(A)$, which makes the problem even more difficult to solve (certainly $\Pi_2$-complete instead of $\NP$-complete). 



 	\paragraph*{Acknowledgments} 
 	We thank Olivier Marcé and Brice Leclerc who have introduced us to the problem, from a practical perspective. We also thank Christian Cad\'er\'e and David Auger for friendly discussions on the subject and insightful remarks. This work has been partially supported by the french ANR project N-GREEN.

\bibliographystyle{ieeetr}
\bibliography{Sources}

\end{document}
