-Dire un mot au début sur la complexité: opérations arithmétiques en O(1), les algos ne dépendent pas de 
$P$,$\tau$
	--> Dans l'intro?
-Vérifier le nom coherent routing et trouver une citation de réseau ou ils parlent de ça.
	-->Ca a l'air assez standard comme notion, il n'y à pas vraiment de papier qui explique cette notion, apres j'ai mis une ref qui parle de ca.
	
Intégrer dans la partie 2.3, pour montrer que les routes networks sont bien des DAGs.
	--> Je ne sais pas trop quoi dire, a part qu'on a un DAG.
-donner un nom et la définition du problème résolu par Simmons et le théorème de son papier
-donner ensuite la définition de Bra et le théorème issu de notre papier avec la question ouverte, peut-on faire en 
temps poly (plutôt théorique car en pratique le facteur multiplicatif n'est pas énorme)
-mettre sous forme de théorème que spall pour un chemin de taille 2, c'est NP-dur 
-faire ce qui est écrit dans Contention Depth Two and More, en particulier l'illustration
-dans la figure 4, retirer O_u, S_u et changer la caption pour parler de Real((2,1,0,3),{1}). 
Mettre un commentaire à coté de l'étape 2 pour dire 1 dans S_u donc pas de contrainte de temps de départ

-faire un passage sur random generation of routed network pour simplifier encore un peu: insister 
uniquement sur la forme du réseau utilisée et comment sont tirés aléatoirement les différents paramètres.
A priori, ça devient un paragraphe avant la partie expérience, non ?
Le dessin correspondant peut déjà etre mis avant, dans la partie sur les routed netwrk de depth 3.
le mot synthetic data est mal utilisée, ça veut juste dire des entrées non réelles, générées automatiquement
Pourquoi y-a-t-il des résultats ici ? Ça n'a pas de sens car on a même pas encore défini les algos.
Comment tu fais pour fixer la load à 80% alors que tu tires aléatoirement les routes, il faut expiquer ...
Le seul but de ce paragraphe est de donner suffisemment de détails pour que quelqu'un puisse faire des expériences
identiques et de justifier le "réalisme" et la "généralité" de la famille d'instances étudiées.

-dans l'expérience sur le hill climbing et les points aléatoires, il faut commencer 
par une solution réalisable. C'est ça que tu compares en fait, la proprotion de solutions
complacts qui sont représentable en fonction de la charge. Il faut que ça soit explicite.
Tu peux faire un hybride Hill climbing, intialisé par 100 trucs au hasard et GNS, pour être sur de fonctionner.
-figure 12: ce ne sont pas des steps mais des nombres de solutions en mémoire

-pour expliquer le tabou et le simulated annealing, il faut le faire par comparaison avec
le hill climbing: dans les deux cas on parcours le graphe des solutions en suivant 
des modifs locales, mais pas forcément en améliorant tout le temps la solution pour éviter
d'être bloqué ds un minimum local. Pour le tabou, ça se fait avec de la mémoire qui permet
de sortir des minimums et la recuit par une proba (de plus en plus faible) d'aller vers des solutions plus mauvaises.

-branch and bound ne devrait pas être dans la partie heuristics locale mais dans sa propre partie 
car ce n'est ni une heuristique, ni un algo local.

-c'est quoi la partie long routes ?

-pour l'algo de branch and bound dire qu'on énumère tous les compact assignements
et qu'on  veut filtrer pour ne garder que ceux qui sont canoniques minimaux. Pour des raisons
d'efficacité, on garde un peu plus -> décrire les coupes.
En plus de ça, c'est un algo branch and bound: décrire la relaxation du problème qui permet
de calculer la borne inf utilisée pour réaliser le bb. 
