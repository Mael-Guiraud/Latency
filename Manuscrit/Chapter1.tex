%!TEX root = Manuscript.tex

\chapter*{Présentation de la thèse}
\label{chap:introfr}
\addcontentsline{toc}{chapter}{Présentation de la thèse}


Les travaux présentés dans cette thèse s'inscrivent dans le contexte du développement de la 5G, et sont plus particulièrement axés sur la réduction de la latence dans les réseaux cœur des opérateurs.
L'un des objectifs pour la 5G est de garantir une latence bout en bout la plus faible possible.
Réduire la latence dans les réseaux permet non seulement d'améliorer la qualité de service des utilisateurs, et ouvre également la porte au développement d'applications pour lesquelles le temps de réponse est critique (véhicules autonomes, industrie 4.0, \ldots).
Le cas d'application que nous étudions est le Cloud Radio Access Network abrégé en C-RAN. Le but du C-RAN est de centraliser les unités de calcul situées aux pieds de chaque antenne dans un ou plusieurs centres de calcul communs, afin de faciliter la maintenance et de réduire les couts d'exploitation. Les antennes envoient périodiquement des messages aux centres de calcul, qui calculent une réponse et l'envoient aux antennes avec la même périodicité. Le temps écoulé entre l'envoi d'un message par une antenne et la réception de sa réponse doit être inférieur à une durée imposée par le protocole de communication radio. Ces messages envoyés sont très lourds, et utilisent donc beaucoup de bande passante dans les réseaux.

La méthode actuelle de gestion des réseaux, le multiplexage statistique, consiste à dimensionner chaque lien de façon à ce que le flux moyen de messages utilisant un lien puisse emprunter ce lien sans contrainte. Il arrive fréquemment que des flux envoient beaucoup de paquets d'un coup dans le réseau. Quand trop de paquets doivent utiliser un lien en même temps, on parle de contention. Les messages qui ne peuvent pas utiliser le lien directement sont mis dans une file d'attente, que nous appelons buffer de contention. Faire attendre les messages dans ces buffers de contention augmente la latence des paquets. Plus un réseau est chargé, plus il est probable d'avoir de hautes latences dues à la contention. Dans les réseaux C-RAN, les sources envoient periodiquement une grande quantité de messages nécessitant une garantie de faible latence, ils ne peuvent donc pas être gérés grâce au multiplexage statistique. C'est pourquoi nous proposons des solution de gestion deterministe et periodique des flux: le calcul d'un ordonnancement qui définit les dates de passage de chaque paquet dans chaque noeud du réseau. Les sources envoient périodiquement des paquets dans le réseau, toutes selon la même période, fixée par le protocole. Les ordonnancements que nous calculons garantissent l'absence de collision des paquets, quand l'ordonnancement est répété à l'infini de manière périodique.

Plusieurs groupes de travail proposent aujourd'hui des solutions techniques (présentées dans le chapitre~\ref{chap:TSN}) pour aider à contrôler la latence dans les réseaux. Avec ces solutions, les équipements du réseau sont capables d'allouer les ressources de transmission pour certains flux à un instant donné. Des travaux au sein de Nokia Bell Labs visent à aller plus loin pour pouvoir réserver une partie des ressources à un temps donné pour un paquet donné. Il faut toutefois calculer les dates auxquels les paquets doivent arriver dans les nœuds du réseau. Cette thèse se concentre sur le fait d'organiser les paquets, de façon à ce qu'ils n'entrent en collision dans aucun des nœuds, afin de supprimer les buffers de contention. Se passer complètement des buffers de contention n'est pas toujours possible, notamment lorsque les réseaux sont composés de beaucoup de nœuds. Dans ce cas, l'objectif de nos travaux est de minimiser le temps passé par les paquets dans les buffers de contention. Il est important de souligner que dans ce cas-là, le temps d'attente dans les buffers de contentions ne sont plus subis comme pour le multiplexage statistique, mais contrôlés et prévisibles.

Nous modélisons un réseau par un multigraphe orienté acyclique pondéré dont les sommets représentent les points de contention entre messages dans le réseau. Les poids des arcs représentent le temps physique de transmission entre deux points de contention. Deux messages rentrent en conflit s’ils doivent passer par le même point de contention au même moment. Nous considérons que le routage est donné, et nous cherchons à organiser les messages de façon à ce qu'il n'y ai pas de conflit dans le réseau. Nous étudions dans un premier temps le problème sur des réseaux simples et courants, constitués de deux points de contention en série. 
Nous définissons le problème de décision consistant à choisir la date de passage de chaque message dans chacun de ces deux points de contention de façon à ce qu'aucun message n'ait de conflit avec un autre dans le réseau. Ce problème ressemble à des problèmes classiques d'ordonnancement mais l'envoi périodique de nos flux en fait un problème original et difficile. Nous prouvons dans le chapitre~\ref{chap:model} que le problème est $\NP$-complet, même sur des graphes orientés acycliques de faible degré ou de faible profondeur, par réduction de problèmes de coloration d'arcs ou de sommets. Nous proposons donc des heuristiques (algorithme gloutons, métaheuristiques) qui nous permettent de trouver de bonnes solutions en temps polynomial pour tout type d'instance, et des algorithmes FPT (de complexité exponentielle en le nombre de routes mais pas en les autres paramètres du problème) qui trouvent une solution optimale au problème et qui sont suffisemment rapides sur les instances simples que nous étudions.


Nous étudions dans le chapitre~\ref{chap:PAZL} le problème de l'organisation de flux non-synchronisés dans un réseau sans aucun buffer.
Même si pour l'instant les protocoles liés au C-RAN ne permettent pas de désynchroniser les antennes (ce qui pourrait être le cas pour de prochaines générations de réseaux mobiles), cette approche est applicable dans d'autres contextes, comme une usine où des robots ne nécessitant pas de synchronisation doivent communiquer rapidement avec un centre de contrôle.
Nous cherchons à calculer un temps de départ des messages au début de leur route de façon à ce qu'ils ne soient pas en conflit avec les autres messages, sans que ce temps de départ ne soit considéré comme du temps de contention.
Les solutions de ce problème sont toutes optimales en terme de latence: la latence des messages est égale au temps physique de transmission, car aucune latence n'est ajoutée aux messages à cause de la contention. Nous décrivons des algorithmes gloutons de plus en plus évolués visant à optimiser l'impact d'ajouter un message à la solution partielle calculée. Ces algorithmes nous permettent de garantir qu'une solution au problème existe quand la charge du réseau est inférieure à $40\%$ (et même jusqu'a $61\%$ pour des messages de taille $1$). Nous proposons aussi un algorithme FPT (quand le problème est paramétré par le nombre de routes) qui nous permet de calculer la solution optimale en un temps raisonnable quand le nombre de routes est inférieur à $20$. Nos résultats montrent que le problème ne peut pas être résolu sans buffer de contention quand la charge du réseau est supérieure à $80\%$.
C'est pourquoi nous traitons dans le chapitre~\ref{chap:PALL} le problème d'organiser les flux avec un buffer sur la route, de façon à offrir un plus grand degré de liberté. Nous étudions plus particulièrement le problème de minimisation, c'est-à-dire, trouver une solution qui minimise la latence maximale des routes. Nous proposons une approche en deux parties. Premièrement, nous choisissons les temps d'envoi des messages sur le premier point de contention, et nous résolvons dans un second temps le problème de choisir le temps d'attente de chaque message dans le second point de contention. Pour cela, nous décrivons un algorithme polynomial basé sur le problème d'ordonnancement classique de la littérature, adapté à notre cadre périodique. Nous proposons aussi un algorithme FPT basé sur le même principe, mais qui garantit de trouver la solution optimale. Nous montrons que nous sommes capables de trouver des solutions pour lesquelles la latence est minimale pour $99.9\%$ des instances dans des réseaux très chargés, et que nos méthodes donnent des résultats excellents comparées au multiplexage statistique.

Dans le chapitre~\ref{chap:SPALL}, nous étudions le problème d'organiser des flux synchronisés sur tout type de DAG. Dans ce cas, tous les messages sont envoyés en même temps par les sources et nous nous permettons de faire attendre les messages dans des buffers à chaque point de contention du réseau. Nous étudions le problème de minimiser la plus grande latence dans le réseau. Nous commençons par décrire des algorithmes gloutons qui trouvent une solution réalisable pour n'importe quelle charge, qui servent de point de départ aux algorithmes de recherche locale utilisés ensuite. Nous introduisons une forme compacte du problème qui nous permet de définir une notion de voisinage entre les solutions afin d'explorer l'ensemble de ces dernières. Nous étudions les performances des algorithmes de recherche d'optimum local (hill-climbing, recherche tabou, recuit simulé) et nous proposons un algorithme Branch and Bound qui énumère l'ensemble des solutions sous forme compacte, en faisaint suffisemment de coupes pour trouver la solution optimale rapidement. Nous montrons expérimentalement que l'algorithme Branch and Bound est capable de trouver une solution optimale en un temps raisonnable pour $12$ routes, tandis que le recuit simulé permet de trouver des solutions bien meilleures que le multiplexage statistique pour n'importe quelle taille d'instance.

Nous étudions ensuite dans le chapitre~\ref{chap:BE} l'impact de nos algorithmes d'ordonnancement, lorsque les flux C-RAN périodiques et prioritaires partagent le réseau avec des flux Best-Effort, non prioiritaires et dont les arivées suivent un processus stochastique. Nous proposons une méthode d'adaptation de nos algorithmes qui permet de lisser la charge des flux C-RAN tout au long de la période, sans augmenter la latence. Nos expériences montrent que, même si organiser les flux de façon déterministe comme nous le faisons requiert d'utiliser un peu plus de bande passante pour réserver les ressources, la latence moyenne des flux Best-Effort est meilleure qu'avec le multiplexage statistique. Nous montrons aussi le même genre de résultats dans un anneau optique ou l'ordonnancement des flux C-RAN est rendu trivial par les contraintes techniques de la conversion opto-électronique.

Toutes nos approches se basent sur des hypothèses techniques fortes : les flux doivent être parfaitement synchronisés, le réseau doit être intelligent et programmable. Le chapitre~\ref{chap:TSN} fait le point sur les standards récemment développés qui se rapprochent de nos hypothèses. Nous montrons aussi les limites de ces standards, et nous introduisons un équipement en phase de développement qui nous permettrait de réduire la latence dans les réseaux au temps physique de transmission.




\chapter*{Introduction (in English)}
\label{chap:introen}
\addcontentsline{toc}{chapter}{Introduction (in English)}
A traduire depuis l'intro fr finie