%!TEX root = Manuscript.tex

\chapter*{Présentation de la thèse}
\label{chap:introfr}
\addcontentsline{toc}{chapter}{Présentation de la thèse}


Les travaux présentés dans cette thèse s'inscrivent dans le contexte du développement de la 5G, et sont plus particulièrement axés sur la réduction de la latence dans les réseaux cœur des opérateurs.
L'un des objectifs pour la 5G est de garantir une latence bout en bout la plus faible possible.
Réduire la latence dans les réseaux permet non seulement d'améliorer la qualité de service des utilisateurs, et ouvre également la porte au développement d'applications pour lesquelles le temps de réponse est critique (véhicules autonomes, industrie 4.0,\ldots).
Le cas d'application que nous étudions est le C-RAN (pour Cloud Radio Access Network). Le but du C-RAN est de centraliser les unités de calcul situés aux pieds de chaque antenne dans un ou plusieurs centres de calcul communs, afin de faciliter la maintenance et de réduire les couts d'exploitations. Les antennes envoient périodiquement des messages aux centres de calcul, qui calculent une réponse et l'envoient aux antennes avec la même période. Le temps écoulé entre l'envoi d'un message par une antenne et la réception de sa réponse doit être inférieur à une durée imposée par le protocole de communication radio. Ces messages envoyés sont très lourds, et utilisent donc beaucoup de bande passante dans les réseaux.

La méthode de gestion actuelle des réseaux, le multiplexage statistique, consiste à dimensionner chaque lien de façon à ce que le flux moyen de message utilisant un lien puisse emprunter ce lien sans contrainte. Il arrive fréquemment que des flux envoient beaucoup de paquets d'un coup dans le réseau. Quand trop de paquets doivent utiliser un lien en même temps, on parle de contention. Les messages qui ne peuvent pas utiliser le lien directement sont mis dans une file d'attente, que nous appelons buffer de contention. Faire attendre les messages dans ces buffers de contention augmente la latence des paquets. Plus un réseau est chargé, plus il est probable d'avoir de hautes latences dues à la contention. Dans les réseaux C-RAN, les sources envoient periodiquement une grande quantité de messages nécessitant une garantie de faible latence, ils ne peuvent donc pas être gérés grâce au multiplexage statistique. C'est pourquoi nous proposons des solution de gestion deterministe et periodique des flux, qui consiste à calculer un ordonnancement qui définit les dates de passage de chaque paquet dans chaque noeud du réseau. Les sources envoient régulièrement des paquets dans le réseau. Le temps ecoulé durée entre deux envois est le même pour toutes les sources et est appelé periode. Nous calculons un ordonnancement sur une durée d'une periode et cet ordonnancement est ensuite répété à l'infini.

Plusieurs groupes de travail proposent aujourd'hui des solutions techniques (présentées dans le chapitre~\ref{chap:TSN}) pour aider à contrôler la latence dans les réseaux. Avec ces solutions, les équipements du réseau sont capables d'allouer les ressources de transmission pour certains flux à un instant donné. Des travaux au sein de Nokia Bell Labs visent à aller plus loin pour pouvoir réserver une partie des ressources à un temps donné pour un paquet donné. Il faut toutefois calculer les dates auxquels les paquets doivent arriver dans les nœuds du réseau. Cette thèse se concentre sur le fait d'organiser les paquets, de façon à ce qu'ils n'entrent en collision dans aucun des nœuds, afin de supprimer les buffers de contention. Se passer complètement des buffers de contention n'est pas toujours possible, notamment lorsque les réseaux sont composés de beaucoup de nœuds. Dans ce cas, l'objectif de nos travaux est de minimiser le temps passé par les paquets dans les files d'attentes. Il est important de souligner que dans ce cas-là que les temps de contentions ne sont plus subis comme pour le multiplexage statistique, mais contrôlés.

Nous modélisons un réseau par un multigraphe orienté pondéré dont les sommets représentent les points de contention entre messages dans le réseau. Deux messages rentrent en conflit s’ils doivent passer par le même point de contention au même moment. Nous étudions dans un premier temps le problème sur des réseaux simples et courant, constitués de deux points de contention en série. 
Nous définissons le problème de décision consistant à choisir la date de passage de chaque message dans chacun de ces deux points de contention de façon à ce qu'aucun message n'ai de conflit avec un autre dans le réseau. Ce problème ressemble à des problèmes classique d'ordonnancement mais l'envoi periodique de nos flux en fait un problème original et difficile. Nous prouvons dans le chapitre~\ref{chap:model} que le problème est $NP$-complet, même sur des graphes orientés acycliques de faible degré ou de faible profondeur, par réduction de problèmes de coloration d'arcs ou de sommets. Nous proposons donc des heuristiques (algorithme gloutons, métaheuristiques) qui nous permettent de trouver de bonnes solutions en temps polynomial pour tout type d'instances, et des algorithmes FPT, qui trouvent une solution optimale au problème en temps exponentiel en le nombre de routes qui sont efficaces sur les instances pratiques que nous étudions.


Nous étudions dans le chapitre~\ref{chap:PAZL} le problème d'organiser des flux non-synchronisés dans le réseau sans aucun buffer.
Même si pour l'instant les protocoles liés au C-RAN ne permettent pas de désynchroniser les antennes (ce qui peut être le cas des prochaines générations de réseaux mobiles), cette approche est applicable à beaucoup de cas d'applications, comme une usine ou des robots qui ne nécéssitent pas de synchronisations doivent communiquer rapidement avec un centre de contrôle par exemple.
Nous cherchons à calculer un temps de départ des messages au début de leur route de façon à ce qu'ils ne soient pas en conflit avec les autres messages, sans que ce temps de départ ne soit considéré comme du temps de contention.
Les solutions de ce problème sont toutes optimales en termes de latence, car aucune latence n'est ajoutée aux messages à cause de la contention. Nous décrivons des algorithmes de plus en plus évolués visant à optimiser l'impact d'ajouter un message à la solution partielle calculée. Ces algorithmes nous permettent de garantir qu'une solution au problème existe quand la charge du réseau est inférieure à $40\%$ (et même jusqu'a $61\%$ pour des messages de taille $1$). Nous proposons aussi un algorithme FPT (quand le problème est paramétré par le nombre de routes) qui nous permet de calculer la solution optimale quand le nombre de routes est inférieur à $20$. Les résultats montrent que le problème ne peut pas être résolu quand la charge du réseau est supérieure à $80\%$.
C'est pourquoi nous traitons dans le chapitre~\ref{chap:PALL} le problème d'organiser les flux avec un buffer sur la route, de façon à offrir un plus grand degré de liberté. Nous étudions plus particulièrement le problème de minimisation, c'est-à-dire, trouver une solution pour laquelle le maximum des latences des routes est minimal. Nous proposons une approche en deux parties. Les temps d'envoi des messages sur le premier point de contention sont fixés en amont et nous résolvons le problème de choisir le temps d'attente de chaque message dans le second point de contention. Pour cela, nous décrivons un algorithme polynomial basé sur le problème d'ordonnancement classique de la littérature, adapté pour la périodicité. Nous proposons aussi un algorithme FPT basé sur le même principe, mais qui garantit de trouver la solution optimale. Nous montrons que nous sommes capables de trouver des solutions pour lesquelles la latence est minimale pour $99.9\%$ des instances dans des réseaux très chargés, et que nos méthodes donnent des résultats excellents comparées au multiplexage statistique.

Dans le chapitre~\ref{chap:SPALL}, nous étudions le problème d'organiser des flux synchronisés sur tout type de DAG. Dans ce cas, tous les messages sont envoyés en même temps par les sources et nous nous permettons de faire attendre les messages dans des buffers à chaque point de contention du réseau. Nous étudions le problème de minimiser la plus grande latence dans le réseau. Nous commençons par décrire des algorithmes gloutons qui trouvent une solution réalisable pour n'importe quelle charge, qui servent de point de départ aux algorithmes de recherche locale utilisés ensuite. Nous définissions une forme compacte du problème qui nous permet de proposer une notion de voisinage entre les solutions afin d'explorer l'ensemble de ces dernières. Nous étudions les performances des algorithmes de recherche d'optimum local (hill-climbing, recherche tabou, recuit simulé) et nous proposons un algorithme Branch and Bound qui énumère l'ensemble des solutions sous forme compacte, en faisaint  suffisemment de coupe pour trouver la solution optimale rapidement. Nous montrons expérimentalement que l'algorithme Branch and Bound est capable de trouver une solution optimale en un temps raisonnable pour $12$ routes, tandis que le recuit simulé permet de trouver des solutions bien meilleures que le multiplexage statistique pour n'importe quelle taille d'instance.

Nous étudions ensuite dans le chapitre~\ref{chap:BE} l'impact de nos algorithmes d'ordonnancement de flux C-RAN, periodiques et prioritaires lorsqu'ils partagent le réseau avec des flux Best-Effort, non prioiritaires et dont les arivées suivent des modèles stochastiques. Nous proposons une méthode d'adaptation de nos algorithmes qui permet de lisser la charge des flux C-RAN tout au long de la période, sans augmenter leurs latences. Les résultats montrent que, même si organiser les flux de façon déterministe comme nous le faisons requiert d'utiliser un peu plus de bande passante pour réserver les ressources, la latence moyenne des flux Best-Effort est meilleure qu'avec le multiplexage statistique. Nous montrons aussi le même genre de résultats dans un anneau optique ou l'ordonnancement des flux C-RAN est rendu trivial par les contraintes techniques de la conversion opto-electronique.

Toutes nos approches se basent sur des hypothèses techniques fortes : les flux doivent être parfaitement synchronisés, le réseau doit être intelligent et programmable. Le chapitre~\ref{chap:TSN} fait le point sur les standards récemment développés qui se rapprochent de nos hypothèses. Nous montrons aussi les limites de ces standards, et nous introduisons un équipement en phase de développement qui nous permettrais de réduire la latence dans les réseaux au temps physique de transmission.




\chapter*{Introduction (in English)}
\label{chap:introen}
\addcontentsline{toc}{chapter}{Introduction (in English)}
A traduire depuis l'intro fr finie